{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'summarize_all_results' from '/juice/scr/ananya/cifar_experiments/transfer_learning/scripts/summarize_all_results.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import summarize_all_results\n",
    "import importlib\n",
    "import math\n",
    "import pickle\n",
    "importlib.reload(summarize_all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '../logs/'\n",
    "name_template = 'full_ft_{option}{dataset}_{model}'\n",
    "\n",
    "def get_bolds(table, std_err_table=None, eps=0.2):\n",
    "    is_best = np.zeros((len(table), len(table[0])), dtype=np.int32)\n",
    "    for col in range(len(table[0])):\n",
    "        best_idx = np.argmax(table[:,col])\n",
    "        best_acc = table[best_idx][col]\n",
    "        if std_err_table is not None and col < len(std_err_table[0]):\n",
    "            best_std = std_err_table[best_idx][col]\n",
    "            if math.isnan(best_std):\n",
    "                best_std = eps\n",
    "        for row in range(len(table)):\n",
    "            if std_err_table is not None and col < len(std_err_table[0]):\n",
    "                cur_std = std_err_table[row][col]\n",
    "                if math.isnan(cur_std):\n",
    "                    cur_std = eps\n",
    "                if np.abs(table[row][col] - best_acc) <= max(best_std, cur_std):\n",
    "                    is_best[row][col] = 1\n",
    "            else:\n",
    "                if table[row][col] >= best_acc - eps:\n",
    "                    is_best[row][col] = 1\n",
    "    return is_best\n",
    "\n",
    "def get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list=None,\n",
    "              aggregation_metric_list=None, num_sweep=6, desired_epochs_list=None):\n",
    "    # desired_epochs_list is a list of size len(datasets) that stores the number of epochs we are\n",
    "    # supposed to have run each dataset for. Used to validate if the runs finished.\n",
    "    mean_table = np.zeros((len(models), len(options), sum([len(ol) for ol in output_metrics_list])))\n",
    "    std_table = np.zeros((len(models), len(options), sum([len(ol) for ol in output_metrics_list])))\n",
    "    for model_idx, model in enumerate(models):\n",
    "        for option_idx, option in enumerate(options):\n",
    "            cur_means = []\n",
    "            cur_stds = []\n",
    "            for dataset_idx, dataset in enumerate(datasets):\n",
    "                dir_path = log_dir + '/' + name_template.format(model=model, option=option, dataset=dataset)\n",
    "                output_metrics = output_metrics_list[dataset_idx]\n",
    "                if val_metric_list is None:\n",
    "                    val_metric = 'LAST'\n",
    "                else:\n",
    "                    val_metric = val_metric_list[dataset_idx]\n",
    "                if aggregation_metric_list is None:\n",
    "                    agg_metric = val_metric\n",
    "                else:\n",
    "                    agg_metric = aggregation_metric_list[dataset_idx]\n",
    "                res, best_row_mean, best_row_std, num_epochs_list = summarize_all_results.get_experiment_aggregate_summary(\n",
    "                    dir_path, val_metric, output_metrics, aggregation_metric=agg_metric)\n",
    "                num_jobs = len(res)\n",
    "                if (desired_epochs_list is not None and\n",
    "                    desired_epochs_list[dataset_idx] != np.min(num_epochs_list)):\n",
    "                    bad_indices = np.argwhere(np.array(num_epochs_list) < desired_epochs_list[dataset_idx])\n",
    "                    bad_runs = [dir_path + '/' + run_folder for run_folder in res['name'][bad_indices[:, 0]]]\n",
    "                    print('some jobs did not finish: ', model, dataset, option, bad_runs)\n",
    "                if num_jobs != num_sweep and num_jobs != num_sweep * 3:\n",
    "                    print('not all jobs ran: ', model, option, dataset, num_jobs)\n",
    "                cur_means.append(best_row_mean.to_numpy()[0,:-2])\n",
    "                cur_stds.append(best_row_std.to_numpy()[0,:-2])\n",
    "            cur_means = np.concatenate(cur_means)\n",
    "            cur_stds = np.concatenate(cur_stds)\n",
    "            mean_table[model_idx][option_idx] = cur_means\n",
    "            std_table[model_idx][option_idx] = cur_stds\n",
    "    return mean_table, std_table\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    x = []\n",
    "    for l in list_of_lists:\n",
    "        x.append(l)\n",
    "    return x\n",
    "\n",
    "def filter_columns(table, old_output_metrics_list, new_output_metrics_list):\n",
    "    def get_indices(old_list, new_items):\n",
    "        return np.array([old_list.index(x) for x in new_items])\n",
    "    local_indices_list = [get_indices(o, n) for o, n in zip(old_output_metrics_list, new_output_metrics_list)]\n",
    "#     print(local_indices_list)\n",
    "    old_lens = [len(o) for o in old_output_metrics_list]\n",
    "    cum_old_lens = np.concatenate([[0], np.cumsum(old_lens)])[:-1]\n",
    "#     print(cum_old_lens)\n",
    "    global_indices = [local_indices + cum_old_len for local_indices, cum_old_len in zip(local_indices_list, cum_old_lens)]\n",
    "#     print(list(np.concatenate(global_indices)))\n",
    "    return table[:, :, global_indices][:,:,:,0]\n",
    "\n",
    "\n",
    "# Add table to make TSV and Latex tables. Add averages.\n",
    "def display_tsv_table(models, options, shortened_output_metrics_list, table, std_err_table=None):\n",
    "    first_line = '\\t\\t' + '\\t'.join(shortened_output_metrics_list)\n",
    "    print(first_line)\n",
    "    for model_idx, model in enumerate(models):\n",
    "        for option_idx, option in enumerate(options):\n",
    "            line = model + '\\t' + option\n",
    "            for idx, val in enumerate(table[model_idx][option_idx]):\n",
    "                line += '\\t' + '{:.1f}'.format(val)\n",
    "                if (std_err_table is not None and\n",
    "                    idx < len(std_err_table[model_idx][option_idx])):\n",
    "                    line += ' ({:.1f})'.format(std_err_table[model_idx][option_idx][idx])\n",
    "            print(line)\n",
    "            \n",
    "def add_average_column(table):\n",
    "    new_table = []\n",
    "    for model_idx in range(len(table)):\n",
    "        model_table = table[model_idx]\n",
    "        means = np.mean(model_table, axis=1)\n",
    "        new_model_table = np.concatenate([model_table, np.expand_dims(means, axis=-1)], axis=-1)\n",
    "        new_table.append(new_model_table)\n",
    "    return np.array(new_table)\n",
    "        \n",
    "def display_latex_table(models, options, shortened_output_metrics_list, table, std_err_table=None, bold_best=True, is_last_avg=True, light_thresh=0.2):\n",
    "\n",
    "    # Print latex table.\n",
    "    if len(models) == 1:\n",
    "        num_columns = 2*len(shortened_output_metrics_list) + 1\n",
    "    else:\n",
    "        num_columns = 2*len(shortened_output_metrics_list) + 2\n",
    "    if is_last_avg:\n",
    "        print('\\\\begin{tabular}{' + ('c'*(num_columns-2)) + '|cc}')\n",
    "    else:\n",
    "        print('\\\\begin{tabular}{' + ('c'*num_columns) + '}')\n",
    "    print('\\\\toprule')\n",
    "    first_line = '' \n",
    "    for oml in shortened_output_metrics_list:\n",
    "        first_line += ' & \\multicolumn{2}{c}{' + oml + '} '\n",
    "    first_line += '\\\\\\\\'\n",
    "    if len(models) > 1:\n",
    "        first_line = ' & ' + first_line\n",
    "    print(first_line)\n",
    "    for model_idx, model in enumerate(models):\n",
    "        print('\\\\midrule')\n",
    "        if std_err_table is None:\n",
    "            is_bold = get_bolds(table[model_idx], eps=0.2)\n",
    "        else:\n",
    "            is_bold = get_bolds(table[model_idx], std_err_table[model_idx], eps=0.2)\n",
    "        for option_idx, option in enumerate(options):\n",
    "            if len(models) > 1:\n",
    "                line = model + ' & ' + option\n",
    "            else:\n",
    "                line = option\n",
    "            for idx, val in enumerate(table[model_idx][option_idx]):\n",
    "                line += ' & '\n",
    "#                 print(is_bold[option_idx][idx])\n",
    "                if is_bold[option_idx][idx] and bold_best:\n",
    "                    line += '\\\\textbf{'\n",
    "                line += '{:.1f}'.format(val)\n",
    "                if (std_err_table is not None and\n",
    "                    idx < len(std_err_table[model_idx][option_idx]) and\n",
    "                    not math.isnan(std_err_table[model_idx][option_idx][idx])):\n",
    "                    line += ' ({:.1f})'.format(std_err_table[model_idx][option_idx][idx])\n",
    "                if is_bold[option_idx][idx] and bold_best:\n",
    "                    line += '}'\n",
    "                if option_idx:# if not sgd\n",
    "                    sgd_val = table[model_idx][0][idx]\n",
    "                    diff_fp = val - sgd_val\n",
    "                    diff = round(val,1)-round(sgd_val,1)\n",
    "                    if diff_fp>=light_thresh:\n",
    "                        line += ' & \\hspace{{-1em}}{{\\hgreen{{(+{:.1f})}}}}'.format(diff)\n",
    "                    elif diff_fp>=0.0:\n",
    "                        line += ' & \\hspace{{-1em}}{{\\lgreen{{(+{:.1f})}}}}'.format(diff)\n",
    "                    elif diff>=-1*light_thresh:\n",
    "                        line += ' & \\hspace{{-1em}}{{\\lred{{(-{:.1f})}}}}'.format(abs(diff))\n",
    "                    else:\n",
    "                        line += ' & \\hspace{{-1em}}{{\\hred{{(-{:.1f})}}}}'.format(abs(diff))\n",
    "                    # else:\n",
    "                    #     line += ' & '\n",
    "                else:\n",
    "                    line += ' & '\n",
    "\n",
    "            line += '\\\\\\\\'\n",
    "            print(line)\n",
    "    print('\\\\bottomrule')\n",
    "    print('\\\\end{tabular}')\n",
    "    \n",
    "    \n",
    "def display_id_ood_tables(mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=False):\n",
    "    # Filter the ID and OOD metrics.\n",
    "    print('\\n\\nID Accuracies')\n",
    "    id_mean_table = filter_columns(mean_table, output_metrics_list, id_output_metrics_list)\n",
    "    id_mean_table = add_average_column(id_mean_table)\n",
    "    id_std_table = filter_columns(std_table, output_metrics_list, id_output_metrics_list)\n",
    "    if no_std:\n",
    "        id_std_table = None\n",
    "    display_tsv_table(shorted_model_names, shortened_options_names, shortened_dataset_names, id_mean_table, id_std_table)\n",
    "    print('')\n",
    "    display_latex_table(shorted_model_names, shortened_options_names, shortened_dataset_names, id_mean_table, id_std_table, is_last_avg=True)\n",
    "\n",
    "    print('\\n\\nOOD Accuracies')\n",
    "    ood_mean_table = filter_columns(mean_table, output_metrics_list, ood_output_metrics_list)\n",
    "    ood_mean_table = add_average_column(ood_mean_table)\n",
    "    ood_std_table = filter_columns(std_table, output_metrics_list, ood_output_metrics_list)\n",
    "    if no_std:\n",
    "        ood_std_table = None\n",
    "    display_tsv_table(shorted_model_names, shortened_options_names, shortened_dataset_names, ood_mean_table, ood_std_table)\n",
    "    print('')\n",
    "    display_latex_table(shorted_model_names, shortened_options_names, shortened_dataset_names, ood_mean_table, ood_std_table, is_last_avg=True)\n",
    "    return id_mean_table, ood_mean_table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big table, Living17, Waterbirds, DomainNet, Camelyon, FMoW (Early stopped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Big table, Living17, Waterbirds, DomainNet, Camelyon, FMoW (Early stopped)\n",
    "models = ['clip_vit_b16', 'clip_vit_l14', 'timm_vit_b16_in21k', 'dino_vit_b16',  'convnext_vit_b', 'bit_resnet_50_in21k', 'bit_resnet_101_in21k']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "shorted_model_names = ['CLIP ViT-B/16', 'CLIP ViT-L/14', 'Sup ViT-B/16', 'DINO ViT-B/16', 'ConvNext-Base', 'BiT ResNet-50', 'BiT ResNet-101', ]\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (freeze-embed)']\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Living-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "# pickle.dump( (mean_table, std_table), open( \"big_table_main.pkl\", \"wb\" ) )\n",
    "# mean_table_old_order, std_table_old_order = pickle.load( open( \"big_table_main.pkl\", \"rb\" ) )\n",
    "\n",
    "# Rearranging mean table\n",
    "mean_table = mean_table_old_order[[0,6,1,2,5,3,4],:,:]\n",
    "std_table = std_table_old_order[[0,6,1,2,5,3,4],:,:]\n",
    "\n",
    "id_mean_table, ood_mean_table = display_id_ood_tables(\n",
    "    mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n",
    "\n",
    "# display_tsv_table(shorted_model_names, shortened_options_names, shortened_output_metrics_list, mean_table, std_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average ID and OOD results for the 3 methods.\n",
    "print(np.mean(id_mean_table[:,:,5], axis=0))\n",
    "print(np.mean(ood_mean_table[:,:,5], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNeXt results including just freeze stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 11)\n",
      "\n",
      "\n",
      "ID Accuracies\n",
      "\t\tLiving-17\tWaterbirds\tFMoW\tCamelyon\tAvg.\n",
      "ConvNext-Base\tSGD\t98.7\t99.0\t66.3\t99.4\t90.9\n",
      "ConvNext-Base\tAdamW\t98.6\t99.5\t68.8\t99.7\t91.7\n",
      "ConvNext-Base\tSGD (freeze-stem-block-1)\t98.6\t99.4\t67.4\t99.5\t91.2\n",
      "ConvNext-Base\tSGD (freeze-stem)\t98.8\t99.3\t67.2\t99.5\t91.2\n",
      "\n",
      "\\begin{tabular}{ccccccccc|cc}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{Living-17}  & \\multicolumn{2}{c}{Waterbirds}  & \\multicolumn{2}{c}{FMoW}  & \\multicolumn{2}{c}{Camelyon}  & \\multicolumn{2}{c}{Avg.} \\\\\n",
      "\\midrule\n",
      "SGD & \\textbf{98.7} &  & 99.0 &  & 66.3 &  & 99.4 &  & 90.9 & \\\\\n",
      "AdamW & \\textbf{98.6} & \\hspace{-1em}{\\lred{(-0.1)}} & \\textbf{99.5} & \\hspace{-1em}{\\hgreen{(+0.5)}} & \\textbf{68.8} & \\hspace{-1em}{\\hgreen{(+2.5)}} & \\textbf{99.7} & \\hspace{-1em}{\\hgreen{(+0.3)}} & \\textbf{91.7} & \\hspace{-1em}{\\hgreen{(+0.8)}}\\\\\n",
      "SGD (freeze-stem-block-1) & \\textbf{98.6} & \\hspace{-1em}{\\lred{(-0.1)}} & \\textbf{99.4} & \\hspace{-1em}{\\hgreen{(+0.4)}} & 67.4 & \\hspace{-1em}{\\hgreen{(+1.1)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & 91.2 & \\hspace{-1em}{\\hgreen{(+0.3)}}\\\\\n",
      "SGD (freeze-stem) & \\textbf{98.8} & \\hspace{-1em}{\\lgreen{(+0.1)}} & 99.3 & \\hspace{-1em}{\\hgreen{(+0.3)}} & 67.2 & \\hspace{-1em}{\\hgreen{(+0.9)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & 91.2 & \\hspace{-1em}{\\hgreen{(+0.3)}}\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "OOD Accuracies\n",
      "\t\tLiving-17\tWaterbirds\tFMoW\tCamelyon\tAvg.\n",
      "ConvNext-Base\tSGD\t94.0\t80.2\t39.7\t83.0\t74.2\n",
      "ConvNext-Base\tAdamW\t90.3\t89.8\t38.4\t89.5\t77.0\n",
      "ConvNext-Base\tSGD (freeze-stem-block-1)\t92.6\t86.9\t38.2\t88.1\t76.5\n",
      "ConvNext-Base\tSGD (freeze-stem)\t91.4\t84.7\t40.3\t86.2\t75.7\n",
      "\n",
      "\\begin{tabular}{ccccccccc|cc}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{Living-17}  & \\multicolumn{2}{c}{Waterbirds}  & \\multicolumn{2}{c}{FMoW}  & \\multicolumn{2}{c}{Camelyon}  & \\multicolumn{2}{c}{Avg.} \\\\\n",
      "\\midrule\n",
      "SGD & \\textbf{94.0} &  & 80.2 &  & 39.7 &  & 83.0 &  & 74.2 & \\\\\n",
      "AdamW & 90.3 & \\hspace{-1em}{\\hred{(-3.7)}} & \\textbf{89.8} & \\hspace{-1em}{\\hgreen{(+9.6)}} & 38.4 & \\hspace{-1em}{\\hred{(-1.3)}} & \\textbf{89.5} & \\hspace{-1em}{\\hgreen{(+6.5)}} & \\textbf{77.0} & \\hspace{-1em}{\\hgreen{(+2.8)}}\\\\\n",
      "SGD (freeze-stem-block-1) & 92.6 & \\hspace{-1em}{\\hred{(-1.4)}} & 86.9 & \\hspace{-1em}{\\hgreen{(+6.7)}} & 38.2 & \\hspace{-1em}{\\hred{(-1.5)}} & 88.1 & \\hspace{-1em}{\\hgreen{(+5.1)}} & 76.5 & \\hspace{-1em}{\\hgreen{(+2.3)}}\\\\\n",
      "SGD (freeze-stem) & 91.4 & \\hspace{-1em}{\\hred{(-2.6)}} & 84.7 & \\hspace{-1em}{\\hgreen{(+4.5)}} & \\textbf{40.3} & \\hspace{-1em}{\\hgreen{(+0.6)}} & 86.2 & \\hspace{-1em}{\\hgreen{(+3.2)}} & 75.7 & \\hspace{-1em}{\\hgreen{(+1.5)}}\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# # ConvNeXt, Living17, Waterbirds, DomainNet, Camelyon, FMoW (Early stopped), including freeze-stem\n",
    "# models = ['convnext_vit_b']\n",
    "# options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'freeze_bottom_1_']\n",
    "# datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "# output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "# val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "# aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "# desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "# shorted_model_names = ['CLIP ViT-B/16', 'CLIP ViT-L/14', 'Sup ViT-B/16', 'DINO ViT-B/16', 'ConvNext-Base', 'BiT ResNet-50', 'BiT ResNet-101', ]\n",
    "# shortened_options_names = ['SGD', 'AdamW', 'SGD (freeze-stem-block-1)', 'SGD (freeze-stem)']\n",
    "# id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "# ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "# shortened_dataset_names = ['Living-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "\n",
    "# mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "# # pickle.dump( (mean_table, std_table), open( \"big_table_main.pkl\", \"wb\" ) )\n",
    "# # mean_table_old_order, std_table_old_order = pickle.load( open( \"big_table_main.pkl\", \"rb\" ) )\n",
    "\n",
    "# id_mean_table, ood_mean_table = display_id_ood_tables(\n",
    "#     mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n",
    "\n",
    "# # display_tsv_table(shorted_model_names, shortened_options_names, shortened_output_metrics_list, mean_table, std_table)\n",
    "\n",
    "# The following table is without DomainNet.\n",
    "models = ['convnext_vit_b']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'freeze_bottom_1_']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/id_val', 'test_acc/id_val']\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 5, 3]\n",
    "shorted_model_names = ['ConvNext-Base']\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (freeze-stem-block-1)', 'SGD (freeze-stem)']\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Living-17', 'Waterbirds', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "# pickle.dump( (mean_table, std_table), open( \"big_table_main.pkl\", \"wb\" ) )\n",
    "# mean_table_old_order, std_table_old_order = pickle.load( open( \"big_table_main.pkl\", \"rb\" ) )\n",
    "\n",
    "print(mean_table.shape)\n",
    "id_mean_table, ood_mean_table = display_id_ood_tables(\n",
    "    mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n",
    "\n",
    "# display_tsv_table(shorted_model_names, shortened_options_names, shortened_output_metrics_list, mean_table, std_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP results including wilds datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Results, all datasets\n",
      "living17_nonorm                                     name  test_acc/source_val_living  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0                     97.8235   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1                     97.6471   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2                     98.0000   \n",
      "3   optimizer.args.lr-0.0003_seed-0_run0                     97.7059   \n",
      "4   optimizer.args.lr-0.0003_seed-1_run1                     97.1765   \n",
      "5   optimizer.args.lr-0.0003_seed-2_run2                     97.2353   \n",
      "6    optimizer.args.lr-0.001_seed-0_run0                     96.8824   \n",
      "7    optimizer.args.lr-0.001_seed-1_run1                     95.1765   \n",
      "8    optimizer.args.lr-0.001_seed-2_run2                     95.5882   \n",
      "9    optimizer.args.lr-0.003_seed-0_run0                     94.0588   \n",
      "10   optimizer.args.lr-0.003_seed-1_run1                     73.0588   \n",
      "11   optimizer.args.lr-0.003_seed-2_run2                     74.8235   \n",
      "12    optimizer.args.lr-0.01_seed-0_run0                     70.7059   \n",
      "13    optimizer.args.lr-0.01_seed-1_run1                     69.7059   \n",
      "14    optimizer.args.lr-0.01_seed-2_run2                     71.2941   \n",
      "15   optimizer.args.lr-3e-05_seed-0_run0                     97.4706   \n",
      "16   optimizer.args.lr-3e-05_seed-1_run1                     97.7059   \n",
      "17   optimizer.args.lr-3e-05_seed-2_run2                     96.7059   \n",
      "\n",
      "    test_acc/target_val_living  \\\n",
      "0                      81.4118   \n",
      "1                      78.7647   \n",
      "2                      79.7059   \n",
      "3                      79.8824   \n",
      "4                      77.0588   \n",
      "5                      78.0588   \n",
      "6                      76.0588   \n",
      "7                      67.2941   \n",
      "8                      67.5882   \n",
      "9                      64.7647   \n",
      "10                     31.9412   \n",
      "11                     33.5882   \n",
      "12                     30.5882   \n",
      "13                     30.6471   \n",
      "14                     31.7059   \n",
      "15                     83.8235   \n",
      "16                     83.1176   \n",
      "17                     75.0588   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/23xt...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/vdnf...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/1hv9...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/oq4g...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/2ywr...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/2n8e...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/35ic...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/2cqg...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/mcfd...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/18y4...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/2at9...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/2yr7...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/4wef...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/1kfz...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/2eyl...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/3mkp...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/24p2...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/2v9m...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3   optimizer.args.lr-0.0003  \n",
      "4   optimizer.args.lr-0.0003  \n",
      "5   optimizer.args.lr-0.0003  \n",
      "6    optimizer.args.lr-0.001  \n",
      "7    optimizer.args.lr-0.001  \n",
      "8    optimizer.args.lr-0.001  \n",
      "9    optimizer.args.lr-0.003  \n",
      "10   optimizer.args.lr-0.003  \n",
      "11   optimizer.args.lr-0.003  \n",
      "12    optimizer.args.lr-0.01  \n",
      "13    optimizer.args.lr-0.01  \n",
      "14    optimizer.args.lr-0.01  \n",
      "15   optimizer.args.lr-3e-05  \n",
      "16   optimizer.args.lr-3e-05  \n",
      "17   optimizer.args.lr-3e-05  \n",
      "waterbirds                                     name  WATERBIRDS_VAL    WORST  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0         96.4352  48.7539   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1         96.1016  47.6636   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2         95.9652  36.7601   \n",
      "3   optimizer.args.lr-0.0003_seed-0_run0         94.4102  25.2336   \n",
      "4   optimizer.args.lr-0.0003_seed-1_run1         95.3812  23.3645   \n",
      "5   optimizer.args.lr-0.0003_seed-2_run2         91.2967   8.5670   \n",
      "6    optimizer.args.lr-0.001_seed-0_run0         92.0223  10.2804   \n",
      "7    optimizer.args.lr-0.001_seed-1_run1         92.2794  11.9938   \n",
      "8    optimizer.args.lr-0.001_seed-2_run2         89.2976   5.1402   \n",
      "9    optimizer.args.lr-0.003_seed-0_run0         88.2076   6.8536   \n",
      "10   optimizer.args.lr-0.003_seed-1_run1         88.5881   4.0498   \n",
      "11   optimizer.args.lr-0.003_seed-2_run2         89.8418   3.5826   \n",
      "12    optimizer.args.lr-0.01_seed-0_run0         89.7166   6.5421   \n",
      "13    optimizer.args.lr-0.01_seed-1_run1         89.2625   3.7383   \n",
      "14    optimizer.args.lr-0.01_seed-2_run2         89.3853   3.4268   \n",
      "15   optimizer.args.lr-3e-05_seed-0_run0         97.2577  61.6822   \n",
      "16   optimizer.args.lr-3e-05_seed-1_run1         97.1104  57.6324   \n",
      "17   optimizer.args.lr-3e-05_seed-2_run2         97.2989  68.0685   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/21nx...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/2ech...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/w69b...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/2c46...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/36q9...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/p95b...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/242a...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/1pwr...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/2ims...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/2txk...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/2kyy...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/123f...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/3s37...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/2dxs...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/3w52...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/39mq...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/1nca...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/3lj2...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3   optimizer.args.lr-0.0003  \n",
      "4   optimizer.args.lr-0.0003  \n",
      "5   optimizer.args.lr-0.0003  \n",
      "6    optimizer.args.lr-0.001  \n",
      "7    optimizer.args.lr-0.001  \n",
      "8    optimizer.args.lr-0.001  \n",
      "9    optimizer.args.lr-0.003  \n",
      "10   optimizer.args.lr-0.003  \n",
      "11   optimizer.args.lr-0.003  \n",
      "12    optimizer.args.lr-0.01  \n",
      "13    optimizer.args.lr-0.01  \n",
      "14    optimizer.args.lr-0.01  \n",
      "15   optimizer.args.lr-3e-05  \n",
      "16   optimizer.args.lr-3e-05  \n",
      "17   optimizer.args.lr-3e-05  \n",
      "domainnet                                     name  test_acc/sketch_val  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0              90.1626   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1              86.4527   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2              86.7028   \n",
      "3   optimizer.args.lr-0.0003_seed-0_run0              82.1175   \n",
      "4   optimizer.args.lr-0.0003_seed-1_run1              83.7015   \n",
      "5   optimizer.args.lr-0.0003_seed-2_run2              83.2430   \n",
      "6    optimizer.args.lr-0.001_seed-0_run0              73.3222   \n",
      "7    optimizer.args.lr-0.001_seed-1_run1              76.6569   \n",
      "8    optimizer.args.lr-0.001_seed-2_run2              74.6561   \n",
      "9    optimizer.args.lr-0.003_seed-0_run0              62.5677   \n",
      "10   optimizer.args.lr-0.003_seed-1_run1              62.3593   \n",
      "11   optimizer.args.lr-0.003_seed-2_run2              64.9437   \n",
      "12    optimizer.args.lr-0.01_seed-0_run0              29.8875   \n",
      "13    optimizer.args.lr-0.01_seed-1_run1              35.6398   \n",
      "14    optimizer.args.lr-0.01_seed-2_run2              29.4706   \n",
      "15   optimizer.args.lr-3e-05_seed-0_run0              93.2472   \n",
      "16   optimizer.args.lr-3e-05_seed-1_run1              93.0388   \n",
      "17   optimizer.args.lr-3e-05_seed-2_run2              80.1167   \n",
      "\n",
      "    test_acc/real_val                                          wandb_url  \\\n",
      "0             78.7556  https://wandb.ai/p-lambda/finetuning/runs/2nfv...   \n",
      "1             64.5398  https://wandb.ai/p-lambda/finetuning/runs/8up5...   \n",
      "2             64.7991  https://wandb.ai/p-lambda/finetuning/runs/63s4...   \n",
      "3             57.8568  https://wandb.ai/p-lambda/finetuning/runs/uc6x...   \n",
      "4             59.9885  https://wandb.ai/p-lambda/finetuning/runs/7fo3...   \n",
      "5             60.1037  https://wandb.ai/p-lambda/finetuning/runs/1ei6...   \n",
      "6             34.9129  https://wandb.ai/p-lambda/finetuning/runs/2dj0...   \n",
      "7             37.4190  https://wandb.ai/p-lambda/finetuning/runs/32j3...   \n",
      "8             38.4128  https://wandb.ai/p-lambda/finetuning/runs/24k1...   \n",
      "9             21.6765  https://wandb.ai/p-lambda/finetuning/runs/2wgz...   \n",
      "10            21.9790  https://wandb.ai/p-lambda/finetuning/runs/1ykm...   \n",
      "11            23.3617  https://wandb.ai/p-lambda/finetuning/runs/2yqb...   \n",
      "12            11.5944  https://wandb.ai/p-lambda/finetuning/runs/171u...   \n",
      "13            12.8331  https://wandb.ai/p-lambda/finetuning/runs/1vhn...   \n",
      "14            11.1335  https://wandb.ai/p-lambda/finetuning/runs/3bcv...   \n",
      "15            83.8398  https://wandb.ai/p-lambda/finetuning/runs/2uhu...   \n",
      "16            83.6238  https://wandb.ai/p-lambda/finetuning/runs/1cmw...   \n",
      "17            50.8714  https://wandb.ai/p-lambda/finetuning/runs/2iam...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3   optimizer.args.lr-0.0003  \n",
      "4   optimizer.args.lr-0.0003  \n",
      "5   optimizer.args.lr-0.0003  \n",
      "6    optimizer.args.lr-0.001  \n",
      "7    optimizer.args.lr-0.001  \n",
      "8    optimizer.args.lr-0.001  \n",
      "9    optimizer.args.lr-0.003  \n",
      "10   optimizer.args.lr-0.003  \n",
      "11   optimizer.args.lr-0.003  \n",
      "12    optimizer.args.lr-0.01  \n",
      "13    optimizer.args.lr-0.01  \n",
      "14    optimizer.args.lr-0.01  \n",
      "15   optimizer.args.lr-3e-05  \n",
      "16   optimizer.args.lr-3e-05  \n",
      "17   optimizer.args.lr-3e-05  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmow_all_nonorm_weakaugs                                     name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0          66.9337           65.3678   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1          65.0527           63.6103   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2          66.1413           64.9561   \n",
      "3   optimizer.args.lr-0.0003_seed-0_run0          67.8830           65.5084   \n",
      "4   optimizer.args.lr-0.0003_seed-1_run1          66.2632           64.6950   \n",
      "5   optimizer.args.lr-0.0003_seed-2_run2          66.7683           64.8104   \n",
      "6    optimizer.args.lr-0.001_seed-0_run0          63.3110           60.7432   \n",
      "7    optimizer.args.lr-0.001_seed-1_run1          63.6506           61.1097   \n",
      "8    optimizer.args.lr-0.001_seed-2_run2          62.5098           60.7381   \n",
      "9    optimizer.args.lr-0.003_seed-0_run0          53.3049           50.9114   \n",
      "10   optimizer.args.lr-0.003_seed-1_run1          53.9929           51.6646   \n",
      "11   optimizer.args.lr-0.003_seed-2_run2          45.8765           43.3241   \n",
      "12    optimizer.args.lr-0.01_seed-0_run0          27.7279           24.6397   \n",
      "13    optimizer.args.lr-0.01_seed-1_run1          27.0835           24.2732   \n",
      "14    optimizer.args.lr-0.01_seed-2_run2          26.4826           24.4389   \n",
      "15   optimizer.args.lr-3e-05_seed-0_run0          62.5446           61.4562   \n",
      "16   optimizer.args.lr-3e-05_seed-1_run1          61.6999           60.2109   \n",
      "17   optimizer.args.lr-3e-05_seed-2_run2          62.2747           61.9081   \n",
      "\n",
      "    test_acc/ood_test  test_acc/africa_test  \\\n",
      "0             58.5897               36.9456   \n",
      "1             57.1377               38.1026   \n",
      "2             57.7890               37.0999   \n",
      "3             58.4540               36.5600   \n",
      "4             57.6352               36.7528   \n",
      "5             57.7167               38.7196   \n",
      "6             53.7814               35.7115   \n",
      "7             53.7769               35.3259   \n",
      "8             52.7773               32.2021   \n",
      "9             44.1469               28.8083   \n",
      "10            43.7670               26.1088   \n",
      "11            36.0277               20.9410   \n",
      "12            20.8929               13.7293   \n",
      "13            19.8752               12.9194   \n",
      "14            19.9747               13.0351   \n",
      "15            55.8802               38.0640   \n",
      "16            54.3378               35.6344   \n",
      "17            56.0159               37.6012   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/1216...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/2ppo...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/qsjv...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/2un3...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/2b5f...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/e921...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/3bdt...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/11ws...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/1yhv...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/1m5g...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/2kp0...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/2kuy...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/3i5d...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/2iad...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/24wq...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/2d4r...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/1jhk...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/2b8g...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3   optimizer.args.lr-0.0003  \n",
      "4   optimizer.args.lr-0.0003  \n",
      "5   optimizer.args.lr-0.0003  \n",
      "6    optimizer.args.lr-0.001  \n",
      "7    optimizer.args.lr-0.001  \n",
      "8    optimizer.args.lr-0.001  \n",
      "9    optimizer.args.lr-0.003  \n",
      "10   optimizer.args.lr-0.003  \n",
      "11   optimizer.args.lr-0.003  \n",
      "12    optimizer.args.lr-0.01  \n",
      "13    optimizer.args.lr-0.01  \n",
      "14    optimizer.args.lr-0.01  \n",
      "15   optimizer.args.lr-3e-05  \n",
      "16   optimizer.args.lr-3e-05  \n",
      "17   optimizer.args.lr-3e-05  \n",
      "camelyon17_weakaugs                                     name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0          99.3772           89.6602   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1          99.3683           91.9092   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2          99.3951           91.7316   \n",
      "3   optimizer.args.lr-0.0003_seed-0_run0          99.1746           83.5320   \n",
      "4   optimizer.args.lr-0.0003_seed-1_run1          99.0793           79.4379   \n",
      "5   optimizer.args.lr-0.0003_seed-2_run2          99.0703           85.8240   \n",
      "6    optimizer.args.lr-0.001_seed-0_run0          98.7664           82.1854   \n",
      "7    optimizer.args.lr-0.001_seed-1_run1          98.7455           84.0248   \n",
      "8    optimizer.args.lr-0.001_seed-2_run2          98.3343           79.7874   \n",
      "9    optimizer.args.lr-0.003_seed-0_run0          98.2926           77.2089   \n",
      "10   optimizer.args.lr-0.003_seed-1_run1          98.3105           77.0284   \n",
      "11   optimizer.args.lr-0.003_seed-2_run2          98.3045           75.3610   \n",
      "12    optimizer.args.lr-0.01_seed-0_run0          98.1913           78.8935   \n",
      "13    optimizer.args.lr-0.01_seed-1_run1          98.2896           77.7103   \n",
      "14    optimizer.args.lr-0.01_seed-2_run2          97.9827           68.7428   \n",
      "15   optimizer.args.lr-3e-05_seed-0_run0          99.3117           94.1239   \n",
      "16   optimizer.args.lr-3e-05_seed-1_run1          99.2729           93.1297   \n",
      "17   optimizer.args.lr-3e-05_seed-2_run2          99.1836           89.9524   \n",
      "\n",
      "    test_acc/ood_test                                          wandb_url  \\\n",
      "0             85.8890  https://wandb.ai/p-lambda/finetuning/runs/3lgv...   \n",
      "1             88.0782  https://wandb.ai/p-lambda/finetuning/runs/9g01...   \n",
      "2             86.4192  https://wandb.ai/p-lambda/finetuning/runs/35sq...   \n",
      "3             69.5358  https://wandb.ai/p-lambda/finetuning/runs/3d0i...   \n",
      "4             68.4130  https://wandb.ai/p-lambda/finetuning/runs/37g3...   \n",
      "5             66.8152  https://wandb.ai/p-lambda/finetuning/runs/3cnf...   \n",
      "6             51.8812  https://wandb.ai/p-lambda/finetuning/runs/3ob1...   \n",
      "7             55.9492  https://wandb.ai/p-lambda/finetuning/runs/ffkb...   \n",
      "8             66.4225  https://wandb.ai/p-lambda/finetuning/runs/7roy...   \n",
      "9             48.2023  https://wandb.ai/p-lambda/finetuning/runs/2fap...   \n",
      "10            55.2919  https://wandb.ai/p-lambda/finetuning/runs/2931...   \n",
      "11            56.0079  https://wandb.ai/p-lambda/finetuning/runs/2gpp...   \n",
      "12            49.3604  https://wandb.ai/p-lambda/finetuning/runs/aydg...   \n",
      "13            65.4255  https://wandb.ai/p-lambda/finetuning/runs/28jo...   \n",
      "14            65.1398  https://wandb.ai/p-lambda/finetuning/runs/10v5...   \n",
      "15            94.1073  https://wandb.ai/p-lambda/finetuning/runs/2x55...   \n",
      "16            94.0614  https://wandb.ai/p-lambda/finetuning/runs/3rtu...   \n",
      "17            86.5039  https://wandb.ai/p-lambda/finetuning/runs/6wx0...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3   optimizer.args.lr-0.0003  \n",
      "4   optimizer.args.lr-0.0003  \n",
      "5   optimizer.args.lr-0.0003  \n",
      "6    optimizer.args.lr-0.001  \n",
      "7    optimizer.args.lr-0.001  \n",
      "8    optimizer.args.lr-0.001  \n",
      "9    optimizer.args.lr-0.003  \n",
      "10   optimizer.args.lr-0.003  \n",
      "11   optimizer.args.lr-0.003  \n",
      "12    optimizer.args.lr-0.01  \n",
      "13    optimizer.args.lr-0.01  \n",
      "14    optimizer.args.lr-0.01  \n",
      "15   optimizer.args.lr-3e-05  \n",
      "16   optimizer.args.lr-3e-05  \n",
      "17   optimizer.args.lr-3e-05  \n",
      "living17_nonorm                                     name  test_acc/source_val_living  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0                     82.5294   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1                     74.4118   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2                     74.1176   \n",
      "3    optimizer.args.lr-1e-05_seed-0_run0                     98.1176   \n",
      "4    optimizer.args.lr-1e-05_seed-1_run1                     97.8824   \n",
      "5    optimizer.args.lr-1e-05_seed-2_run2                     97.8824   \n",
      "6    optimizer.args.lr-1e-06_seed-0_run0                     97.6471   \n",
      "7    optimizer.args.lr-1e-06_seed-1_run1                     97.8824   \n",
      "8    optimizer.args.lr-1e-06_seed-2_run2                     98.2941   \n",
      "9    optimizer.args.lr-3e-05_seed-0_run0                     97.3529   \n",
      "10   optimizer.args.lr-3e-05_seed-1_run1                     96.8235   \n",
      "11   optimizer.args.lr-3e-05_seed-2_run2                     96.5882   \n",
      "12   optimizer.args.lr-3e-06_seed-0_run0                     98.0588   \n",
      "13   optimizer.args.lr-3e-06_seed-1_run1                     98.0588   \n",
      "14   optimizer.args.lr-3e-06_seed-2_run2                     98.1765   \n",
      "15   optimizer.args.lr-3e-07_seed-0_run0                     96.9412   \n",
      "16   optimizer.args.lr-3e-07_seed-1_run1                     97.2941   \n",
      "17   optimizer.args.lr-3e-07_seed-2_run2                     97.8235   \n",
      "\n",
      "    test_acc/target_val_living  \\\n",
      "0                      41.5294   \n",
      "1                      34.3529   \n",
      "2                      34.2941   \n",
      "3                      81.5294   \n",
      "4                      79.7059   \n",
      "5                      80.4118   \n",
      "6                      84.1765   \n",
      "7                      82.9412   \n",
      "8                      83.7059   \n",
      "9                      78.1176   \n",
      "10                     74.5294   \n",
      "11                     75.2941   \n",
      "12                     84.1765   \n",
      "13                     81.7647   \n",
      "14                     82.4706   \n",
      "15                     82.8824   \n",
      "16                     83.0000   \n",
      "17                     83.7647   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/bxpw...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/21xk...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/3nio...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/2f58...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/xnsv...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/2dtz...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/320l...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/icog...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/2q6p...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/2fhj...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/3kfd...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/1ryy...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/1czo...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/2e0r...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/3hxw...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/107a...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/14jd...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/1dl4...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3    optimizer.args.lr-1e-05  \n",
      "4    optimizer.args.lr-1e-05  \n",
      "5    optimizer.args.lr-1e-05  \n",
      "6    optimizer.args.lr-1e-06  \n",
      "7    optimizer.args.lr-1e-06  \n",
      "8    optimizer.args.lr-1e-06  \n",
      "9    optimizer.args.lr-3e-05  \n",
      "10   optimizer.args.lr-3e-05  \n",
      "11   optimizer.args.lr-3e-05  \n",
      "12   optimizer.args.lr-3e-06  \n",
      "13   optimizer.args.lr-3e-06  \n",
      "14   optimizer.args.lr-3e-06  \n",
      "15   optimizer.args.lr-3e-07  \n",
      "16   optimizer.args.lr-3e-07  \n",
      "17   optimizer.args.lr-3e-07  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waterbirds                                     name  WATERBIRDS_VAL    WORST  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0         89.5521   2.8037   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1         89.9072   6.2305   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2         88.8488   5.4517   \n",
      "3    optimizer.args.lr-1e-05_seed-0_run0         97.9436  69.3146   \n",
      "4    optimizer.args.lr-1e-05_seed-1_run1         97.4628  66.6667   \n",
      "5    optimizer.args.lr-1e-05_seed-2_run2         97.6901  68.5358   \n",
      "6    optimizer.args.lr-1e-06_seed-0_run0         97.3885  67.2897   \n",
      "7    optimizer.args.lr-1e-06_seed-1_run1         97.3596  70.7165   \n",
      "8    optimizer.args.lr-1e-06_seed-2_run2         97.6066  64.1745   \n",
      "9    optimizer.args.lr-3e-05_seed-0_run0         97.0159  53.5826   \n",
      "10   optimizer.args.lr-3e-05_seed-1_run1         96.7293  43.6137   \n",
      "11   optimizer.args.lr-3e-05_seed-2_run2         96.9287  48.5981   \n",
      "12   optimizer.args.lr-3e-06_seed-0_run0         97.7807  69.3146   \n",
      "13   optimizer.args.lr-3e-06_seed-1_run1         97.7180  74.2991   \n",
      "14   optimizer.args.lr-3e-06_seed-2_run2         97.7429  71.9626   \n",
      "15   optimizer.args.lr-3e-07_seed-0_run0         96.8930  56.8536   \n",
      "16   optimizer.args.lr-3e-07_seed-1_run1         97.0290  67.6012   \n",
      "17   optimizer.args.lr-3e-07_seed-2_run2         97.2621  64.4860   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/1q9q...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/2pim...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/i3p7...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/6jgf...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/epno...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/3bkh...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/7jaa...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/18r2...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/3p0v...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/30gn...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/3dv5...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/lejn...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/2a7x...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/2xwh...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/4t60...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/1eam...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/18yv...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/1p12...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3    optimizer.args.lr-1e-05  \n",
      "4    optimizer.args.lr-1e-05  \n",
      "5    optimizer.args.lr-1e-05  \n",
      "6    optimizer.args.lr-1e-06  \n",
      "7    optimizer.args.lr-1e-06  \n",
      "8    optimizer.args.lr-1e-06  \n",
      "9    optimizer.args.lr-3e-05  \n",
      "10   optimizer.args.lr-3e-05  \n",
      "11   optimizer.args.lr-3e-05  \n",
      "12   optimizer.args.lr-3e-06  \n",
      "13   optimizer.args.lr-3e-06  \n",
      "14   optimizer.args.lr-3e-06  \n",
      "15   optimizer.args.lr-3e-07  \n",
      "16   optimizer.args.lr-3e-07  \n",
      "17   optimizer.args.lr-3e-07  \n",
      "domainnet                                     name  test_acc/sketch_val  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0              52.9804   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1              33.5556   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2              40.3918   \n",
      "3    optimizer.args.lr-1e-05_seed-0_run0              94.5394   \n",
      "4    optimizer.args.lr-1e-05_seed-1_run1              94.6644   \n",
      "5    optimizer.args.lr-1e-05_seed-2_run2              94.0392   \n",
      "6    optimizer.args.lr-1e-06_seed-0_run0              94.3310   \n",
      "7    optimizer.args.lr-1e-06_seed-1_run1              94.1642   \n",
      "8    optimizer.args.lr-1e-06_seed-2_run2              93.4973   \n",
      "9    optimizer.args.lr-3e-05_seed-0_run0              91.0796   \n",
      "10   optimizer.args.lr-3e-05_seed-1_run1              91.2047   \n",
      "11   optimizer.args.lr-3e-05_seed-2_run2              90.8712   \n",
      "12   optimizer.args.lr-3e-06_seed-0_run0              95.0396   \n",
      "13   optimizer.args.lr-3e-06_seed-1_run1              94.9145   \n",
      "14   optimizer.args.lr-3e-06_seed-2_run2              95.0396   \n",
      "15   optimizer.args.lr-3e-07_seed-0_run0              92.2468   \n",
      "16   optimizer.args.lr-3e-07_seed-1_run1              91.9133   \n",
      "17   optimizer.args.lr-3e-07_seed-2_run2              91.9967   \n",
      "\n",
      "    test_acc/real_val                                          wandb_url  \\\n",
      "0             16.9811  https://wandb.ai/p-lambda/finetuning/runs/232h...   \n",
      "1             11.7817  https://wandb.ai/p-lambda/finetuning/runs/2sx2...   \n",
      "2             13.2220  https://wandb.ai/p-lambda/finetuning/runs/3i7o...   \n",
      "3             88.5352  https://wandb.ai/p-lambda/finetuning/runs/1wdb...   \n",
      "4             88.9241  https://wandb.ai/p-lambda/finetuning/runs/p66t...   \n",
      "5             88.0455  https://wandb.ai/p-lambda/finetuning/runs/kemg...   \n",
      "6             85.1937  https://wandb.ai/p-lambda/finetuning/runs/h6og...   \n",
      "7             84.1567  https://wandb.ai/p-lambda/finetuning/runs/sw9z...   \n",
      "8             85.3810  https://wandb.ai/p-lambda/finetuning/runs/1hc8...   \n",
      "9             75.6589  https://wandb.ai/p-lambda/finetuning/runs/3ue3...   \n",
      "10            76.4799  https://wandb.ai/p-lambda/finetuning/runs/3gl6...   \n",
      "11            78.2947  https://wandb.ai/p-lambda/finetuning/runs/t7sx...   \n",
      "12            90.5516  https://wandb.ai/p-lambda/finetuning/runs/1gon...   \n",
      "13            88.6216  https://wandb.ai/p-lambda/finetuning/runs/318v...   \n",
      "14            88.3336  https://wandb.ai/p-lambda/finetuning/runs/12xq...   \n",
      "15            82.2699  https://wandb.ai/p-lambda/finetuning/runs/4ndp...   \n",
      "16            81.3769  https://wandb.ai/p-lambda/finetuning/runs/12m4...   \n",
      "17            81.6938  https://wandb.ai/p-lambda/finetuning/runs/37vl...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3    optimizer.args.lr-1e-05  \n",
      "4    optimizer.args.lr-1e-05  \n",
      "5    optimizer.args.lr-1e-05  \n",
      "6    optimizer.args.lr-1e-06  \n",
      "7    optimizer.args.lr-1e-06  \n",
      "8    optimizer.args.lr-1e-06  \n",
      "9    optimizer.args.lr-3e-05  \n",
      "10   optimizer.args.lr-3e-05  \n",
      "11   optimizer.args.lr-3e-05  \n",
      "12   optimizer.args.lr-3e-06  \n",
      "13   optimizer.args.lr-3e-06  \n",
      "14   optimizer.args.lr-3e-06  \n",
      "15   optimizer.args.lr-3e-07  \n",
      "16   optimizer.args.lr-3e-07  \n",
      "17   optimizer.args.lr-3e-07  \n",
      "fmow_all_nonorm_weakaugs                                     name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0          33.5452           30.7658   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1          34.5728           32.1818   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2          35.5221           33.1860   \n",
      "3    optimizer.args.lr-1e-05_seed-0_run0          70.2778           67.7831   \n",
      "4    optimizer.args.lr-1e-05_seed-1_run1          69.8424           67.5370   \n",
      "5    optimizer.args.lr-1e-05_seed-2_run2          70.2343           68.0542   \n",
      "6    optimizer.args.lr-1e-06_seed-0_run0          62.6578           61.0545   \n",
      "7    optimizer.args.lr-1e-06_seed-1_run1          62.2921           60.5172   \n",
      "8    optimizer.args.lr-1e-06_seed-2_run2          62.0482           61.0495   \n",
      "9    optimizer.args.lr-3e-05_seed-0_run0          68.3968           66.0507   \n",
      "10   optimizer.args.lr-3e-05_seed-1_run1          68.5535           66.2064   \n",
      "11   optimizer.args.lr-3e-05_seed-2_run2          68.9280           66.2315   \n",
      "12   optimizer.args.lr-3e-06_seed-0_run0          67.7872           65.5687   \n",
      "13   optimizer.args.lr-3e-06_seed-1_run1          68.1094           65.7695   \n",
      "14   optimizer.args.lr-3e-06_seed-2_run2          68.5100           66.0357   \n",
      "15   optimizer.args.lr-3e-07_seed-0_run0          47.9666           48.1195   \n",
      "16   optimizer.args.lr-3e-07_seed-1_run1          47.3570           46.7386   \n",
      "17   optimizer.args.lr-3e-07_seed-2_run2          48.0624           47.9588   \n",
      "\n",
      "    test_acc/ood_test  test_acc/africa_test  \\\n",
      "0             25.9499               17.0459   \n",
      "1             26.7595               16.5831   \n",
      "2             27.3430               16.9688   \n",
      "3             61.5298               40.8407   \n",
      "4             60.8196               40.8793   \n",
      "5             61.3850               40.2622   \n",
      "6             55.1294               37.6398   \n",
      "7             54.2699               36.7914   \n",
      "8             55.6902               37.9869   \n",
      "9             58.9696               38.1797   \n",
      "10            59.0058               39.2981   \n",
      "11            58.7977               38.1026   \n",
      "12            58.6665               38.4882   \n",
      "13            59.0646               41.8049   \n",
      "14            59.2772               41.1107   \n",
      "15            43.7896               32.0478   \n",
      "16            42.0843               29.4639   \n",
      "17            43.4006               31.8936   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/2ctt...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/2c18...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/dcqz...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/1ft8...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/2kb5...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/24m2...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/m7tk...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/50fj...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/92oa...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/3jhw...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/2reh...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/3jb3...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/xmr9...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/amzd...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/1z3l...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/3b7x...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/zty5...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/ga5d...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3    optimizer.args.lr-1e-05  \n",
      "4    optimizer.args.lr-1e-05  \n",
      "5    optimizer.args.lr-1e-05  \n",
      "6    optimizer.args.lr-1e-06  \n",
      "7    optimizer.args.lr-1e-06  \n",
      "8    optimizer.args.lr-1e-06  \n",
      "9    optimizer.args.lr-3e-05  \n",
      "10   optimizer.args.lr-3e-05  \n",
      "11   optimizer.args.lr-3e-05  \n",
      "12   optimizer.args.lr-3e-06  \n",
      "13   optimizer.args.lr-3e-06  \n",
      "14   optimizer.args.lr-3e-06  \n",
      "15   optimizer.args.lr-3e-07  \n",
      "16   optimizer.args.lr-3e-07  \n",
      "17   optimizer.args.lr-3e-07  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelyon17_weakaugs                                     name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0   optimizer.args.lr-0.0001_seed-0_run0          98.4237           78.4065   \n",
      "1   optimizer.args.lr-0.0001_seed-1_run1          98.3045           79.9851   \n",
      "2   optimizer.args.lr-0.0001_seed-2_run2          97.5387           76.1517   \n",
      "3    optimizer.args.lr-1e-05_seed-0_run0          99.4458           91.2102   \n",
      "4    optimizer.args.lr-1e-05_seed-1_run1          99.4160           91.2847   \n",
      "5    optimizer.args.lr-1e-05_seed-2_run2          99.4190           89.3594   \n",
      "6    optimizer.args.lr-1e-06_seed-0_run0          99.4249           94.7886   \n",
      "7    optimizer.args.lr-1e-06_seed-1_run1          99.5143           93.6110   \n",
      "8    optimizer.args.lr-1e-06_seed-2_run2          99.5083           94.2757   \n",
      "9    optimizer.args.lr-3e-05_seed-0_run0          99.1359           87.5659   \n",
      "10   optimizer.args.lr-3e-05_seed-1_run1          98.9988           84.8413   \n",
      "11   optimizer.args.lr-3e-05_seed-2_run2          98.6323           79.1342   \n",
      "12   optimizer.args.lr-3e-06_seed-0_run0          99.5679           94.3474   \n",
      "13   optimizer.args.lr-3e-06_seed-1_run1          99.5322           94.4734   \n",
      "14   optimizer.args.lr-3e-06_seed-2_run2          99.5352           93.7514   \n",
      "15   optimizer.args.lr-3e-07_seed-0_run0          99.2878           94.5479   \n",
      "16   optimizer.args.lr-3e-07_seed-1_run1          99.2938           92.8547   \n",
      "17   optimizer.args.lr-3e-07_seed-2_run2          99.3117           92.5940   \n",
      "\n",
      "    test_acc/ood_test                                          wandb_url  \\\n",
      "0             63.7560  https://wandb.ai/p-lambda/finetuning/runs/2zux...   \n",
      "1             61.7337  https://wandb.ai/p-lambda/finetuning/runs/umt6...   \n",
      "2             59.0942  https://wandb.ai/p-lambda/finetuning/runs/3pci...   \n",
      "3             91.5183  https://wandb.ai/p-lambda/finetuning/runs/8eai...   \n",
      "4             92.0686  https://wandb.ai/p-lambda/finetuning/runs/2d88...   \n",
      "5             93.1032  https://wandb.ai/p-lambda/finetuning/runs/11gy...   \n",
      "6             96.6010  https://wandb.ai/p-lambda/finetuning/runs/183o...   \n",
      "7             95.6216  https://wandb.ai/p-lambda/finetuning/runs/e8e7...   \n",
      "8             96.6798  https://wandb.ai/p-lambda/finetuning/runs/10zp...   \n",
      "9             81.5952  https://wandb.ai/p-lambda/finetuning/runs/2g31...   \n",
      "10            82.3700  https://wandb.ai/p-lambda/finetuning/runs/2v1i...   \n",
      "11            64.1933  https://wandb.ai/p-lambda/finetuning/runs/17xu...   \n",
      "12            95.9720  https://wandb.ai/p-lambda/finetuning/runs/3bn2...   \n",
      "13            95.1819  https://wandb.ai/p-lambda/finetuning/runs/23om...   \n",
      "14            96.0237  https://wandb.ai/p-lambda/finetuning/runs/2v57...   \n",
      "15            94.0403  https://wandb.ai/p-lambda/finetuning/runs/2502...   \n",
      "16            94.8492  https://wandb.ai/p-lambda/finetuning/runs/14ml...   \n",
      "17            94.7986  https://wandb.ai/p-lambda/finetuning/runs/36bk...   \n",
      "\n",
      "                       group  \n",
      "0   optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-0.0001  \n",
      "2   optimizer.args.lr-0.0001  \n",
      "3    optimizer.args.lr-1e-05  \n",
      "4    optimizer.args.lr-1e-05  \n",
      "5    optimizer.args.lr-1e-05  \n",
      "6    optimizer.args.lr-1e-06  \n",
      "7    optimizer.args.lr-1e-06  \n",
      "8    optimizer.args.lr-1e-06  \n",
      "9    optimizer.args.lr-3e-05  \n",
      "10   optimizer.args.lr-3e-05  \n",
      "11   optimizer.args.lr-3e-05  \n",
      "12   optimizer.args.lr-3e-06  \n",
      "13   optimizer.args.lr-3e-06  \n",
      "14   optimizer.args.lr-3e-06  \n",
      "15   optimizer.args.lr-3e-07  \n",
      "16   optimizer.args.lr-3e-07  \n",
      "17   optimizer.args.lr-3e-07  \n",
      "living17_nonorm                                                  name  \\\n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...   \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...   \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...   \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...   \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...   \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...   \n",
      "6   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...   \n",
      "7   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...   \n",
      "8   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...   \n",
      "9   freeze_bottom_k-2_optimizer.args.lr-0.003_seed...   \n",
      "10  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...   \n",
      "11  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...   \n",
      "12  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...   \n",
      "13  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...   \n",
      "14  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...   \n",
      "15  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...   \n",
      "16  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...   \n",
      "17  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...   \n",
      "\n",
      "    test_acc/source_val_living  test_acc/target_val_living  \\\n",
      "0                      97.8235                     83.7647   \n",
      "1                      98.3529                     82.1765   \n",
      "2                      98.2941                     83.5882   \n",
      "3                      98.1176                     80.7059   \n",
      "4                      97.8824                     81.8235   \n",
      "5                      98.1765                     81.0000   \n",
      "6                      97.8824                     79.4706   \n",
      "7                      97.8235                     77.1765   \n",
      "8                      97.4706                     78.1765   \n",
      "9                      97.2353                     74.1176   \n",
      "10                     95.7059                     69.5882   \n",
      "11                     95.7059                     71.1765   \n",
      "12                     94.5882                     63.7647   \n",
      "13                     88.9412                     50.7647   \n",
      "14                     87.4706                     47.5294   \n",
      "15                     97.7059                     84.1765   \n",
      "16                     97.8235                     82.4118   \n",
      "17                     98.2353                     84.1176   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/cjnc...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/37b2...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/168z...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/2sg5...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/3df8...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/2sgu...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/2bmu...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/3jd6...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/3ayf...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/24mp...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/151t...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/338h...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/1e4k...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/1ooi...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/meox...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/23jc...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/30ne...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/2zk0...   \n",
      "\n",
      "                                         group  \n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "6    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "7    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "8    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "9    freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "10   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "11   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "12    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "13    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "14    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "15   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "16   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "17   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "waterbirds                                                  name  WATERBIRDS_VAL  \\\n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...         97.6151   \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...         97.7998   \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...         97.6586   \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...         97.8519   \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...         97.8297   \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...         97.7370   \n",
      "6   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...         97.7858   \n",
      "7   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...         97.2823   \n",
      "8   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...         97.4715   \n",
      "9   freeze_bottom_k-2_optimizer.args.lr-0.003_seed...         96.2965   \n",
      "10  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...         96.4551   \n",
      "11  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...         92.0653   \n",
      "12  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...         90.0736   \n",
      "13  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...         90.7563   \n",
      "14  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...         92.3953   \n",
      "15  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...         97.3644   \n",
      "16  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...         97.1726   \n",
      "17  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...         97.3713   \n",
      "\n",
      "      WORST                                          wandb_url  \\\n",
      "0   71.9626  https://wandb.ai/p-lambda/finetuning/runs/2w3y...   \n",
      "1   75.8567  https://wandb.ai/p-lambda/finetuning/runs/2qf0...   \n",
      "2   67.7570  https://wandb.ai/p-lambda/finetuning/runs/1zf0...   \n",
      "3   73.0530  https://wandb.ai/p-lambda/finetuning/runs/3z79...   \n",
      "4   73.0530  https://wandb.ai/p-lambda/finetuning/runs/3hg2...   \n",
      "5   75.0779  https://wandb.ai/p-lambda/finetuning/runs/j7im...   \n",
      "6   66.9782  https://wandb.ai/p-lambda/finetuning/runs/3e8b...   \n",
      "7   71.0280  https://wandb.ai/p-lambda/finetuning/runs/kqer...   \n",
      "8   57.7882  https://wandb.ai/p-lambda/finetuning/runs/3tte...   \n",
      "9   40.4984  https://wandb.ai/p-lambda/finetuning/runs/1h6c...   \n",
      "10  46.8847  https://wandb.ai/p-lambda/finetuning/runs/102j...   \n",
      "11  13.2399  https://wandb.ai/p-lambda/finetuning/runs/2ckq...   \n",
      "12   9.6573  https://wandb.ai/p-lambda/finetuning/runs/208v...   \n",
      "13   5.6075  https://wandb.ai/p-lambda/finetuning/runs/3mci...   \n",
      "14   9.3458  https://wandb.ai/p-lambda/finetuning/runs/4p8p...   \n",
      "15  67.2897  https://wandb.ai/p-lambda/finetuning/runs/17ng...   \n",
      "16  72.2741  https://wandb.ai/p-lambda/finetuning/runs/522l...   \n",
      "17  73.5202  https://wandb.ai/p-lambda/finetuning/runs/156a...   \n",
      "\n",
      "                                         group  \n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "6    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "7    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "8    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "9    freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "10   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "11   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "12    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "13    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "14    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "15   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "16   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "17   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domainnet                                                  name  test_acc/sketch_val  \\\n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...              95.1647   \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...              94.6228   \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...              94.9562   \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...              94.4977   \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...              94.5394   \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...              94.4977   \n",
      "6   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...              90.7461   \n",
      "7   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...              90.3710   \n",
      "8   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...              92.3718   \n",
      "9   freeze_bottom_k-2_optimizer.args.lr-0.003_seed...              84.1601   \n",
      "10  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...              85.5356   \n",
      "11  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...              85.7024   \n",
      "12  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...              70.9045   \n",
      "13  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...              68.8203   \n",
      "14  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...              66.9862   \n",
      "15  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...              93.9975   \n",
      "16  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...              94.2476   \n",
      "17  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...              94.1226   \n",
      "\n",
      "    test_acc/real_val                                          wandb_url  \\\n",
      "0             89.0249  https://wandb.ai/p-lambda/finetuning/runs/1hdc...   \n",
      "1             88.0743  https://wandb.ai/p-lambda/finetuning/runs/3m8c...   \n",
      "2             87.5846  https://wandb.ai/p-lambda/finetuning/runs/31rn...   \n",
      "3             87.4838  https://wandb.ai/p-lambda/finetuning/runs/1vfm...   \n",
      "4             86.7780  https://wandb.ai/p-lambda/finetuning/runs/2uic...   \n",
      "5             89.0249  https://wandb.ai/p-lambda/finetuning/runs/3meu...   \n",
      "6             72.2886  https://wandb.ai/p-lambda/finetuning/runs/3ea0...   \n",
      "7             76.2207  https://wandb.ai/p-lambda/finetuning/runs/dp9h...   \n",
      "8             75.6157  https://wandb.ai/p-lambda/finetuning/runs/b7nx...   \n",
      "9             54.9906  https://wandb.ai/p-lambda/finetuning/runs/3leh...   \n",
      "10            58.0009  https://wandb.ai/p-lambda/finetuning/runs/3gge...   \n",
      "11            56.0853  https://wandb.ai/p-lambda/finetuning/runs/1nu1...   \n",
      "12            32.6228  https://wandb.ai/p-lambda/finetuning/runs/2qr4...   \n",
      "13            30.6640  https://wandb.ai/p-lambda/finetuning/runs/c1ft...   \n",
      "14            29.8574  https://wandb.ai/p-lambda/finetuning/runs/wsxh...   \n",
      "15            85.5250  https://wandb.ai/p-lambda/finetuning/runs/rq4v...   \n",
      "16            84.6464  https://wandb.ai/p-lambda/finetuning/runs/33zi...   \n",
      "17            86.0291  https://wandb.ai/p-lambda/finetuning/runs/yjxd...   \n",
      "\n",
      "                                         group  \n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "6    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "7    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "8    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "9    freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "10   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "11   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "12    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "13    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "14    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "15   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "16   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "17   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "fmow_all_nonorm_weakaugs                                                  name  test_acc/id_val  \\\n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...          68.4577   \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...          68.5013   \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...          68.7712   \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...          70.2604   \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...          69.9643   \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...          69.7814   \n",
      "6   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...          69.6247   \n",
      "7   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...          68.4926   \n",
      "8   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...          68.8148   \n",
      "9   freeze_bottom_k-2_optimizer.args.lr-0.003_seed...          65.1311   \n",
      "10  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...          65.4533   \n",
      "11  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...          65.0962   \n",
      "12  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...          53.3397   \n",
      "13  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...          48.2714   \n",
      "14  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...          53.8361   \n",
      "15  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...          64.0512   \n",
      "16  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...          63.8857   \n",
      "17  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...          63.7551   \n",
      "\n",
      "    test_acc/ood_val  test_acc/ood_test  test_acc/africa_test  \\\n",
      "0            66.3871            59.8471               39.7995   \n",
      "1            65.8197            58.8294               39.7609   \n",
      "2            66.0909            59.0601               40.3008   \n",
      "3            67.7128            60.8422               39.5681   \n",
      "4            66.8391            59.9602               39.9923   \n",
      "5            67.2458            60.5527               40.9950   \n",
      "6            66.5328            59.5893               38.1797   \n",
      "7            65.9352            59.0827               35.9815   \n",
      "8            66.5478            59.2953               38.1026   \n",
      "9            62.9224            55.6767               35.6344   \n",
      "10           62.5860            55.0887               34.8631   \n",
      "11           62.8722            55.1746               34.1689   \n",
      "12           50.7256            44.1514               30.3509   \n",
      "13           44.7703            37.7510               23.9491   \n",
      "14           51.9257            43.8936               25.1446   \n",
      "15           62.0587            55.4641               36.9456   \n",
      "16           61.6621            54.8534               37.2541   \n",
      "17           61.9382            55.9028               37.7169   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/3eni...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/2sgj...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/3tel...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/1cr0...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/1hvg...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/3lh6...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/w8ll...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/rwap...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/3kbr...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/2s21...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/1glt...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/3iis...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/rw88...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/18ab...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/1pou...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/o8u7...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/1dyr...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/iqb4...   \n",
      "\n",
      "                                         group  \n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "6    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "7    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "8    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "9    freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "10   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "11   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "12    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "13    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "14    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "15   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "16   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "17   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelyon17_weakaugs                                                  name  test_acc/id_val  \\\n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...          99.5143   \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...          99.5083   \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001_see...          99.5203   \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...          99.5322   \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...          99.5173   \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003_see...          99.5292   \n",
      "6   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...          99.4458   \n",
      "7   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...          99.3802   \n",
      "8   freeze_bottom_k-2_optimizer.args.lr-0.001_seed...          99.4219   \n",
      "9   freeze_bottom_k-2_optimizer.args.lr-0.003_seed...          99.2223   \n",
      "10  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...          97.6698   \n",
      "11  freeze_bottom_k-2_optimizer.args.lr-0.003_seed...          98.6532   \n",
      "12  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...          97.8784   \n",
      "13  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...          97.9082   \n",
      "14  freeze_bottom_k-2_optimizer.args.lr-0.01_seed-...          97.9350   \n",
      "15  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...          99.4398   \n",
      "16  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...          99.3534   \n",
      "17  freeze_bottom_k-2_optimizer.args.lr-3e-05_seed...          99.4547   \n",
      "\n",
      "    test_acc/ood_val  test_acc/ood_test  \\\n",
      "0            94.8802            94.8797   \n",
      "1            93.0753            95.7274   \n",
      "2            94.0952            96.1495   \n",
      "3            93.7858            93.9603   \n",
      "4            93.1555            94.6446   \n",
      "5            93.3102            94.2683   \n",
      "6            91.5683            89.2656   \n",
      "7            91.4021            92.6952   \n",
      "8            91.6055            90.1968   \n",
      "9            85.6177            69.5993   \n",
      "10           79.7043            70.1695   \n",
      "11           79.2603            63.3668   \n",
      "12           72.2381            58.2947   \n",
      "13           76.4096            56.8027   \n",
      "14           77.0284            68.2390   \n",
      "15           94.0007            95.9567   \n",
      "16           94.5966            94.4659   \n",
      "17           93.7342            95.9073   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/niyx...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/3pj2...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/3pqw...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/1rxa...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/247u...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/ujrs...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/1smz...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/23j5...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/1qtj...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/42jz...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/m57o...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/3oov...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/3iew...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/3qxp...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/1i5f...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/wuhs...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/37r8...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/2rqw...   \n",
      "\n",
      "                                         group  \n",
      "0   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "1   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "2   freeze_bottom_k-2_optimizer.args.lr-0.0001  \n",
      "3   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "4   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "5   freeze_bottom_k-2_optimizer.args.lr-0.0003  \n",
      "6    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "7    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "8    freeze_bottom_k-2_optimizer.args.lr-0.001  \n",
      "9    freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "10   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "11   freeze_bottom_k-2_optimizer.args.lr-0.003  \n",
      "12    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "13    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "14    freeze_bottom_k-2_optimizer.args.lr-0.01  \n",
      "15   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "16   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "17   freeze_bottom_k-2_optimizer.args.lr-3e-05  \n",
      "living17_nonorm                                                  name  \\\n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001_...   \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001_...   \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001_...   \n",
      "3   layer-wise-tune-True_optimizer.args.lr-1e-05_s...   \n",
      "4   layer-wise-tune-True_optimizer.args.lr-1e-05_s...   \n",
      "5   layer-wise-tune-True_optimizer.args.lr-1e-05_s...   \n",
      "6   layer-wise-tune-True_optimizer.args.lr-1e-06_s...   \n",
      "7   layer-wise-tune-True_optimizer.args.lr-1e-06_s...   \n",
      "8   layer-wise-tune-True_optimizer.args.lr-1e-06_s...   \n",
      "9   layer-wise-tune-True_optimizer.args.lr-3e-05_s...   \n",
      "10  layer-wise-tune-True_optimizer.args.lr-3e-05_s...   \n",
      "11  layer-wise-tune-True_optimizer.args.lr-3e-05_s...   \n",
      "12  layer-wise-tune-True_optimizer.args.lr-3e-06_s...   \n",
      "13  layer-wise-tune-True_optimizer.args.lr-3e-06_s...   \n",
      "14  layer-wise-tune-True_optimizer.args.lr-3e-06_s...   \n",
      "15  layer-wise-tune-True_optimizer.args.lr-3e-07_s...   \n",
      "16  layer-wise-tune-True_optimizer.args.lr-3e-07_s...   \n",
      "17  layer-wise-tune-True_optimizer.args.lr-3e-07_s...   \n",
      "\n",
      "    test_acc/source_val_living  test_acc/target_val_living  \\\n",
      "0                      98.1765                     80.4706   \n",
      "1                      98.3529                     83.0000   \n",
      "2                      97.9412                     79.3529   \n",
      "3                      98.1765                     83.4706   \n",
      "4                      98.1765                     85.7059   \n",
      "5                      98.0588                     84.4118   \n",
      "6                      97.8235                     87.6471   \n",
      "7                      97.7647                     87.6471   \n",
      "8                      97.7647                     87.7059   \n",
      "9                      98.2353                     81.8824   \n",
      "10                     98.2941                     81.8235   \n",
      "11                     98.4118                     82.0000   \n",
      "12                     98.0588                     85.5294   \n",
      "13                     98.0000                     86.4706   \n",
      "14                     97.9412                     86.1765   \n",
      "15                     97.3529                     86.6471   \n",
      "16                     97.1765                     87.4118   \n",
      "17                     97.4118                     87.2941   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/3002...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/137p...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/in9f...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/1vca...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/wec9...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/3rqg...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/33lf...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/uspk...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/229d...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/2moq...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/1a5r...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/2sxl...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/3fdk...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/1wgh...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/2dox...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/3n5n...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/3kdx...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/2auy...   \n",
      "\n",
      "                                            group  \n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "3    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "4    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "5    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "6    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "7    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "8    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "9    layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "10   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "11   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "12   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "13   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "14   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "15   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "16   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "17   layer-wise-tune-True_optimizer.args.lr-3e-07  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waterbirds                                                  name  WATERBIRDS_VAL  \\\n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001_...         98.2763   \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001_...         98.2581   \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001_...         98.3464   \n",
      "3   layer-wise-tune-True_optimizer.args.lr-1e-05_s...         98.0542   \n",
      "4   layer-wise-tune-True_optimizer.args.lr-1e-05_s...         97.8983   \n",
      "5   layer-wise-tune-True_optimizer.args.lr-1e-05_s...         97.9775   \n",
      "6   layer-wise-tune-True_optimizer.args.lr-1e-06_s...         97.3154   \n",
      "7   layer-wise-tune-True_optimizer.args.lr-1e-06_s...         97.3131   \n",
      "8   layer-wise-tune-True_optimizer.args.lr-1e-06_s...         97.2459   \n",
      "9   layer-wise-tune-True_optimizer.args.lr-3e-05_s...         98.2068   \n",
      "10  layer-wise-tune-True_optimizer.args.lr-3e-05_s...         98.1980   \n",
      "11  layer-wise-tune-True_optimizer.args.lr-3e-05_s...         98.0882   \n",
      "12  layer-wise-tune-True_optimizer.args.lr-3e-06_s...         97.5852   \n",
      "13  layer-wise-tune-True_optimizer.args.lr-3e-06_s...         97.4949   \n",
      "14  layer-wise-tune-True_optimizer.args.lr-3e-06_s...         97.5619   \n",
      "15  layer-wise-tune-True_optimizer.args.lr-3e-07_s...         96.8196   \n",
      "16  layer-wise-tune-True_optimizer.args.lr-3e-07_s...         96.9204   \n",
      "17  layer-wise-tune-True_optimizer.args.lr-3e-07_s...         96.9769   \n",
      "\n",
      "      WORST                                          wandb_url  \\\n",
      "0   71.4953  https://wandb.ai/p-lambda/finetuning/runs/2be5...   \n",
      "1   64.9533  https://wandb.ai/p-lambda/finetuning/runs/3s7t...   \n",
      "2   70.7165  https://wandb.ai/p-lambda/finetuning/runs/w5h7...   \n",
      "3   76.1682  https://wandb.ai/p-lambda/finetuning/runs/qaxr...   \n",
      "4   78.6604  https://wandb.ai/p-lambda/finetuning/runs/1ss9...   \n",
      "5   77.5701  https://wandb.ai/p-lambda/finetuning/runs/15wn...   \n",
      "6   72.4299  https://wandb.ai/p-lambda/finetuning/runs/23pq...   \n",
      "7   71.9626  https://wandb.ai/p-lambda/finetuning/runs/93k6...   \n",
      "8   70.0935  https://wandb.ai/p-lambda/finetuning/runs/28g3...   \n",
      "9   76.0125  https://wandb.ai/p-lambda/finetuning/runs/76s1...   \n",
      "10  74.1433  https://wandb.ai/p-lambda/finetuning/runs/1bos...   \n",
      "11  65.8879  https://wandb.ai/p-lambda/finetuning/runs/3b9z...   \n",
      "12  74.2991  https://wandb.ai/p-lambda/finetuning/runs/3n5j...   \n",
      "13  76.4798  https://wandb.ai/p-lambda/finetuning/runs/1r58...   \n",
      "14  75.0779  https://wandb.ai/p-lambda/finetuning/runs/21mt...   \n",
      "15  52.0249  https://wandb.ai/p-lambda/finetuning/runs/veh2...   \n",
      "16  53.8941  https://wandb.ai/p-lambda/finetuning/runs/2adf...   \n",
      "17  51.4019  https://wandb.ai/p-lambda/finetuning/runs/2mlb...   \n",
      "\n",
      "                                            group  \n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "3    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "4    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "5    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "6    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "7    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "8    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "9    layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "10   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "11   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "12   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "13   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "14   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "15   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "16   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "17   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "domainnet                                                  name  test_acc/sketch_val  \\\n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001_...              95.4981   \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001_...              95.4148   \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001_...              95.2897   \n",
      "3   layer-wise-tune-True_optimizer.args.lr-1e-05_s...              96.2901   \n",
      "4   layer-wise-tune-True_optimizer.args.lr-1e-05_s...              96.4152   \n",
      "5   layer-wise-tune-True_optimizer.args.lr-1e-05_s...              96.2068   \n",
      "6   layer-wise-tune-True_optimizer.args.lr-1e-06_s...              93.3722   \n",
      "7   layer-wise-tune-True_optimizer.args.lr-1e-06_s...              93.2472   \n",
      "8   layer-wise-tune-True_optimizer.args.lr-1e-06_s...              93.2889   \n",
      "9   layer-wise-tune-True_optimizer.args.lr-3e-05_s...              95.8733   \n",
      "10  layer-wise-tune-True_optimizer.args.lr-3e-05_s...              96.0817   \n",
      "11  layer-wise-tune-True_optimizer.args.lr-3e-05_s...              95.8733   \n",
      "12  layer-wise-tune-True_optimizer.args.lr-3e-06_s...              95.8733   \n",
      "13  layer-wise-tune-True_optimizer.args.lr-3e-06_s...              95.8316   \n",
      "14  layer-wise-tune-True_optimizer.args.lr-3e-06_s...              95.9566   \n",
      "15  layer-wise-tune-True_optimizer.args.lr-3e-07_s...              73.9892   \n",
      "16  layer-wise-tune-True_optimizer.args.lr-3e-07_s...              76.1984   \n",
      "17  layer-wise-tune-True_optimizer.args.lr-3e-07_s...              74.6144   \n",
      "\n",
      "    test_acc/real_val                                          wandb_url  \\\n",
      "0             92.1504  https://wandb.ai/p-lambda/finetuning/runs/1983...   \n",
      "1             92.0784  https://wandb.ai/p-lambda/finetuning/runs/1r6b...   \n",
      "2             92.6257  https://wandb.ai/p-lambda/finetuning/runs/26mi...   \n",
      "3             93.2882  https://wandb.ai/p-lambda/finetuning/runs/1s2w...   \n",
      "4             93.4898  https://wandb.ai/p-lambda/finetuning/runs/1noz...   \n",
      "5             92.9425  https://wandb.ai/p-lambda/finetuning/runs/3iz4...   \n",
      "6             86.3172  https://wandb.ai/p-lambda/finetuning/runs/2kp2...   \n",
      "7             84.9057  https://wandb.ai/p-lambda/finetuning/runs/8f3c...   \n",
      "8             87.5702  https://wandb.ai/p-lambda/finetuning/runs/2wkl...   \n",
      "9             93.3602  https://wandb.ai/p-lambda/finetuning/runs/2x9b...   \n",
      "10            93.5042  https://wandb.ai/p-lambda/finetuning/runs/360e...   \n",
      "11            93.6483  https://wandb.ai/p-lambda/finetuning/runs/3d9r...   \n",
      "12            91.7615  https://wandb.ai/p-lambda/finetuning/runs/14v9...   \n",
      "13            91.7759  https://wandb.ai/p-lambda/finetuning/runs/33oz...   \n",
      "14            92.2656  https://wandb.ai/p-lambda/finetuning/runs/195b...   \n",
      "15            52.9598  https://wandb.ai/p-lambda/finetuning/runs/2r8a...   \n",
      "16            58.0153  https://wandb.ai/p-lambda/finetuning/runs/1f92...   \n",
      "17            55.3363  https://wandb.ai/p-lambda/finetuning/runs/cgzl...   \n",
      "\n",
      "                                            group  \n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "3    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "4    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "5    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "6    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "7    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "8    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "9    layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "10   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "11   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "12   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "13   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "14   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "15   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "16   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "17   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "fmow_all_nonorm_weakaugs                                                  name  test_acc/id_val  \\\n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001_...          68.6493   \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001_...          69.4418   \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001_...          69.5027   \n",
      "3   layer-wise-tune-True_optimizer.args.lr-1e-05_s...          67.5956   \n",
      "4   layer-wise-tune-True_optimizer.args.lr-1e-05_s...          66.7334   \n",
      "5   layer-wise-tune-True_optimizer.args.lr-1e-05_s...          66.2893   \n",
      "6   layer-wise-tune-True_optimizer.args.lr-1e-06_s...          45.5891   \n",
      "7   layer-wise-tune-True_optimizer.args.lr-1e-06_s...          39.3800   \n",
      "8   layer-wise-tune-True_optimizer.args.lr-1e-06_s...          40.4163   \n",
      "9   layer-wise-tune-True_optimizer.args.lr-3e-05_s...          68.9628   \n",
      "10  layer-wise-tune-True_optimizer.args.lr-3e-05_s...          69.1544   \n",
      "11  layer-wise-tune-True_optimizer.args.lr-3e-05_s...          68.9367   \n",
      "12  layer-wise-tune-True_optimizer.args.lr-3e-06_s...          62.4314   \n",
      "13  layer-wise-tune-True_optimizer.args.lr-3e-06_s...          59.0090   \n",
      "14  layer-wise-tune-True_optimizer.args.lr-3e-06_s...          58.3558   \n",
      "15  layer-wise-tune-True_optimizer.args.lr-3e-07_s...          23.6088   \n",
      "16  layer-wise-tune-True_optimizer.args.lr-3e-07_s...          21.6494   \n",
      "17  layer-wise-tune-True_optimizer.args.lr-3e-07_s...          21.4839   \n",
      "\n",
      "    test_acc/ood_val  test_acc/ood_test  test_acc/africa_test  \\\n",
      "0            65.6591            59.3134               41.5735   \n",
      "1            66.9295            60.0461               40.8022   \n",
      "2            67.1152            60.2633               39.0282   \n",
      "3            65.5185            59.8109               40.3779   \n",
      "4            64.4439            58.5218               39.7609   \n",
      "5            64.5443            58.9244               40.1851   \n",
      "6            47.1906            42.6904               30.5438   \n",
      "7            40.7130            35.5754               23.4477   \n",
      "8            41.2202            36.2086               24.9518   \n",
      "9            66.9947            61.0232               42.3833   \n",
      "10           66.5177            60.3311               39.8766   \n",
      "11           66.6282            60.6161               38.4111   \n",
      "12           61.2202            55.3781               37.5241   \n",
      "13           57.8458            52.7637               35.5573   \n",
      "14           57.6852            52.6325               35.2873   \n",
      "15           26.1562            20.8115               16.4288   \n",
      "16           23.8263            18.9072               14.7320   \n",
      "17           23.7409            18.5453               14.9248   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/249d...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/2b0j...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/3aek...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/3nxd...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/2lv5...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/wsc5...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/2sb5...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/1qvv...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/1zop...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/2crw...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/3lpx...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/2bqh...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/24it...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/2ir8...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/hq0o...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/1wmr...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/ask4...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/236v...   \n",
      "\n",
      "                                            group  \n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "3    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "4    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "5    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "6    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "7    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "8    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "9    layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "10   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "11   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "12   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "13   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "14   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "15   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "16   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "17   layer-wise-tune-True_optimizer.args.lr-3e-07  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelyon17_weakaugs                                                  name  test_acc/id_val  \\\n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001_...          99.1597   \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001_...          99.0256   \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001_...          98.7217   \n",
      "3   layer-wise-tune-True_optimizer.args.lr-1e-05_s...          99.2610   \n",
      "4   layer-wise-tune-True_optimizer.args.lr-1e-05_s...          99.1329   \n",
      "5   layer-wise-tune-True_optimizer.args.lr-1e-05_s...          99.3325   \n",
      "6   layer-wise-tune-True_optimizer.args.lr-1e-06_s...          98.6442   \n",
      "7   layer-wise-tune-True_optimizer.args.lr-1e-06_s...          98.6591   \n",
      "8   layer-wise-tune-True_optimizer.args.lr-1e-06_s...          98.7455   \n",
      "9   layer-wise-tune-True_optimizer.args.lr-3e-05_s...          99.3355   \n",
      "10  layer-wise-tune-True_optimizer.args.lr-3e-05_s...          99.1895   \n",
      "11  layer-wise-tune-True_optimizer.args.lr-3e-05_s...          99.2819   \n",
      "12  layer-wise-tune-True_optimizer.args.lr-3e-06_s...          99.0495   \n",
      "13  layer-wise-tune-True_optimizer.args.lr-3e-06_s...          98.9809   \n",
      "14  layer-wise-tune-True_optimizer.args.lr-3e-06_s...          99.1418   \n",
      "15  layer-wise-tune-True_optimizer.args.lr-3e-07_s...          97.8337   \n",
      "16  layer-wise-tune-True_optimizer.args.lr-3e-07_s...          97.8456   \n",
      "17  layer-wise-tune-True_optimizer.args.lr-3e-07_s...          97.8546   \n",
      "\n",
      "    test_acc/ood_val  test_acc/ood_test  \\\n",
      "0            94.2041            95.9355   \n",
      "1            94.9003            95.2195   \n",
      "2            92.6828            94.8891   \n",
      "3            93.7887            94.7645   \n",
      "4            94.3932            93.6146   \n",
      "5            93.8775            92.7552   \n",
      "6            92.7687            95.4511   \n",
      "7            92.2273            95.2183   \n",
      "8            92.0124            95.3383   \n",
      "9            95.1152            96.9361   \n",
      "10           94.1697            96.1812   \n",
      "11           95.1553            96.3270   \n",
      "12           92.9693            95.4735   \n",
      "13           92.7515            94.6940   \n",
      "14           92.5166            95.1066   \n",
      "15           92.8232            94.6481   \n",
      "16           93.0810            94.7986   \n",
      "17           93.0151            94.8527   \n",
      "\n",
      "                                            wandb_url  \\\n",
      "0   https://wandb.ai/p-lambda/finetuning/runs/3aew...   \n",
      "1   https://wandb.ai/p-lambda/finetuning/runs/3pgh...   \n",
      "2   https://wandb.ai/p-lambda/finetuning/runs/1zp9...   \n",
      "3   https://wandb.ai/p-lambda/finetuning/runs/2ktv...   \n",
      "4   https://wandb.ai/p-lambda/finetuning/runs/3179...   \n",
      "5   https://wandb.ai/p-lambda/finetuning/runs/rnel...   \n",
      "6   https://wandb.ai/p-lambda/finetuning/runs/3k6b...   \n",
      "7   https://wandb.ai/p-lambda/finetuning/runs/9f0p...   \n",
      "8   https://wandb.ai/p-lambda/finetuning/runs/3se2...   \n",
      "9   https://wandb.ai/p-lambda/finetuning/runs/3kzy...   \n",
      "10  https://wandb.ai/p-lambda/finetuning/runs/3d3p...   \n",
      "11  https://wandb.ai/p-lambda/finetuning/runs/17fj...   \n",
      "12  https://wandb.ai/p-lambda/finetuning/runs/3u8y...   \n",
      "13  https://wandb.ai/p-lambda/finetuning/runs/34un...   \n",
      "14  https://wandb.ai/p-lambda/finetuning/runs/1xmj...   \n",
      "15  https://wandb.ai/p-lambda/finetuning/runs/2iqx...   \n",
      "16  https://wandb.ai/p-lambda/finetuning/runs/35hv...   \n",
      "17  https://wandb.ai/p-lambda/finetuning/runs/3bvu...   \n",
      "\n",
      "                                            group  \n",
      "0   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "1   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "2   layer-wise-tune-True_optimizer.args.lr-0.0001  \n",
      "3    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "4    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "5    layer-wise-tune-True_optimizer.args.lr-1e-05  \n",
      "6    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "7    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "8    layer-wise-tune-True_optimizer.args.lr-1e-06  \n",
      "9    layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "10   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "11   layer-wise-tune-True_optimizer.args.lr-3e-05  \n",
      "12   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "13   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "14   layer-wise-tune-True_optimizer.args.lr-3e-06  \n",
      "15   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "16   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "17   layer-wise-tune-True_optimizer.args.lr-3e-07  \n",
      "living17_nonorm                                    name  test_acc/source_val_living  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0                     98.1176   \n",
      "1  optimizer.args.lr-0.0003_seed-0_run0                     98.1765   \n",
      "2   optimizer.args.lr-0.001_seed-0_run0                     96.2353   \n",
      "3   optimizer.args.lr-1e-05_seed-0_run0                     97.2353   \n",
      "4   optimizer.args.lr-1e-06_seed-0_run0                     91.4118   \n",
      "5   optimizer.args.lr-3e-05_seed-0_run0                     97.8824   \n",
      "6   optimizer.args.lr-3e-06_seed-0_run0                     96.0000   \n",
      "7   optimizer.args.lr-3e-07_seed-0_run0                     71.2353   \n",
      "\n",
      "   test_acc/target_val_living  \\\n",
      "0                     83.5882   \n",
      "1                     79.5294   \n",
      "2                     70.8235   \n",
      "3                     84.1765   \n",
      "4                     74.8824   \n",
      "5                     84.7059   \n",
      "6                     77.8824   \n",
      "7                     56.5294   \n",
      "\n",
      "                                           wandb_url                     group  \n",
      "0  https://wandb.ai/p-lambda/finetuning/runs/138g...  optimizer.args.lr-0.0001  \n",
      "1  https://wandb.ai/p-lambda/finetuning/runs/2lqs...  optimizer.args.lr-0.0003  \n",
      "2  https://wandb.ai/p-lambda/finetuning/runs/185g...   optimizer.args.lr-0.001  \n",
      "3  https://wandb.ai/p-lambda/finetuning/runs/2o2z...   optimizer.args.lr-1e-05  \n",
      "4  https://wandb.ai/p-lambda/finetuning/runs/1ufa...   optimizer.args.lr-1e-06  \n",
      "5  https://wandb.ai/p-lambda/finetuning/runs/qyz8...   optimizer.args.lr-3e-05  \n",
      "6  https://wandb.ai/p-lambda/finetuning/runs/3kg7...   optimizer.args.lr-3e-06  \n",
      "7  https://wandb.ai/p-lambda/finetuning/runs/3ofw...   optimizer.args.lr-3e-07  \n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.Lamb_ living17_nonorm 8\n",
      "waterbirds                                    name  WATERBIRDS_VAL    WORST  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0         97.7633  64.0187   \n",
      "1  optimizer.args.lr-0.0003_seed-0_run0         97.7132  65.1090   \n",
      "2   optimizer.args.lr-0.001_seed-0_run0         95.9931  30.6854   \n",
      "3   optimizer.args.lr-1e-05_seed-0_run0         96.8696  57.7882   \n",
      "4   optimizer.args.lr-1e-06_seed-0_run0         78.0727   0.0000   \n",
      "5   optimizer.args.lr-3e-05_seed-0_run0         97.2860  66.8224   \n",
      "6   optimizer.args.lr-3e-06_seed-0_run0         95.3479  14.3302   \n",
      "7   optimizer.args.lr-3e-07_seed-0_run0         76.7741   0.0000   \n",
      "\n",
      "                                           wandb_url                     group  \n",
      "0  https://wandb.ai/p-lambda/finetuning/runs/2lvy...  optimizer.args.lr-0.0001  \n",
      "1  https://wandb.ai/p-lambda/finetuning/runs/2htp...  optimizer.args.lr-0.0003  \n",
      "2  https://wandb.ai/p-lambda/finetuning/runs/1xf9...   optimizer.args.lr-0.001  \n",
      "3  https://wandb.ai/p-lambda/finetuning/runs/37yi...   optimizer.args.lr-1e-05  \n",
      "4  https://wandb.ai/p-lambda/finetuning/runs/1vwm...   optimizer.args.lr-1e-06  \n",
      "5  https://wandb.ai/p-lambda/finetuning/runs/273s...   optimizer.args.lr-3e-05  \n",
      "6  https://wandb.ai/p-lambda/finetuning/runs/bfpd...   optimizer.args.lr-3e-06  \n",
      "7  https://wandb.ai/p-lambda/finetuning/runs/x0nb...   optimizer.args.lr-3e-07  \n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.Lamb_ waterbirds 8\n",
      "domainnet                                    name  test_acc/sketch_val  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0              95.1230   \n",
      "1  optimizer.args.lr-0.0003_seed-0_run0              93.5807   \n",
      "2   optimizer.args.lr-0.001_seed-0_run0              89.2872   \n",
      "3   optimizer.args.lr-1e-05_seed-0_run0              91.2880   \n",
      "4   optimizer.args.lr-1e-06_seed-0_run0              32.2634   \n",
      "5   optimizer.args.lr-3e-05_seed-0_run0              93.8308   \n",
      "6   optimizer.args.lr-3e-06_seed-0_run0              67.9867   \n",
      "7   optimizer.args.lr-3e-07_seed-0_run0               9.0038   \n",
      "\n",
      "   test_acc/real_val                                          wandb_url  \\\n",
      "0            90.3644  https://wandb.ai/p-lambda/finetuning/runs/3tyw...   \n",
      "1            85.2801  https://wandb.ai/p-lambda/finetuning/runs/2k27...   \n",
      "2            70.1858  https://wandb.ai/p-lambda/finetuning/runs/wosn...   \n",
      "3            79.0580  https://wandb.ai/p-lambda/finetuning/runs/11o5...   \n",
      "4            16.3906  https://wandb.ai/p-lambda/finetuning/runs/1cib...   \n",
      "5            83.9263  https://wandb.ai/p-lambda/finetuning/runs/242n...   \n",
      "6            47.9908  https://wandb.ai/p-lambda/finetuning/runs/2cu3...   \n",
      "7             6.0493  https://wandb.ai/p-lambda/finetuning/runs/a1ev...   \n",
      "\n",
      "                      group  \n",
      "0  optimizer.args.lr-0.0001  \n",
      "1  optimizer.args.lr-0.0003  \n",
      "2   optimizer.args.lr-0.001  \n",
      "3   optimizer.args.lr-1e-05  \n",
      "4   optimizer.args.lr-1e-06  \n",
      "5   optimizer.args.lr-3e-05  \n",
      "6   optimizer.args.lr-3e-06  \n",
      "7   optimizer.args.lr-3e-07  \n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.Lamb_ domainnet 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmow_all_nonorm_weakaugs                                    name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0          67.9178           66.1863   \n",
      "1   optimizer.args.lr-1e-05_seed-0_run0          47.3918           47.9538   \n",
      "2   optimizer.args.lr-1e-06_seed-0_run0          15.7624           17.8509   \n",
      "3   optimizer.args.lr-3e-05_seed-0_run0          62.4924           61.0244   \n",
      "4   optimizer.args.lr-3e-06_seed-0_run0          26.6394           28.8024   \n",
      "5   optimizer.args.lr-3e-07_seed-0_run0          11.1382           11.9407   \n",
      "\n",
      "   test_acc/ood_test  test_acc/africa_test  \\\n",
      "0            59.2365               38.7582   \n",
      "1            43.8484               32.2792   \n",
      "2            12.8686                7.2503   \n",
      "3            55.2108               37.6012   \n",
      "4            23.6928               15.9661   \n",
      "5             9.2093                1.9283   \n",
      "\n",
      "                                           wandb_url                     group  \n",
      "0  https://wandb.ai/p-lambda/finetuning/runs/1c88...  optimizer.args.lr-0.0001  \n",
      "1  https://wandb.ai/p-lambda/finetuning/runs/2hzp...   optimizer.args.lr-1e-05  \n",
      "2  https://wandb.ai/p-lambda/finetuning/runs/2elk...   optimizer.args.lr-1e-06  \n",
      "3  https://wandb.ai/p-lambda/finetuning/runs/ryko...   optimizer.args.lr-3e-05  \n",
      "4  https://wandb.ai/p-lambda/finetuning/runs/3ifo...   optimizer.args.lr-3e-06  \n",
      "5  https://wandb.ai/p-lambda/finetuning/runs/35s8...   optimizer.args.lr-3e-07  \n",
      "camelyon17_weakaugs                                    name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0          99.5232           93.3818   \n",
      "1   optimizer.args.lr-1e-05_seed-0_run0          99.3176           94.6883   \n",
      "2   optimizer.args.lr-1e-06_seed-0_run0          98.1943           91.3849   \n",
      "3   optimizer.args.lr-3e-05_seed-0_run0          99.4815           94.1955   \n",
      "4   optimizer.args.lr-3e-06_seed-0_run0          98.9869           92.4622   \n",
      "5   optimizer.args.lr-3e-07_seed-0_run0          96.2992           92.8747   \n",
      "\n",
      "   test_acc/ood_test                                          wandb_url  \\\n",
      "0            93.3948  https://wandb.ai/p-lambda/finetuning/runs/3nvc...   \n",
      "1            95.3406  https://wandb.ai/p-lambda/finetuning/runs/1p4m...   \n",
      "2            91.7688  https://wandb.ai/p-lambda/finetuning/runs/1z8r...   \n",
      "3            96.1613  https://wandb.ai/p-lambda/finetuning/runs/wr9d...   \n",
      "4            92.1779  https://wandb.ai/p-lambda/finetuning/runs/gj7w...   \n",
      "5            93.8933  https://wandb.ai/p-lambda/finetuning/runs/2tdk...   \n",
      "\n",
      "                      group  \n",
      "0  optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-1e-05  \n",
      "2   optimizer.args.lr-1e-06  \n",
      "3   optimizer.args.lr-3e-05  \n",
      "4   optimizer.args.lr-3e-06  \n",
      "5   optimizer.args.lr-3e-07  \n",
      "living17_nonorm                                    name  test_acc/source_val_living  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0                     97.5882   \n",
      "1  optimizer.args.lr-0.0003_seed-0_run0                     97.3529   \n",
      "2   optimizer.args.lr-0.001_seed-0_run0                     95.8235   \n",
      "3   optimizer.args.lr-1e-05_seed-0_run0                     97.4706   \n",
      "4   optimizer.args.lr-1e-06_seed-0_run0                     92.8235   \n",
      "5   optimizer.args.lr-3e-05_seed-0_run0                     97.7059   \n",
      "6   optimizer.args.lr-3e-06_seed-0_run0                     96.3529   \n",
      "7   optimizer.args.lr-3e-07_seed-0_run0                     74.5294   \n",
      "\n",
      "   test_acc/target_val_living  \\\n",
      "0                     81.3529   \n",
      "1                     79.8824   \n",
      "2                     67.6471   \n",
      "3                     84.8235   \n",
      "4                     79.3529   \n",
      "5                     83.8824   \n",
      "6                     80.8235   \n",
      "7                     63.6471   \n",
      "\n",
      "                                           wandb_url                     group  \n",
      "0  https://wandb.ai/p-lambda/finetuning/runs/1rvf...  optimizer.args.lr-0.0001  \n",
      "1  https://wandb.ai/p-lambda/finetuning/runs/1k06...  optimizer.args.lr-0.0003  \n",
      "2  https://wandb.ai/p-lambda/finetuning/runs/2lm1...   optimizer.args.lr-0.001  \n",
      "3  https://wandb.ai/p-lambda/finetuning/runs/14j4...   optimizer.args.lr-1e-05  \n",
      "4  https://wandb.ai/p-lambda/finetuning/runs/2j6q...   optimizer.args.lr-1e-06  \n",
      "5  https://wandb.ai/p-lambda/finetuning/runs/1lry...   optimizer.args.lr-3e-05  \n",
      "6  https://wandb.ai/p-lambda/finetuning/runs/3ebz...   optimizer.args.lr-3e-06  \n",
      "7  https://wandb.ai/p-lambda/finetuning/runs/ljkn...   optimizer.args.lr-3e-07  \n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.LARS_ living17_nonorm 8\n",
      "waterbirds                                    name  WATERBIRDS_VAL    WORST  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0         96.3042  44.2368   \n",
      "1  optimizer.args.lr-0.0003_seed-0_run0         95.0043  20.0935   \n",
      "2   optimizer.args.lr-0.001_seed-0_run0         89.5186   3.7383   \n",
      "3   optimizer.args.lr-1e-05_seed-0_run0         96.9109  56.5421   \n",
      "4   optimizer.args.lr-1e-06_seed-0_run0         78.5911   0.0000   \n",
      "5   optimizer.args.lr-3e-05_seed-0_run0         97.1196  48.5981   \n",
      "6   optimizer.args.lr-3e-06_seed-0_run0         95.7925  21.6511   \n",
      "7   optimizer.args.lr-3e-07_seed-0_run0         76.8178   0.0000   \n",
      "\n",
      "                                           wandb_url                     group  \n",
      "0  https://wandb.ai/p-lambda/finetuning/runs/2fuj...  optimizer.args.lr-0.0001  \n",
      "1  https://wandb.ai/p-lambda/finetuning/runs/3s5h...  optimizer.args.lr-0.0003  \n",
      "2  https://wandb.ai/p-lambda/finetuning/runs/bk9a...   optimizer.args.lr-0.001  \n",
      "3  https://wandb.ai/p-lambda/finetuning/runs/1dtz...   optimizer.args.lr-1e-05  \n",
      "4  https://wandb.ai/p-lambda/finetuning/runs/3esy...   optimizer.args.lr-1e-06  \n",
      "5  https://wandb.ai/p-lambda/finetuning/runs/1p3r...   optimizer.args.lr-3e-05  \n",
      "6  https://wandb.ai/p-lambda/finetuning/runs/2t2e...   optimizer.args.lr-3e-06  \n",
      "7  https://wandb.ai/p-lambda/finetuning/runs/eff9...   optimizer.args.lr-3e-07  \n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.LARS_ waterbirds 8\n",
      "domainnet                                    name  test_acc/sketch_val  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0              90.1626   \n",
      "1  optimizer.args.lr-0.0003_seed-0_run0              83.3681   \n",
      "2   optimizer.args.lr-0.001_seed-0_run0              72.6553   \n",
      "3   optimizer.args.lr-1e-05_seed-0_run0              91.4965   \n",
      "4   optimizer.args.lr-1e-06_seed-0_run0              27.7199   \n",
      "5   optimizer.args.lr-3e-05_seed-0_run0              93.2472   \n",
      "6   optimizer.args.lr-3e-06_seed-0_run0              21.5090   \n",
      "7   optimizer.args.lr-3e-07_seed-0_run0               9.1288   \n",
      "\n",
      "   test_acc/real_val                                          wandb_url  \\\n",
      "0            78.7556  https://wandb.ai/p-lambda/finetuning/runs/6xuy...   \n",
      "1            63.5892  https://wandb.ai/p-lambda/finetuning/runs/13jn...   \n",
      "2            34.8408  https://wandb.ai/p-lambda/finetuning/runs/2izf...   \n",
      "3            80.2535  https://wandb.ai/p-lambda/finetuning/runs/nbzx...   \n",
      "4            14.0285  https://wandb.ai/p-lambda/finetuning/runs/2c5l...   \n",
      "5            83.8398  https://wandb.ai/p-lambda/finetuning/runs/bmfh...   \n",
      "6             8.8434  https://wandb.ai/p-lambda/finetuning/runs/wlgh...   \n",
      "7             6.3949  https://wandb.ai/p-lambda/finetuning/runs/1rkr...   \n",
      "\n",
      "                      group  \n",
      "0  optimizer.args.lr-0.0001  \n",
      "1  optimizer.args.lr-0.0003  \n",
      "2   optimizer.args.lr-0.001  \n",
      "3   optimizer.args.lr-1e-05  \n",
      "4   optimizer.args.lr-1e-06  \n",
      "5   optimizer.args.lr-3e-05  \n",
      "6   optimizer.args.lr-3e-06  \n",
      "7   optimizer.args.lr-3e-07  \n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.LARS_ domainnet 8\n",
      "fmow_all_nonorm_weakaugs                                    name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0          66.9860           65.7243   \n",
      "1   optimizer.args.lr-1e-05_seed-0_run0          47.3134           48.0191   \n",
      "2   optimizer.args.lr-1e-06_seed-0_run0          14.7087           16.5051   \n",
      "3   optimizer.args.lr-3e-05_seed-0_run0          60.7942           59.9749   \n",
      "4   optimizer.args.lr-3e-06_seed-0_run0          23.8352           26.1913   \n",
      "5   optimizer.args.lr-3e-07_seed-0_run0          10.9989           11.8303   \n",
      "\n",
      "   test_acc/ood_test  test_acc/africa_test  \\\n",
      "0            58.9289               38.6425   \n",
      "1            43.1925               31.7007   \n",
      "2            12.2490                6.7104   \n",
      "3            54.4102               37.7169   \n",
      "4            21.2593               14.6548   \n",
      "5             9.2093                1.8897   \n",
      "\n",
      "                                           wandb_url                     group  \n",
      "0  https://wandb.ai/p-lambda/finetuning/runs/4m5k...  optimizer.args.lr-0.0001  \n",
      "1  https://wandb.ai/p-lambda/finetuning/runs/38yn...   optimizer.args.lr-1e-05  \n",
      "2  https://wandb.ai/p-lambda/finetuning/runs/2shg...   optimizer.args.lr-1e-06  \n",
      "3  https://wandb.ai/p-lambda/finetuning/runs/20v2...   optimizer.args.lr-3e-05  \n",
      "4  https://wandb.ai/p-lambda/finetuning/runs/3fra...   optimizer.args.lr-3e-06  \n",
      "5  https://wandb.ai/p-lambda/finetuning/runs/fmd3...   optimizer.args.lr-3e-07  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelyon17_weakaugs                                    name  test_acc/id_val  test_acc/ood_val  \\\n",
      "0  optimizer.args.lr-0.0001_seed-0_run0          99.2193           85.9844   \n",
      "1   optimizer.args.lr-1e-05_seed-0_run0          99.1806           94.0694   \n",
      "2   optimizer.args.lr-1e-06_seed-0_run0          98.4118           89.9353   \n",
      "3   optimizer.args.lr-3e-05_seed-0_run0          99.3445           94.1124   \n",
      "4   optimizer.args.lr-3e-06_seed-0_run0          98.9273           91.0411   \n",
      "5   optimizer.args.lr-3e-07_seed-0_run0          96.9249           91.2073   \n",
      "\n",
      "   test_acc/ood_test                                          wandb_url  \\\n",
      "0            75.9976  https://wandb.ai/p-lambda/finetuning/runs/2hlj...   \n",
      "1            94.2683  https://wandb.ai/p-lambda/finetuning/runs/uaha...   \n",
      "2            89.2750  https://wandb.ai/p-lambda/finetuning/runs/1lmq...   \n",
      "3            93.2843  https://wandb.ai/p-lambda/finetuning/runs/2km8...   \n",
      "4            91.7335  https://wandb.ai/p-lambda/finetuning/runs/2wbk...   \n",
      "5            92.4272  https://wandb.ai/p-lambda/finetuning/runs/2ja1...   \n",
      "\n",
      "                      group  \n",
      "0  optimizer.args.lr-0.0001  \n",
      "1   optimizer.args.lr-1e-05  \n",
      "2   optimizer.args.lr-1e-06  \n",
      "3   optimizer.args.lr-3e-05  \n",
      "4   optimizer.args.lr-3e-06  \n",
      "5   optimizer.args.lr-3e-07  \n",
      "\n",
      "\n",
      "ID Accuracies\n",
      "\t\tLiv-17\tWaterbirds\tDomainNet\tFMoW\tCamelyon\tAvg.\n",
      "CLIP ViT-B/16\tSGD\t97.8 (0.2)\t97.2 (0.1)\t88.8 (7.1)\t67.0 (0.8)\t99.4 (0.0)\t90.0\n",
      "CLIP ViT-B/16\tAdamW\t98.1 (0.1)\t97.7 (0.0)\t95.0 (0.1)\t70.1 (0.2)\t99.5 (0.0)\t92.1\n",
      "CLIP ViT-B/16\tSGD (Freeze-embed)\t98.2 (0.3)\t97.8 (0.1)\t94.9 (0.3)\t70.0 (0.2)\t99.5 (0.0)\t92.1\n",
      "CLIP ViT-B/16\tLayer-wise\t98.3 (0.1)\t98.3 (0.0)\t96.3 (0.1)\t69.2 (0.5)\t99.3 (0.1)\t92.3\n",
      "CLIP ViT-B/16\tLAMB\t98.2 (nan)\t97.8 (nan)\t95.1 (nan)\t67.9 (nan)\t99.5 (nan)\t91.7\n",
      "CLIP ViT-B/16\tLARS\t97.7 (nan)\t97.1 (nan)\t93.2 (nan)\t67.0 (nan)\t99.3 (nan)\t90.9\n",
      "\n",
      "\\begin{tabular}{ccccccccccc|cc}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{Liv-17}  & \\multicolumn{2}{c}{Waterbirds}  & \\multicolumn{2}{c}{DomainNet}  & \\multicolumn{2}{c}{FMoW}  & \\multicolumn{2}{c}{Camelyon}  & \\multicolumn{2}{c}{Avg.} \\\\\n",
      "\\midrule\n",
      "SGD & 97.8 (0.2) &  & 97.2 (0.1) &  & 88.8 (7.1) &  & 67.0 (0.8) &  & 99.4 (0.0) &  & 90.0 & \\\\\n",
      "AdamW & 98.1 (0.1) & \\hspace{-1em}{\\hgreen{(+0.3)}} & 97.7 (0.0) & \\hspace{-1em}{\\hgreen{(+0.5)}} & 95.0 (0.1) & \\hspace{-1em}{\\hgreen{(+6.2)}} & \\textbf{70.1 (0.2)} & \\hspace{-1em}{\\hgreen{(+3.1)}} & \\textbf{99.5 (0.0)} & \\hspace{-1em}{\\lgreen{(+0.1)}} & \\textbf{92.1} & \\hspace{-1em}{\\hgreen{(+2.1)}}\\\\\n",
      "SGD (Freeze-embed) & \\textbf{98.2 (0.3)} & \\hspace{-1em}{\\hgreen{(+0.4)}} & 97.8 (0.1) & \\hspace{-1em}{\\hgreen{(+0.6)}} & 94.9 (0.3) & \\hspace{-1em}{\\hgreen{(+6.1)}} & \\textbf{70.0 (0.2)} & \\hspace{-1em}{\\hgreen{(+3.0)}} & 99.5 (0.0) & \\hspace{-1em}{\\lgreen{(+0.1)}} & \\textbf{92.1} & \\hspace{-1em}{\\hgreen{(+2.1)}}\\\\\n",
      "Layer-wise & \\textbf{98.3 (0.1)} & \\hspace{-1em}{\\hgreen{(+0.5)}} & \\textbf{98.3 (0.0)} & \\hspace{-1em}{\\hgreen{(+1.1)}} & \\textbf{96.3 (0.1)} & \\hspace{-1em}{\\hgreen{(+7.5)}} & 69.2 (0.5) & \\hspace{-1em}{\\hgreen{(+2.2)}} & 99.3 (0.1) & \\hspace{-1em}{\\lred{(-0.1)}} & \\textbf{92.3} & \\hspace{-1em}{\\hgreen{(+2.3)}}\\\\\n",
      "LAMB & \\textbf{98.2} & \\hspace{-1em}{\\hgreen{(+0.4)}} & 97.8 & \\hspace{-1em}{\\hgreen{(+0.6)}} & 95.1 & \\hspace{-1em}{\\hgreen{(+6.3)}} & 67.9 & \\hspace{-1em}{\\hgreen{(+0.9)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & 91.7 & \\hspace{-1em}{\\hgreen{(+1.7)}}\\\\\n",
      "LARS & 97.7 & \\hspace{-1em}{\\lred{(-0.1)}} & 97.1 & \\hspace{-1em}{\\lred{(-0.1)}} & 93.2 & \\hspace{-1em}{\\hgreen{(+4.4)}} & 67.0 & \\hspace{-1em}{\\lgreen{(+0.0)}} & 99.3 & \\hspace{-1em}{\\lred{(-0.1)}} & 90.9 & \\hspace{-1em}{\\hgreen{(+0.9)}}\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "OOD Accuracies\n",
      "\t\tLiv-17\tWaterbirds\tDomainNet\tFMoW\tCamelyon\tAvg.\n",
      "CLIP ViT-B/16\tSGD\t80.0 (1.3)\t62.5 (5.0)\t72.8 (18.0)\t37.3 (1.1)\t86.8 (1.1)\t67.9\n",
      "CLIP ViT-B/16\tAdamW\t82.8 (1.2)\t71.9 (2.4)\t89.2 (1.1)\t40.7 (0.3)\t95.7 (0.4)\t76.0\n",
      "CLIP ViT-B/16\tSGD (Freeze-embed)\t83.2 (0.8)\t73.7 (1.1)\t88.2 (0.7)\t40.2 (0.7)\t94.3 (0.3)\t75.9\n",
      "CLIP ViT-B/16\tLayer-wise\t81.9 (0.1)\t69.1 (3.4)\t93.2 (0.3)\t40.5 (1.2)\t96.5 (0.4)\t76.2\n",
      "CLIP ViT-B/16\tLAMB\t79.5 (nan)\t64.0 (nan)\t90.4 (nan)\t38.8 (nan)\t93.4 (nan)\t73.2\n",
      "CLIP ViT-B/16\tLARS\t83.9 (nan)\t48.6 (nan)\t83.8 (nan)\t38.6 (nan)\t93.3 (nan)\t69.6\n",
      "\n",
      "\\begin{tabular}{ccccccccccc|cc}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{Liv-17}  & \\multicolumn{2}{c}{Waterbirds}  & \\multicolumn{2}{c}{DomainNet}  & \\multicolumn{2}{c}{FMoW}  & \\multicolumn{2}{c}{Camelyon}  & \\multicolumn{2}{c}{Avg.} \\\\\n",
      "\\midrule\n",
      "SGD & 80.0 (1.3) &  & 62.5 (5.0) &  & 72.8 (18.0) &  & 37.3 (1.1) &  & 86.8 (1.1) &  & 67.9 & \\\\\n",
      "AdamW & \\textbf{82.8 (1.2)} & \\hspace{-1em}{\\hgreen{(+2.8)}} & \\textbf{71.9 (2.4)} & \\hspace{-1em}{\\hgreen{(+9.4)}} & 89.2 (1.1) & \\hspace{-1em}{\\hgreen{(+16.4)}} & \\textbf{40.7 (0.3)} & \\hspace{-1em}{\\hgreen{(+3.4)}} & 95.7 (0.4) & \\hspace{-1em}{\\hgreen{(+8.9)}} & \\textbf{76.0} & \\hspace{-1em}{\\hgreen{(+8.1)}}\\\\\n",
      "SGD (Freeze-embed) & \\textbf{83.2 (0.8)} & \\hspace{-1em}{\\hgreen{(+3.2)}} & \\textbf{73.7 (1.1)} & \\hspace{-1em}{\\hgreen{(+11.2)}} & 88.2 (0.7) & \\hspace{-1em}{\\hgreen{(+15.4)}} & \\textbf{40.2 (0.7)} & \\hspace{-1em}{\\hgreen{(+2.9)}} & 94.3 (0.3) & \\hspace{-1em}{\\hgreen{(+7.5)}} & 75.9 & \\hspace{-1em}{\\hgreen{(+8.0)}}\\\\\n",
      "Layer-wise & 81.9 (0.1) & \\hspace{-1em}{\\hgreen{(+1.9)}} & 69.1 (3.4) & \\hspace{-1em}{\\hgreen{(+6.6)}} & \\textbf{93.2 (0.3)} & \\hspace{-1em}{\\hgreen{(+20.4)}} & \\textbf{40.5 (1.2)} & \\hspace{-1em}{\\hgreen{(+3.2)}} & \\textbf{96.5 (0.4)} & \\hspace{-1em}{\\hgreen{(+9.7)}} & \\textbf{76.2} & \\hspace{-1em}{\\hgreen{(+8.3)}}\\\\\n",
      "LAMB & 79.5 & \\hspace{-1em}{\\hred{(-0.5)}} & 64.0 & \\hspace{-1em}{\\hgreen{(+1.5)}} & 90.4 & \\hspace{-1em}{\\hgreen{(+17.6)}} & 38.8 & \\hspace{-1em}{\\hgreen{(+1.5)}} & 93.4 & \\hspace{-1em}{\\hgreen{(+6.6)}} & 73.2 & \\hspace{-1em}{\\hgreen{(+5.3)}}\\\\\n",
      "LARS & \\textbf{83.9} & \\hspace{-1em}{\\hgreen{(+3.9)}} & 48.6 & \\hspace{-1em}{\\hred{(-13.9)}} & 83.8 & \\hspace{-1em}{\\hgreen{(+11.0)}} & 38.6 & \\hspace{-1em}{\\hgreen{(+1.3)}} & 93.3 & \\hspace{-1em}{\\hgreen{(+6.5)}} & 69.6 & \\hspace{-1em}{\\hgreen{(+1.7)}}\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[97.82353333, 97.22233333, 88.8009    , 66.9715    ,\n",
       "          99.3802    , 90.03969333],\n",
       "         [98.09803333, 97.7472    , 94.9979    , 70.11816667,\n",
       "          99.5451    , 92.10128   ],\n",
       "         [98.15683333, 97.8062    , 94.91456667, 70.00203333,\n",
       "          99.52623333, 92.08117333],\n",
       "         [98.31373333, 98.2936    , 96.30403333, 69.19793333,\n",
       "          99.26896667, 92.27565333],\n",
       "         [98.1765    , 97.7633    , 95.123     , 67.9178    ,\n",
       "          99.5232    , 91.70076   ],\n",
       "         [97.7059    , 97.1196    , 93.2472    , 66.986     ,\n",
       "          99.3445    , 90.88064   ]]]),\n",
       " array([[[79.9608    , 62.46103333, 72.77833333, 37.34413333,\n",
       "          86.79546667, 67.86795333],\n",
       "         [82.80393333, 71.85876667, 89.16893333, 40.66073333,\n",
       "          95.72586667, 76.04364667],\n",
       "         [83.17646667, 73.72796667, 88.22793333, 40.18513333,\n",
       "          94.29106667, 75.92171333],\n",
       "         [81.90196667, 69.05503333, 93.24016667, 40.46796667,\n",
       "          96.48143333, 76.22931333],\n",
       "         [79.5294    , 64.0187    , 90.3644    , 38.7582    ,\n",
       "          93.3948    , 73.2131    ],\n",
       "         [83.8824    , 48.5981    , 83.8398    , 38.6425    ,\n",
       "          93.2843    , 69.64942   ]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"CLIP Results, all datasets\")\n",
    "models = ['clip_vit_b16']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'layer_wise_tune__', 'opt_torch_optimizer.Lamb_', 'opt_torch_optimizer.LARS_']\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "# pickle.dump( (mean_table, std_table), open( \"clip_table_main.pkl\", \"wb\" ) )\n",
    "# mean_table, std_table = pickle.load( open( \"clip_table_main.pkl\", \"rb\" ) )\n",
    "\n",
    "shorted_model_names = ['CLIP ViT-B/16']\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (Freeze-embed)', 'Layer-wise', 'LAMB', 'LARS']\n",
    "shortened_output_metrics_list = ['Living-17 ID', 'Living-17 OOD', 'Waterbirds ID', 'Waterbirds OOD', 'DomainNet ID', 'DomainNet OOD', \"FMoW ID\", \"FMoW OOD Val\", \"FMoW OOD Test\", \"FMoW Africa\", \"Camelyon ID\", \"Camelyon OOD Val\", \"Camelyon OOD Test\"]\n",
    "\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Liv-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "display_id_ood_tables(mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP Results for ViT-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big table, Living17, Waterbirds, DomainNet, Camelyon, FMoW (Early stopped)\n",
    "models = ['clip_vit_l14']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "shorted_model_names = ['CLIP ViT-B/16', 'Sup ViT-B/16', 'DINO ViT-B/16', 'BIT ResNet-50', 'BIT ResNet-101', 'ConvNext-Base', 'CLIP ViT-L/14']\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (Freeze-2)']\n",
    "\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Liv-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "id_mean_table, ood_mean_table = display_id_ood_tables(\n",
    "    mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n",
    "\n",
    "# display_tsv_table(shorted_model_names, shortened_options_names, shortened_output_metrics_list, mean_table, std_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table for dino and clip, freezing different number of layers.\n",
    "print(\"CLIP Results, all datasets\")\n",
    "models = ['clip_vit_b16']\n",
    "options = ['freeze_bottom_2_full_ft_epoch_50_', 'freeze_bottom_5_full_ft_epoch_50_', 'freeze_bottom_8_full_ft_epoch_50_', 'freeze_bottom_11_full_ft_epoch_50_', 'freeze_bottom_14_full_ft_epoch_50_']\n",
    "val_metric_list = ['WATERBIRDS_VAL']\n",
    "datasets = ['waterbirds']\n",
    "output_metrics_list = [['WATERBIRDS_VAL', 'WORST']]\n",
    "aggregation_metric_list = ['WATERBIRDS_VAL']\n",
    "# desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "mean_table, std_table = get_table('../older_logs/', name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "shorted_model_names = ['CLIP ViT-B/16']\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (Freeze-embed)', 'Layer-wise', 'LAMB', 'LARS']\n",
    "shortened_output_metrics_list = ['Living-17 ID', 'Living-17 OOD', 'Waterbirds ID', 'Waterbirds OOD', 'DomainNet ID', 'DomainNet OOD', \"FMoW ID\", \"FMoW OOD Val\", \"FMoW OOD Test\", \"FMoW Africa\", \"Camelyon ID\", \"Camelyon OOD Val\", \"Camelyon OOD Test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post ICLR Supplementary results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big table, including AdamW + Freeze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big table, Living17, Waterbirds, DomainNet, Camelyon, FMoW (Early stopped)\n",
    "models = ['clip_vit_b16', 'clip_vit_l14', 'timm_vit_b16_in21k', 'dino_vit_b16',  'convnext_vit_b', 'bit_resnet_50_in21k', 'bit_resnet_101_in21k']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'freeze_bottom_2_opt_torch.optim.AdamW_']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "\n",
    "# mean_table_3, std_table_3 = pickle.load( open( \"big_table_main.pkl\", \"rb\" ) )\n",
    "# mean_table = np.concatenate((mean_table_3, mean_table_3[:,1,None,:]), axis=1)\n",
    "# std_table = np.concatenate((std_table_3, std_table_3[:,1,None,:]), axis=1)\n",
    "\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "shorted_model_names = ['CLIP ViT-B/16', 'CLIP ViT-L/14', 'Sup ViT-B/16', 'DINO ViT-B/16', 'ConvNext-Base', 'BiT ResNet-50', 'BiT ResNet-101']\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (freeze-embed)', 'AdamW (freeze-embed)']\n",
    "\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Living-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "\n",
    "id_mean_table, ood_mean_table = display_id_ood_tables(\n",
    "    mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n",
    "\n",
    "# display_tsv_table(shorted_model_names, shortened_options_names, shortened_output_metrics_list, mean_table, std_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average ID and OOD results for the 3 methods.\n",
    "print(np.mean(id_mean_table[:,:,5], axis=0))\n",
    "print(np.mean(ood_mean_table[:,:,5], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-50 all results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big table, Living17, Waterbirds, DomainNet, Camelyon, FMoW (Early stopped)\n",
    "models = ['sup_resnet50']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'freeze_bottom_2_opt_torch.optim.AdamW_']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "shorted_model_names = ['ResNet50']\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (Freeze-2)', 'AdamW (Freeze-2)']\n",
    "\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Liv-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "id_mean_table, ood_mean_table = display_id_ood_tables(\n",
    "    mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n",
    "\n",
    "# display_tsv_table(shorted_model_names, shortened_options_names, shortened_output_metrics_list, mean_table, std_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP weight decay, no momentum, freeze only embed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Results, all datasets\n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.Lamb_ living17_nonorm 8\n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.Lamb_ waterbirds 8\n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.Lamb_ domainnet 8\n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.LARS_ living17_nonorm 8\n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.LARS_ waterbirds 8\n",
      "not all jobs ran:  clip_vit_b16 opt_torch_optimizer.LARS_ domainnet 8\n",
      "\n",
      "\n",
      "ID Accuracies\n",
      "\t\tLiv-17\tWaterbirds\tDomainNet\tFMoW\tCamelyon\tAvg.\n",
      "CLIP ViT-B/16\tSGD\t97.8\t97.2\t88.8\t67.0\t99.4\t90.0\n",
      "CLIP ViT-B/16\tAdamW\t98.1\t97.7\t95.0\t70.1\t99.5\t92.1\n",
      "CLIP ViT-B/16\tSGD (Freeze-embed)\t98.2\t97.8\t94.9\t70.0\t99.5\t92.1\n",
      "CLIP ViT-B/16\tLayer-wise\t98.3\t98.3\t96.3\t69.2\t99.3\t92.3\n",
      "CLIP ViT-B/16\tLAMB\t98.2\t97.8\t95.1\t67.9\t99.5\t91.7\n",
      "CLIP ViT-B/16\tLARS\t97.7\t97.1\t93.2\t67.0\t99.3\t90.9\n",
      "CLIP ViT-B/16\tSGD (Freeze-embed, not layer-norm)\t98.0\t98.0\t95.4\t70.2\t99.5\t92.2\n",
      "CLIP ViT-B/16\tSGD (no momentum)\t98.0\t97.1\t89.5\t66.4\t99.3\t90.1\n",
      "CLIP ViT-B/16\tSGD (weight decay)\t97.6\t97.2\t87.9\t66.4\t99.3\t89.7\n",
      "CLIP ViT-B/16\tSGD (lower LR, embed layer)\t98.0\t97.5\t94.8\t68.7\t99.5\t91.7\n",
      "\n",
      "\\begin{tabular}{ccccccccccc|cc}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{Liv-17}  & \\multicolumn{2}{c}{Waterbirds}  & \\multicolumn{2}{c}{DomainNet}  & \\multicolumn{2}{c}{FMoW}  & \\multicolumn{2}{c}{Camelyon}  & \\multicolumn{2}{c}{Avg.} \\\\\n",
      "\\midrule\n",
      "SGD & 97.8 &  & 97.2 &  & 88.8 &  & 67.0 &  & \\textbf{99.4} &  & 90.0 & \\\\\n",
      "AdamW & 98.1 & \\hspace{-1em}{\\hgreen{(+0.3)}} & 97.7 & \\hspace{-1em}{\\hgreen{(+0.5)}} & 95.0 & \\hspace{-1em}{\\hgreen{(+6.2)}} & \\textbf{70.1} & \\hspace{-1em}{\\hgreen{(+3.1)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & \\textbf{92.1} & \\hspace{-1em}{\\hgreen{(+2.1)}}\\\\\n",
      "SGD (Freeze-embed) & \\textbf{98.2} & \\hspace{-1em}{\\hgreen{(+0.4)}} & 97.8 & \\hspace{-1em}{\\hgreen{(+0.6)}} & 94.9 & \\hspace{-1em}{\\hgreen{(+6.1)}} & \\textbf{70.0} & \\hspace{-1em}{\\hgreen{(+3.0)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & \\textbf{92.1} & \\hspace{-1em}{\\hgreen{(+2.1)}}\\\\\n",
      "Layer-wise & \\textbf{98.3} & \\hspace{-1em}{\\hgreen{(+0.5)}} & \\textbf{98.3} & \\hspace{-1em}{\\hgreen{(+1.1)}} & \\textbf{96.3} & \\hspace{-1em}{\\hgreen{(+7.5)}} & 69.2 & \\hspace{-1em}{\\hgreen{(+2.2)}} & 99.3 & \\hspace{-1em}{\\lred{(-0.1)}} & \\textbf{92.3} & \\hspace{-1em}{\\hgreen{(+2.3)}}\\\\\n",
      "LAMB & \\textbf{98.2} & \\hspace{-1em}{\\hgreen{(+0.4)}} & 97.8 & \\hspace{-1em}{\\hgreen{(+0.6)}} & 95.1 & \\hspace{-1em}{\\hgreen{(+6.3)}} & 67.9 & \\hspace{-1em}{\\hgreen{(+0.9)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & 91.7 & \\hspace{-1em}{\\hgreen{(+1.7)}}\\\\\n",
      "LARS & 97.7 & \\hspace{-1em}{\\lred{(-0.1)}} & 97.1 & \\hspace{-1em}{\\lred{(-0.1)}} & 93.2 & \\hspace{-1em}{\\hgreen{(+4.4)}} & 67.0 & \\hspace{-1em}{\\lgreen{(+0.0)}} & 99.3 & \\hspace{-1em}{\\lred{(-0.1)}} & 90.9 & \\hspace{-1em}{\\hgreen{(+0.9)}}\\\\\n",
      "SGD (Freeze-embed, not layer-norm) & 98.0 & \\hspace{-1em}{\\lgreen{(+0.2)}} & 98.0 & \\hspace{-1em}{\\hgreen{(+0.8)}} & 95.4 & \\hspace{-1em}{\\hgreen{(+6.6)}} & \\textbf{70.2} & \\hspace{-1em}{\\hgreen{(+3.2)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & \\textbf{92.2} & \\hspace{-1em}{\\hgreen{(+2.2)}}\\\\\n",
      "SGD (no momentum) & 98.0 & \\hspace{-1em}{\\lgreen{(+0.2)}} & 97.1 & \\hspace{-1em}{\\lred{(-0.1)}} & 89.5 & \\hspace{-1em}{\\hgreen{(+0.7)}} & 66.4 & \\hspace{-1em}{\\hred{(-0.6)}} & 99.3 & \\hspace{-1em}{\\lred{(-0.1)}} & 90.1 & \\hspace{-1em}{\\lgreen{(+0.1)}}\\\\\n",
      "SGD (weight decay) & 97.6 & \\hspace{-1em}{\\hred{(-0.2)}} & 97.2 & \\hspace{-1em}{\\lgreen{(+0.0)}} & 87.9 & \\hspace{-1em}{\\hred{(-0.9)}} & 66.4 & \\hspace{-1em}{\\hred{(-0.6)}} & 99.3 & \\hspace{-1em}{\\lred{(-0.1)}} & 89.7 & \\hspace{-1em}{\\hred{(-0.3)}}\\\\\n",
      "SGD (lower LR, embed layer) & 98.0 & \\hspace{-1em}{\\lgreen{(+0.2)}} & 97.5 & \\hspace{-1em}{\\hgreen{(+0.3)}} & 94.8 & \\hspace{-1em}{\\hgreen{(+6.0)}} & 68.7 & \\hspace{-1em}{\\hgreen{(+1.7)}} & \\textbf{99.5} & \\hspace{-1em}{\\lgreen{(+0.1)}} & 91.7 & \\hspace{-1em}{\\hgreen{(+1.7)}}\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "OOD Accuracies\n",
      "\t\tLiv-17\tWaterbirds\tDomainNet\tFMoW\tCamelyon\tAvg.\n",
      "CLIP ViT-B/16\tSGD\t80.0\t62.5\t72.8\t37.3\t86.8\t67.9\n",
      "CLIP ViT-B/16\tAdamW\t82.8\t71.9\t89.2\t40.7\t95.7\t76.0\n",
      "CLIP ViT-B/16\tSGD (Freeze-embed)\t83.2\t73.7\t88.2\t40.2\t94.3\t75.9\n",
      "CLIP ViT-B/16\tLayer-wise\t81.9\t69.1\t93.2\t40.5\t96.5\t76.2\n",
      "CLIP ViT-B/16\tLAMB\t79.5\t64.0\t90.4\t38.8\t93.4\t73.2\n",
      "CLIP ViT-B/16\tLARS\t83.9\t48.6\t83.8\t38.6\t93.3\t69.6\n",
      "CLIP ViT-B/16\tSGD (Freeze-embed, not layer-norm)\t83.6\t74.3\t89.1\t39.3\t92.9\t75.9\n",
      "CLIP ViT-B/16\tSGD (no momentum)\t81.4\t59.2\t76.7\t37.9\t84.3\t67.9\n",
      "CLIP ViT-B/16\tSGD (weight decay)\t83.9\t65.1\t67.5\t37.1\t85.6\t67.8\n",
      "CLIP ViT-B/16\tSGD (lower LR, embed layer)\t83.3\t71.7\t85.7\t38.7\t95.7\t75.0\n",
      "\n",
      "\\begin{tabular}{ccccccccccc|cc}\n",
      "\\toprule\n",
      " & \\multicolumn{2}{c}{Liv-17}  & \\multicolumn{2}{c}{Waterbirds}  & \\multicolumn{2}{c}{DomainNet}  & \\multicolumn{2}{c}{FMoW}  & \\multicolumn{2}{c}{Camelyon}  & \\multicolumn{2}{c}{Avg.} \\\\\n",
      "\\midrule\n",
      "SGD & 80.0 &  & 62.5 &  & 72.8 &  & 37.3 &  & 86.8 &  & 67.9 & \\\\\n",
      "AdamW & 82.8 & \\hspace{-1em}{\\hgreen{(+2.8)}} & 71.9 & \\hspace{-1em}{\\hgreen{(+9.4)}} & 89.2 & \\hspace{-1em}{\\hgreen{(+16.4)}} & \\textbf{40.7} & \\hspace{-1em}{\\hgreen{(+3.4)}} & 95.7 & \\hspace{-1em}{\\hgreen{(+8.9)}} & \\textbf{76.0} & \\hspace{-1em}{\\hgreen{(+8.1)}}\\\\\n",
      "SGD (Freeze-embed) & 83.2 & \\hspace{-1em}{\\hgreen{(+3.2)}} & 73.7 & \\hspace{-1em}{\\hgreen{(+11.2)}} & 88.2 & \\hspace{-1em}{\\hgreen{(+15.4)}} & 40.2 & \\hspace{-1em}{\\hgreen{(+2.9)}} & 94.3 & \\hspace{-1em}{\\hgreen{(+7.5)}} & 75.9 & \\hspace{-1em}{\\hgreen{(+8.0)}}\\\\\n",
      "Layer-wise & 81.9 & \\hspace{-1em}{\\hgreen{(+1.9)}} & 69.1 & \\hspace{-1em}{\\hgreen{(+6.6)}} & \\textbf{93.2} & \\hspace{-1em}{\\hgreen{(+20.4)}} & \\textbf{40.5} & \\hspace{-1em}{\\hgreen{(+3.2)}} & \\textbf{96.5} & \\hspace{-1em}{\\hgreen{(+9.7)}} & \\textbf{76.2} & \\hspace{-1em}{\\hgreen{(+8.3)}}\\\\\n",
      "LAMB & 79.5 & \\hspace{-1em}{\\hred{(-0.5)}} & 64.0 & \\hspace{-1em}{\\hgreen{(+1.5)}} & 90.4 & \\hspace{-1em}{\\hgreen{(+17.6)}} & 38.8 & \\hspace{-1em}{\\hgreen{(+1.5)}} & 93.4 & \\hspace{-1em}{\\hgreen{(+6.6)}} & 73.2 & \\hspace{-1em}{\\hgreen{(+5.3)}}\\\\\n",
      "LARS & \\textbf{83.9} & \\hspace{-1em}{\\hgreen{(+3.9)}} & 48.6 & \\hspace{-1em}{\\hred{(-13.9)}} & 83.8 & \\hspace{-1em}{\\hgreen{(+11.0)}} & 38.6 & \\hspace{-1em}{\\hgreen{(+1.3)}} & 93.3 & \\hspace{-1em}{\\hgreen{(+6.5)}} & 69.6 & \\hspace{-1em}{\\hgreen{(+1.7)}}\\\\\n",
      "SGD (Freeze-embed, not layer-norm) & 83.6 & \\hspace{-1em}{\\hgreen{(+3.6)}} & \\textbf{74.3} & \\hspace{-1em}{\\hgreen{(+11.8)}} & 89.1 & \\hspace{-1em}{\\hgreen{(+16.3)}} & 39.3 & \\hspace{-1em}{\\hgreen{(+2.0)}} & 92.9 & \\hspace{-1em}{\\hgreen{(+6.1)}} & 75.9 & \\hspace{-1em}{\\hgreen{(+8.0)}}\\\\\n",
      "SGD (no momentum) & 81.4 & \\hspace{-1em}{\\hgreen{(+1.4)}} & 59.2 & \\hspace{-1em}{\\hred{(-3.3)}} & 76.7 & \\hspace{-1em}{\\hgreen{(+3.9)}} & 37.9 & \\hspace{-1em}{\\hgreen{(+0.6)}} & 84.3 & \\hspace{-1em}{\\hred{(-2.5)}} & 67.9 & \\hspace{-1em}{\\lgreen{(+0.0)}}\\\\\n",
      "SGD (weight decay) & \\textbf{83.9} & \\hspace{-1em}{\\hgreen{(+3.9)}} & 65.1 & \\hspace{-1em}{\\hgreen{(+2.6)}} & 67.5 & \\hspace{-1em}{\\hred{(-5.3)}} & 37.1 & \\hspace{-1em}{\\lred{(-0.2)}} & 85.6 & \\hspace{-1em}{\\hred{(-1.2)}} & 67.8 & \\hspace{-1em}{\\lred{(-0.1)}}\\\\\n",
      "SGD (lower LR, embed layer) & 83.3 & \\hspace{-1em}{\\hgreen{(+3.3)}} & 71.7 & \\hspace{-1em}{\\hgreen{(+9.2)}} & 85.7 & \\hspace{-1em}{\\hgreen{(+12.9)}} & 38.7 & \\hspace{-1em}{\\hgreen{(+1.4)}} & 95.7 & \\hspace{-1em}{\\hgreen{(+8.9)}} & 75.0 & \\hspace{-1em}{\\hgreen{(+7.1)}}\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[97.82353333, 97.22233333, 88.8009    , 66.9715    ,\n",
       "          99.3802    , 90.03969333],\n",
       "         [98.09803333, 97.7472    , 94.9979    , 70.11816667,\n",
       "          99.5451    , 92.10128   ],\n",
       "         [98.15683333, 97.8062    , 94.91456667, 70.00203333,\n",
       "          99.52623333, 92.08117333],\n",
       "         [98.31373333, 98.2936    , 96.30403333, 69.19793333,\n",
       "          99.26896667, 92.27565333],\n",
       "         [98.1765    , 97.7633    , 95.123     , 67.9178    ,\n",
       "          99.5232    , 91.70076   ],\n",
       "         [97.7059    , 97.1196    , 93.2472    , 66.986     ,\n",
       "          99.3445    , 90.88064   ],\n",
       "         [98.        , 98.0037    , 95.4148    , 70.1646    ,\n",
       "          99.5262    , 92.22186   ],\n",
       "         [98.        , 97.071     , 89.5373    , 66.3764    ,\n",
       "          99.3236    , 90.06166   ],\n",
       "         [97.6471    , 97.2224    , 87.8699    , 66.3503    ,\n",
       "          99.2938    , 89.6767    ],\n",
       "         [98.        , 97.5392    , 94.7895    , 68.6841    ,\n",
       "          99.5113    , 91.70482   ]]]),\n",
       " array([[[79.9608    , 62.46103333, 72.77833333, 37.34413333,\n",
       "          86.79546667, 67.86795333],\n",
       "         [82.80393333, 71.85876667, 89.16893333, 40.66073333,\n",
       "          95.72586667, 76.04364667],\n",
       "         [83.17646667, 73.72796667, 88.22793333, 40.18513333,\n",
       "          94.29106667, 75.92171333],\n",
       "         [81.90196667, 69.05503333, 93.24016667, 40.46796667,\n",
       "          96.48143333, 76.22931333],\n",
       "         [79.5294    , 64.0187    , 90.3644    , 38.7582    ,\n",
       "          93.3948    , 73.2131    ],\n",
       "         [83.8824    , 48.5981    , 83.8398    , 38.6425    ,\n",
       "          93.2843    , 69.64942   ],\n",
       "         [83.6471    , 74.2991    , 89.0681    , 39.2981    ,\n",
       "          92.941     , 75.85068   ],\n",
       "         [81.3529    , 59.19      , 76.6671    , 37.9483    ,\n",
       "          84.2829    , 67.88824   ],\n",
       "         [83.9412    , 65.109     , 67.478     , 37.0613    ,\n",
       "          85.5645    , 67.8308    ],\n",
       "         [83.2941    , 71.6511    , 85.6834    , 38.7196    ,\n",
       "          95.6675    , 75.00314   ]]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"CLIP Results, all datasets\")\n",
    "models = ['clip_vit_b16']\n",
    "# options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'layer_wise_tune__', 'opt_torch_optimizer.Lamb_', 'opt_torch_optimizer.LARS_', 'freeze_bottom_1_', 'optimizer.args.momentum-0.0_', 'freeze_bottom_2_optimizer.args.momentum-0.0_', 'optimizer.args.weight_decay-0.01_']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'layer_wise_tune__', 'opt_torch_optimizer.Lamb_', 'opt_torch_optimizer.LARS_', 'freeze_bottom_1_', 'optimizer.args.momentum-0.0_', 'optimizer.args.weight_decay-0.01_', 'embed_layer_lr_multiplier-0.2_']\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "# pickle.dump( (mean_table, std_table), open( \"clip_table_extended.pkl\", \"wb\" ) )\n",
    "# mean_table, std_table = pickle.load( open( \"clip_table_extended.pkl\", \"rb\" ) )\n",
    "\n",
    "shorted_model_names = ['CLIP ViT-B/16']\n",
    "# shortened_options_names = ['SGD', 'AdamW', 'SGD (Freeze-embed)', 'Layer-wise', 'LAMB', 'LARS', 'Freeze only embed', 'SGD (no momentum)', 'SGD (Freeze, no momentum)', 'SGD (weight decay)']\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (Freeze-embed)', 'Layer-wise', 'LAMB', 'LARS', 'SGD (Freeze-embed, not layer-norm)', 'SGD (no momentum)', 'SGD (weight decay)', 'SGD (lower LR, embed layer)']\n",
    "shortened_output_metrics_list = ['Living-17 ID', 'Living-17 OOD', 'Waterbirds ID', 'Waterbirds OOD', 'DomainNet ID', 'DomainNet OOD', \"FMoW ID\", \"FMoW OOD Val\", \"FMoW OOD Test\", \"FMoW Africa\", \"Camelyon ID\", \"Camelyon OOD Val\", \"Camelyon OOD Test\"]\n",
    "\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Liv-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "display_id_ood_tables(mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big table with no momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not all jobs ran:  clip_vit_l14 freeze_bottom_2_optimizer.args.momentum-0.0_ domainnet 1\n",
      "not all jobs ran:  timm_vit_b16_in21k freeze_bottom_2_optimizer.args.momentum-0.0_ domainnet 1\n",
      "not all jobs ran:  timm_vit_b16_in21k freeze_bottom_2_optimizer.args.momentum-0.0_ fmow_all_nonorm_weakaugs 4\n",
      "not all jobs ran:  dino_vit_b16 freeze_bottom_2_optimizer.args.momentum-0.0_ domainnet 5\n",
      "empty dir ../logs//full_ft_freeze_bottom_2_optimizer.args.momentum-0.0_fmow_all_nonorm_weakaugs_dino_vit_b16\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-acc1143b7e1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmean_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_metrics_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metric_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_metric_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_epochs_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesired_epochs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Rearranging mean table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-0ab32fca2bc0>\u001b[0m in \u001b[0;36mget_table\u001b[0;34m(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, num_sweep, desired_epochs_list)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 res, best_row_mean, best_row_std, num_epochs_list = summarize_all_results.get_experiment_aggregate_summary(\n\u001b[1;32m     47\u001b[0m                     dir_path, val_metric, output_metrics, aggregation_metric=agg_metric)\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mnum_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 if (desired_epochs_list is not None and\n\u001b[1;32m     50\u001b[0m                     desired_epochs_list[dataset_idx] != np.min(num_epochs_list)):\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Big table, Living17, Waterbirds, DomainNet, Camelyon, FMoW (Early stopped)\n",
    "models = ['clip_vit_b16', 'clip_vit_l14', 'timm_vit_b16_in21k', 'dino_vit_b16',  'convnext_vit_b', 'bit_resnet_50_in21k', 'bit_resnet_101_in21k']\n",
    "options = ['', 'opt_torch.optim.AdamW_', 'freeze_bottom_2_', 'freeze_bottom_2_optimizer.args.momentum-0.0_']\n",
    "datasets = ['living17_nonorm', 'waterbirds', 'domainnet', 'fmow_all_nonorm_weakaugs', 'camelyon17_weakaugs']\n",
    "output_metrics_list = [['test_acc/source_val_living', 'test_acc/target_val_living'], ['WATERBIRDS_VAL', 'WORST'], ['test_acc/sketch_val', 'test_acc/real_val'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test', 'test_acc/africa_test'], ['test_acc/id_val', 'test_acc/ood_val', 'test_acc/ood_test']]\n",
    "val_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "aggregation_metric_list = ['test_acc/source_val_living', 'WATERBIRDS_VAL', 'test_acc/sketch_val', 'test_acc/id_val', 'test_acc/id_val']\n",
    "desired_epochs_list = [20, 20, 50, 5, 3]\n",
    "shorted_model_names = ['CLIP ViT-B/16', 'CLIP ViT-L/14', 'Sup ViT-B/16', 'DINO ViT-B/16', 'ConvNext-Base', 'BiT ResNet-50', 'BiT ResNet-101', ]\n",
    "shortened_options_names = ['SGD', 'AdamW', 'SGD (freeze-embed)', 'SGD (freeze-embed, no momentum)']\n",
    "id_output_metrics_list = [['test_acc/source_val_living'], ['WATERBIRDS_VAL'], ['test_acc/sketch_val'], ['test_acc/id_val'], ['test_acc/id_val']]\n",
    "ood_output_metrics_list = [['test_acc/target_val_living'], ['WORST'], ['test_acc/real_val'], ['test_acc/africa_test'], ['test_acc/ood_test']]\n",
    "shortened_dataset_names = ['Living-17', 'Waterbirds', 'DomainNet', \"FMoW\", \"Camelyon\", \"Avg.\"]\n",
    "\n",
    "\n",
    "mean_table, std_table = get_table(log_dir, name_template, models, options, datasets, output_metrics_list, val_metric_list, aggregation_metric_list, desired_epochs_list=desired_epochs_list)\n",
    "\n",
    "# Rearranging mean table\n",
    "mean_table = mean_table_old_order[[0,6,1,2,5,3,4],:,:]\n",
    "std_table = std_table_old_order[[0,6,1,2,5,3,4],:,:]\n",
    "\n",
    "id_mean_table, ood_mean_table = display_id_ood_tables(\n",
    "    mean_table, std_table, id_output_metrics_list, ood_output_metrics_list, shortened_dataset_names, no_std=True)\n",
    "\n",
    "# display_tsv_table(shorted_model_names, shortened_options_names, shortened_output_metrics_list, mean_table, std_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e20a982d9929f39844afb80a108913d82415026ed53cd5cf5e2e4d27193773a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
