{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_data(mu_c, mu_spur, sigma_c, sigma_spur, n):\n",
    "    # Generate n/2 negative examples, n/2 positive examples from core-spurious distribution.\n",
    "    assert(n % 2 == 0)\n",
    "    d_core, d_spur = len(mu_c), len(mu_spur)\n",
    "    ys = [0] * (n // 2) + [1] * (n // 2)\n",
    "    x_cores_0 = multivariate_normal(-mu_c, np.eye(d_core) * sigma_c, size=n//2)\n",
    "    x_cores_1 = multivariate_normal(mu_c, np.eye(d_core) * sigma_c, size=n//2)\n",
    "    x_spurs_0 = multivariate_normal(-mu_spur, np.eye(d_spur) * sigma_spur, size=n//2)\n",
    "    x_spurs_1 = multivariate_normal(mu_spur, np.eye(d_spur) * sigma_spur, size=n//2)\n",
    "    x0 = np.concatenate([x_cores_0, x_spurs_0], axis=1)\n",
    "    x1 = np.concatenate([x_cores_1, x_spurs_1], axis=1)\n",
    "    return np.concatenate([x0, x1], axis=0), np.array(ys)\n",
    "\n",
    "\n",
    "def make_data(mu_c, Mu_spur, sigma_c, sigma_spur, n_per_domain_train, n_per_domain_val):\n",
    "    # Generate train and val examples for each domain.\n",
    "    assert(n_per_domain_train % 2 == 0 and n_per_domain_val % 2 == 0)\n",
    "    train_xs, train_ys = [], []\n",
    "    val_xs, val_ys = [], []\n",
    "    num_domains, d_spur = Mu_spur.shape\n",
    "    d_core = len(mu_c)\n",
    "    for domain in range(num_domains):\n",
    "        xs, ys = generate_data(mu_c, Mu_spur[domain], sigma_c, sigma_spur, n_per_domain_train)\n",
    "        train_xs.append(xs)\n",
    "        train_ys.append(ys)\n",
    "        xs, ys = generate_data(mu_c, Mu_spur[domain], sigma_c, sigma_spur, n_per_domain_val)\n",
    "        val_xs.append(xs)\n",
    "        val_ys.append(ys)\n",
    "    train_xs = np.concatenate(train_xs, axis=0)\n",
    "    train_ys = np.concatenate(train_ys, axis=0)\n",
    "    val_xs = np.concatenate(val_xs, axis=0)\n",
    "    val_ys = np.concatenate(val_ys, axis=0)\n",
    "    return train_xs, train_ys, val_xs, val_ys\n",
    "    \n",
    "def generate_mus(d_core, d_spur, D):\n",
    "    mu_c = multivariate_normal(np.zeros(d_core), np.eye(d_core))\n",
    "    mu_c = mu_c / np.linalg.norm(mu_c)\n",
    "    Mu_spur = multivariate_normal(np.zeros(d_spur), np.eye(d_spur) * 1 / d_spur, size=D)\n",
    "    return mu_c, Mu_spur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve logistic regression.\n",
    "\n",
    "def get_log_reg_problem(xs, ys, w0):\n",
    "    n, d = xs.shape\n",
    "    w = cp.Variable(d)\n",
    "    lambd = cp.Parameter(nonneg=True)\n",
    "    log_likelihood = cp.sum(\n",
    "        cp.multiply(ys, xs @ w) - cp.logistic(xs @ w)\n",
    "    )\n",
    "    problem = cp.Problem(cp.Maximize(log_likelihood / n - lambd * cp.norm(w - w0, 2)))\n",
    "    return problem, lambd, w\n",
    "\n",
    "def log_reg(xs, ys, w0, reg, solver=cp.ECOS):\n",
    "    # w_0 is the initialization to regularize towards, reg is the regularization strength (lambda)\n",
    "    problem, lambd, w = get_log_reg_problem(xs, ys, w0)\n",
    "    lambd.value = reg\n",
    "    problem.solve(solver=solver)\n",
    "    if problem.status != 'optimal':\n",
    "        print(problem.status, reg)\n",
    "    return w.value\n",
    "\n",
    "def get_logits(w, xs):\n",
    "    return xs @ w\n",
    "\n",
    "def get_preds(w, xs):\n",
    "    logits = xs @ w\n",
    "    return (logits >= 0).astype(np.int32)\n",
    "\n",
    "def get_acc(preds, ys):\n",
    "    return np.mean(preds == ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sigma_spur, D combination. Sample. Pre-train. Fine-tune or linear probe. Measure accuracy.\n",
    "def compare_fine_tuning(sigma_c, sigma_spur, d_core, d_spur, D, n_per_domain_train, n_per_domain_val):\n",
    "    mu_c, Mu_spur = generate_mus(d_core, d_spur, D)\n",
    "    train_xs, train_ys, val_xs, val_ys = make_data(mu_c, Mu_spur, sigma_c, sigma_spur, n_per_domain_train, n_per_domain_val)\n",
    "    id_tr_xs, id_tr_ys = train_xs[:n_per_domain_train], train_ys[:n_per_domain_train]\n",
    "    id_val_xs, id_val_ys = val_xs[:n_per_domain_val], val_ys[:n_per_domain_val]\n",
    "    xs = [train_xs, val_xs, id_tr_xs, id_val_xs]\n",
    "    ys = [train_ys, val_ys, id_tr_ys, id_val_ys]\n",
    "    # Pre-train classifier.\n",
    "    w0 = log_reg(train_xs, train_ys, np.zeros(d_core + d_spur), reg=0.0)\n",
    "    pretrain_ood_acc = get_acc(get_preds(w0, val_xs), val_ys)\n",
    "    pretrain_id_acc = get_acc(get_preds(w0, id_val_xs), id_val_ys)\n",
    "    print('pretrain_ood_acc: ', pretrain_ood_acc)\n",
    "    print('pretrain_id_acc: ', pretrain_id_acc)\n",
    "    # Fine-tune classifier. \n",
    "    ft_ood_accs, ft_id_accs = [], []\n",
    "    prob, lambd, w_param = get_log_reg_problem(id_tr_xs, id_tr_ys, w0)\n",
    "    regs = np.logspace(0, -3, 20)\n",
    "    for reg in regs:\n",
    "        lambd.value = reg\n",
    "        prob.solve()\n",
    "        if prob.status != 'optimal':\n",
    "            print(prob.status, reg)\n",
    "        ft_ood_accs.append(get_acc(get_preds(w_param.value, val_xs), val_ys))\n",
    "        ft_id_accs.append(get_acc(get_preds(w_param.value, id_val_xs), id_val_ys))\n",
    "    print(ft_ood_accs)\n",
    "    print(ft_id_accs)\n",
    "    # Linear-probe classifier. \n",
    "    lp_ood_accs, lp_id_accs = [], []\n",
    "    logits = []\n",
    "    for i in range(len(xs)):\n",
    "        logits.append(get_logits(w0, xs[i]))\n",
    "    prob, lambd, head_param = get_log_reg_problem(logits[2], id_tr_ys, np.array([1.0]))\n",
    "    regs = np.logspace(0, -3, 20)\n",
    "    for reg in regs:\n",
    "        lambd.value = reg\n",
    "        prob.solve()\n",
    "        if prob.status != 'optimal':\n",
    "            print(prob.status, reg)\n",
    "        ft_ood_accs.append(get_acc(get_preds(w_param.value, val_xs), val_ys))\n",
    "        ft_id_accs.append(get_acc(get_preds(w_param.value, id_val_xs), id_val_ys))\n",
    "    print(ft_ood_accs)\n",
    "    print(ft_id_accs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_data(np.array([2.0]), np.array([[5.0], [0.0]]), 1.0, 1.0, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain_ood_acc:  0.8482\n",
      "pretrain_id_acc:  0.798\n",
      "[0.8482, 0.8482, 0.8482, 0.8483, 0.8428, 0.8312, 0.80775, 0.7823, 0.7537, 0.72395, 0.69655, 0.66915, 0.64355, 0.62255, 0.6058, 0.59385, 0.58515, 0.5778, 0.5747, 0.5731]\n",
      "[0.798, 0.798, 0.798, 0.8, 0.881, 0.932, 0.963, 0.975, 0.983, 0.984, 0.986, 0.985, 0.985, 0.987, 0.988, 0.988, 0.987, 0.987, 0.985, 0.985]\n"
     ]
    }
   ],
   "source": [
    "sigma_c = 1.0\n",
    "sigma_spur = 0.3\n",
    "d_core, d_spur = 1, 10\n",
    "D = 20\n",
    "n_per_domain_train, n_per_domain_val = 1000, 1000\n",
    "compare_fine_tuning(sigma_c, sigma_spur, d_core, d_spur, D, n_per_domain_train, n_per_domain_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n"
     ]
    }
   ],
   "source": [
    "w0 = np.zeros(d_core + d_spur)\n",
    "w = log_reg(id_tr_xs, id_train_ys, w0, reg=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7980729  -0.51111631  0.99871807  0.8447853   3.15868253 -1.84308014\n",
      "  0.83643784 -1.5165847   1.99099672  0.49510643  1.26742756]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962\n"
     ]
    }
   ],
   "source": [
    "val_preds = get_preds(w, id_tr_xs)\n",
    "val_acc = get_acc(val_preds, id_train_ys)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, C=1000.0, fit_intercept=False).fit(id_tr_xs, id_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.85829487, -0.53834539,  1.03173298,  0.86021655,  3.3017722 ,\n",
       "        -1.91698605,  0.8680179 , -1.57759646,  2.08355504,  0.50766487,\n",
       "         1.31722613]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(clf.predict(id_tr_xs), id_train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
