{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can load files from other sub-directories, e.g. datasets.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from robustness.tools.breeds_helpers import make_living17, make_entity13, make_entity30, make_nonliving26\n",
    "\n",
    "BREEDS_SPLITS_TO_FUNC = {\n",
    "    'entity13': make_entity13,\n",
    "    'entity30': make_entity30,\n",
    "    'living17': make_living17,\n",
    "    'nonliving26': make_nonliving26,\n",
    "}\n",
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif']\n",
    "\n",
    "SPLITS = ['train', 'val']\n",
    "\n",
    "NUM_TRAIN_PER_CLASS = 1300\n",
    "\n",
    "NUM_VAL_PER_CLASS = 50\n",
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif']\n",
    "\n",
    "def get_classes(dir):\n",
    "    if sys.version_info >= (3, 5):\n",
    "        # Faster and available in Python 3.5 and above\n",
    "        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "    else:\n",
    "        classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "def has_file_allowed_extension(filename, extensions):\n",
    "    filename_lower = filename.lower()\n",
    "    return any(filename_lower.endswith(ext) for ext in extensions)\n",
    "\n",
    "def get_class_image_names(class_dir):\n",
    "    image_names = []\n",
    "    for root, _, fnames in sorted(os.walk(class_dir)):\n",
    "        for fname in sorted(fnames):\n",
    "            if has_file_allowed_extension(fname, extensions=IMG_EXTENSIONS):\n",
    "                path = os.path.join(root, fname)\n",
    "                image_names.append(path)\n",
    "    return image_names\n",
    "\n",
    "def get_image_paths_by_class(data_dir, idx_to_class_id, subclasses, split):\n",
    "    image_paths_by_class = []\n",
    "    for idx in range(len(subclasses)):\n",
    "        image_paths_by_class.append([])\n",
    "        for subclass in subclasses[idx]:\n",
    "            subclass_image_names = get_class_image_names(data_dir + '/' + idx_to_class_id[subclass] + '/')\n",
    "            image_paths_by_class[-1].extend(subclass_image_names)\n",
    "            if split == 'train':\n",
    "                assert(len(subclass_image_names) == NUM_TRAIN_PER_CLASS)\n",
    "            else:\n",
    "                assert(len(subclass_image_names) == NUM_VAL_PER_CLASS)\n",
    "    return image_paths_by_class\n",
    "\n",
    "class Breeds(Dataset):\n",
    "\n",
    "    def __init__(self, root, breeds_name,\n",
    "                 info_dir='/juice/scr/ananya/cifar_experiments/BREEDS-Benchmarks/imagenet_class_hierarchy/modified',\n",
    "                 source=True, split='train', transform=None):\n",
    "        super().__init__()\n",
    "        if breeds_name not in BREEDS_SPLITS:\n",
    "            raise ValueError(f'breeds_name must be in {BREEDS_SPLITS} but was {breeds_name}')\n",
    "        if split not in SPLITS:\n",
    "            raise ValueError(f'split must be in {SPLITS} but was {split}')\n",
    "        self._breeds_name = breeds_name\n",
    "        self._source = source\n",
    "        self._split = split\n",
    "        self._transform = transform\n",
    "        self._info_dir = info_dir\n",
    "        self._data_dir = root + '/' + split\n",
    "        self._idx_to_class_id, self._class_to_idx = get_classes(self._data_dir)\n",
    "        if breeds_name == \n",
    "        self._superclasses, self._subclass_split, self._label_map = make_living17(self._info_dir, split=\"rand\")\n",
    "        # print(superclasses, label_map)\n",
    "        if source:\n",
    "            self._subclasses = self._subclass_split[0]\n",
    "        else:\n",
    "            self._subclasses = self._subclass_split[1]\n",
    "        self._image_paths_by_class = get_image_paths_by_class(\n",
    "            self._data_dir, self._idx_to_class_id, self._subclasses, split)\n",
    "        \n",
    "        # Get a mapping of class index to type by sorting.\n",
    "        # Get the names of the classes using robustness helper\n",
    "        # Get the source and target classes\n",
    "        # Get a list of files in each class\n",
    "        # 1300 examples per class in train, 50 in test, check this.\n",
    "        # Get item by class order.\n",
    "#         if corruption not in CORRUPTIONS:\n",
    "#             raise ValueError(f\"{corruption} is not a valid corruption.\")\n",
    "#         if not(0 <= severity <= 4):\n",
    "#             raise ValueError(f\"Severity was {severity} but must be 0, 1, 2, 3, 4.\")\n",
    "#         num_examples = 10000\n",
    "#         start_idx = num_examples * severity\n",
    "#         end_idx = num_examples * (severity + 1)\n",
    "#         self._xs = np.load(root + '/' + corruption + '.npy')[start_idx:end_idx]\n",
    "#         self._ys = torch.LongTensor(np.load(root + 'labels.npy'))[start_idx:end_idx]\n",
    "#         assert(len(self._xs) == len(self._ys) == num_examples)\n",
    "#         self._transform = transform\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self._xs[i], self._ys[i]\n",
    "        x = Image.fromarray(np.uint8(x))\n",
    "        if self._transform is not None:\n",
    "            x = self._transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._xs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Breeds(root='/u/scr/nlp/imagenet/', breeds_name='entity13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
