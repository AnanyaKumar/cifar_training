{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unlabeled_extrapolation.datasets.fmow' from '/juice/scr/ananya/cifar_experiments/unlabeled_extrapolation/unlabeled_extrapolation/datasets/fmow.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can load files from other sub-directories, e.g. datasets.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('unlabeled_extrapolation'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from unlabeled_extrapolation.models import imnet_resnet\n",
    "from unlabeled_extrapolation.models import imnet_models\n",
    "from unlabeled_extrapolation.models import clip_model\n",
    "from unlabeled_extrapolation.models import vit_model\n",
    "from torch import nn\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import unlabeled_extrapolation.utils.utils as utils\n",
    "\n",
    "from unlabeled_extrapolation.datasets import fmow\n",
    "\n",
    "import importlib\n",
    "importlib.reload(imnet_resnet)\n",
    "importlib.reload(imnet_models)\n",
    "importlib.reload(fmow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /sailhome/ananya/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "vitb16 = vit_model.VitModel('dino_vitb16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vitb16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-adb38ceeec5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvitb16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvitb16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_last_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvitb16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_last_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vitb16' is not defined"
     ]
    }
   ],
   "source": [
    "vitb16.set_requires_grad(False)\n",
    "vitb16.new_last_layer(30)\n",
    "print(vitb16.get_last_layer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = imnet_resnet.ResNet50(pretrained=True, pretrain_style='mocov2', checkpoint_path='/u/scr/ananya/simclr_weights/moco_v2_800ep_pretrain.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try loading fmow checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = imnet_resnet.ResNet50(pretrained=True, pretrain_style='mocov2', checkpoint_path='/u/scr/ananya/simclr_weights/moco_checkpoint_0200.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = imnet_resnet.ResNet50(pretrained=True, pretrain_style='mocov2', checkpoint_path='/u/scr/ananya/simclr_weights/mocotp_checkpoint_0200.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fmow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.Compose(\n",
    "[\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "fmow_dataset = fmow.Fmow(split='test', regions=['all'], root='/u/scr/nlp/wilds/data', transform=trans)\n",
    "# use 'train', 'ood_val', 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2048]) torch.Size([1, 2048])\n",
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(type(fmow_dataset[0][0]))\n",
    "model.enable_side_tuning()\n",
    "model.cuda()\n",
    "output = model(fmow_dataset[0][0].cuda().unsqueeze(0))\n",
    "# output = vitb16(fmow_dataset[0][0].cuda().unsqueeze(0))\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23508032\n",
      "27606032\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model, trainable):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad == trainable)\n",
    "print(count_parameters(model, trainable=False))\n",
    "print(count_parameters(model, trainable=True))\n",
    "# for p in model.parameters():\n",
    "#     print(p.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22108"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fmow_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmow_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "fmow_loader = torch.utils.data.DataLoader(fmow_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "# model2.cuda()\n",
    "# model2.train()\n",
    "labels_list = []\n",
    "\n",
    "for data in fmow_loader:\n",
    "    print('hi')\n",
    "    images, labels = data\n",
    "    labels_list.append(labels.cpu().numpy())\n",
    "#     images = images.cuda()\n",
    "#     outputs = model2(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "57\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 58 59 60 61]\n"
     ]
    }
   ],
   "source": [
    "# As you can see there are missing elements.\n",
    "unique_elements = np.unique(np.concatenate(labels_list))\n",
    "for i in range(62):\n",
    "    if i not in unique_elements:\n",
    "        print(i)\n",
    "print(unique_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_fmow_mocotp_fmow_resnet50/weights_0.pkl\n",
      "(60, 2048) (60,)\n",
      "(62, 2048) (62,)\n",
      "[0. 0. 0. ... 0. 0. 0.] [-0.77600142  0.26469648  0.44337508 ...  0.76615316 -0.02349414\n",
      "  1.0102488 ]\n",
      "/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_fmow_mocotp_fmow_resnet50/weights_0_old.pkl\n",
      "(60, 2048) (60,)\n",
      "(62, 2048) (62,)\n",
      "[0. 0. 0. ... 0. 0. 0.] [-0.77600142  0.26469648  0.44337508 ...  0.76615316 -0.02349414\n",
      "  1.0102488 ]\n",
      "/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_fmow_mocotp_fmow_resnet50/weights_1_old.pkl\n",
      "(60, 2048) (60,)\n",
      "(62, 2048) (62,)\n",
      "[0. 0. 0. ... 0. 0. 0.] [-0.77448514  0.264641    0.44119132 ...  0.76753556 -0.02327004\n",
      "  1.01224038]\n",
      "/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_fmow_mocotp_fmow_resnet50/weights_1.pkl\n",
      "(60, 2048) (60,)\n",
      "(62, 2048) (62,)\n",
      "[0. 0. 0. ... 0. 0. 0.] [-0.77448514  0.264641    0.44119132 ...  0.76753556 -0.02327004\n",
      "  1.01224038]\n",
      "/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_fmow_mocotp_fmow_resnet50/weights_2.pkl\n",
      "(60, 2048) (60,)\n",
      "(62, 2048) (62,)\n",
      "[0. 0. 0. ... 0. 0. 0.] [-0.77565739  0.26482096  0.44288826 ...  0.76715519 -0.02332003\n",
      "  1.01377229]\n",
      "/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_fmow_mocotp_fmow_resnet50/weights_2_old.pkl\n",
      "(60, 2048) (60,)\n",
      "(62, 2048) (62,)\n",
      "[0. 0. 0. ... 0. 0. 0.] [-0.77565739  0.26482096  0.44288826 ...  0.76715519 -0.02332003\n",
      "  1.01377229]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 62\n",
    "missing_elements = [30, 57]\n",
    "\n",
    "def get_updated_weights(weights,  biases, num_classes, missing_elements):\n",
    "    padded_elements = missing_elements + [num_classes]\n",
    "    assert weights.shape[0] + len(missing_elements) == num_classes\n",
    "    feat_size = weights.shape[1]\n",
    "    new_weights = np.zeros((num_classes, feat_size))\n",
    "    new_biases = np.zeros((num_classes,))\n",
    "    prev = 0\n",
    "    for i in range(len(padded_elements)):\n",
    "        cur = padded_elements[i]\n",
    "        new_weights[prev:cur] = weights[prev-i:cur-i]\n",
    "        new_biases[prev:cur] = biases[prev-i:cur-i]\n",
    "        if cur < num_classes:\n",
    "            new_biases[cur] = -1000.0\n",
    "        prev = cur+1\n",
    "    return new_weights, new_biases\n",
    "\n",
    "def update_weights(num_classes=62, missing_elements=[30, 57], results_dir='.'):\n",
    "    file_paths = glob.glob(results_dir + 'weights*.pkl', recursive=True)\n",
    "    for file_path in file_paths:\n",
    "        print(file_path)\n",
    "        weights, biases, a, b = pickle.load(open(file_path, 'rb'))\n",
    "        print(weights.shape, biases.shape)\n",
    "        new_weights, new_biases = get_updated_weights(weights,  biases, num_classes, missing_elements)\n",
    "        print(new_weights.shape, new_biases.shape)\n",
    "        print(new_weights[30], new_weights[56])\n",
    "        archive_file_path = file_path[:-4] + '_old.pkl'\n",
    "        pickle.dump( (weights, biases, a, b), open(archive_file_path, \"wb\" ) )\n",
    "        pickle.dump( (new_weights, new_biases, a, b), open(archive_file_path, \"wb\" ) )\n",
    "update_weights(results_dir='/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_fmow_mocotp_fmow_resnet50/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79114543]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens with logistic regression if there are missing labels (e.g. labels are 0 or 4)?\n",
    "# sklearn would treat it as binary classification, but output 0 or 4 (instead of 0, 1)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = [[-1], [-2], [1.0], [-3.0], [4.0], [0.0], [1.0], [0.2]]\n",
    "y = [1, 1, 1, 1, 4, 4, 4, 4]\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 4.5925e-02,  2.4501e-02,  1.7135e-02,  ...,  3.4709e-02,\n",
      "           -3.0446e-02, -3.3597e-02],\n",
      "          [ 2.7815e-02,  1.9076e-02,  1.7268e-02,  ...,  4.9695e-02,\n",
      "           -2.4068e-02, -3.3174e-02],\n",
      "          [ 8.5390e-03,  1.2160e-02,  2.2308e-02,  ...,  7.1529e-02,\n",
      "           -1.3284e-03, -1.3955e-02],\n",
      "          ...,\n",
      "          [-7.1822e-03,  2.3723e-02,  5.7477e-02,  ...,  7.8695e-02,\n",
      "           -2.4064e-03,  9.9170e-03],\n",
      "          [-8.3695e-02, -6.1164e-02, -5.1117e-03,  ...,  2.0737e-02,\n",
      "           -6.2004e-02, -6.9332e-02],\n",
      "          [-8.0871e-02, -7.3265e-02, -1.3761e-02,  ...,  4.8501e-02,\n",
      "           -4.5042e-02, -6.3812e-02]],\n",
      "\n",
      "         [[-1.3739e-01, -9.2955e-02, -7.8492e-02,  ..., -6.5235e-03,\n",
      "           -4.8398e-02, -5.8640e-02],\n",
      "          [-8.9618e-02, -3.5499e-02, -1.5408e-02,  ...,  8.3488e-02,\n",
      "            4.3193e-02,  2.9939e-02],\n",
      "          [-7.1726e-02, -4.7808e-03,  1.8898e-02,  ...,  1.3059e-01,\n",
      "            1.0011e-01,  8.2546e-02],\n",
      "          ...,\n",
      "          [ 1.2064e-02,  1.0760e-01,  1.5136e-01,  ...,  2.2190e-01,\n",
      "            1.8246e-01,  1.9295e-01],\n",
      "          [-1.6681e-02,  7.8839e-02,  1.4834e-01,  ...,  2.3272e-01,\n",
      "            1.7746e-01,  1.6578e-01],\n",
      "          [-2.5878e-02,  6.0297e-02,  1.3529e-01,  ...,  2.5782e-01,\n",
      "            1.8243e-01,  1.6204e-01]],\n",
      "\n",
      "         [[ 1.6008e-01,  1.2341e-01,  4.9481e-02,  ...,  1.2669e-02,\n",
      "            3.5911e-02,  8.0644e-02],\n",
      "          [ 1.0838e-01,  5.3092e-02, -3.5156e-02,  ..., -7.7496e-02,\n",
      "           -4.2005e-02,  2.0842e-02],\n",
      "          [ 5.7166e-02, -1.0780e-02, -1.2188e-01,  ..., -1.8988e-01,\n",
      "           -1.2817e-01, -4.1789e-02],\n",
      "          ...,\n",
      "          [-8.6204e-03, -8.6324e-02, -2.2266e-01,  ..., -4.1926e-01,\n",
      "           -3.4261e-01, -1.8408e-01],\n",
      "          [ 2.7667e-02, -3.7312e-02, -1.2708e-01,  ..., -3.0425e-01,\n",
      "           -2.6430e-01, -1.4493e-01],\n",
      "          [ 5.1539e-02, -7.4702e-03, -5.6247e-02,  ..., -1.6542e-01,\n",
      "           -1.6885e-01, -9.4366e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2936e-02,  5.2673e-02,  5.2981e-02,  ...,  6.2996e-02,\n",
      "            5.2896e-02,  9.0275e-02],\n",
      "          [ 8.2224e-02,  8.2666e-02,  8.9195e-02,  ...,  9.9163e-02,\n",
      "            1.0582e-01,  1.5603e-01],\n",
      "          [ 1.1048e-02, -4.3189e-04,  1.4019e-02,  ...,  1.9328e-02,\n",
      "            3.8681e-02,  8.7278e-02],\n",
      "          ...,\n",
      "          [-2.9883e-02, -5.4366e-02, -1.1447e-02,  ..., -7.7825e-03,\n",
      "            4.7025e-03,  3.0076e-02],\n",
      "          [-5.2923e-02, -1.0625e-01, -7.1972e-02,  ..., -6.7059e-02,\n",
      "           -4.4120e-02, -2.1843e-02],\n",
      "          [-1.0266e-01, -2.0007e-01, -1.8511e-01,  ..., -1.8086e-01,\n",
      "           -1.4163e-01, -1.0696e-01]],\n",
      "\n",
      "         [[ 3.8626e-02,  5.9833e-02,  6.3666e-02,  ...,  6.9415e-02,\n",
      "            6.8196e-02,  1.0334e-01],\n",
      "          [ 8.7093e-02,  9.0954e-02,  9.5186e-02,  ...,  1.0585e-01,\n",
      "            1.2158e-01,  1.7538e-01],\n",
      "          [ 1.1815e-02, -6.6357e-04,  1.5291e-02,  ...,  2.2548e-02,\n",
      "            4.9274e-02,  1.0383e-01],\n",
      "          ...,\n",
      "          [-4.4813e-02, -7.4258e-02, -2.7346e-02,  ..., -2.0560e-02,\n",
      "           -1.6076e-03,  2.8265e-02],\n",
      "          [-6.2823e-02, -1.1831e-01, -8.0370e-02,  ..., -7.6038e-02,\n",
      "           -4.3525e-02, -1.8571e-02],\n",
      "          [-1.0949e-01, -2.0914e-01, -1.9216e-01,  ..., -1.8956e-01,\n",
      "           -1.4128e-01, -1.0503e-01]],\n",
      "\n",
      "         [[ 4.4019e-02,  7.2691e-02,  7.0099e-02,  ...,  6.1821e-02,\n",
      "            6.3667e-02,  1.0603e-01],\n",
      "          [ 6.3506e-02,  7.5122e-02,  7.2939e-02,  ...,  7.2826e-02,\n",
      "            9.1235e-02,  1.4480e-01],\n",
      "          [-3.2647e-03, -2.7480e-03,  7.7184e-03,  ...,  1.8156e-03,\n",
      "            3.0441e-02,  8.1611e-02],\n",
      "          ...,\n",
      "          [-3.8425e-02, -5.2726e-02, -9.0700e-03,  ..., -1.6659e-02,\n",
      "           -1.4089e-03,  2.2061e-02],\n",
      "          [-4.0022e-02, -8.0716e-02, -4.6680e-02,  ..., -5.7972e-02,\n",
      "           -3.3150e-02, -1.4950e-02],\n",
      "          [-7.1606e-02, -1.5742e-01, -1.4592e-01,  ..., -1.6088e-01,\n",
      "           -1.2090e-01, -8.9758e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3851e-05, -5.1388e-03, -6.9611e-03,  ..., -9.2312e-03,\n",
      "           -5.8066e-03, -5.6668e-03],\n",
      "          [-5.7175e-03, -9.5799e-03, -6.3399e-03,  ..., -1.1623e-02,\n",
      "           -1.7406e-02, -2.3456e-02],\n",
      "          [-6.9436e-04,  7.4017e-05,  2.1436e-03,  ...,  2.7654e-03,\n",
      "            1.2393e-03, -1.2059e-02],\n",
      "          ...,\n",
      "          [ 5.7140e-03,  6.3091e-03,  2.7742e-03,  ..., -2.6989e-03,\n",
      "            3.7459e-03,  4.4359e-04],\n",
      "          [ 2.5032e-03,  6.4125e-03,  8.7315e-03,  ...,  3.9713e-03,\n",
      "            4.9167e-03, -4.9279e-03],\n",
      "          [-8.2829e-03, -8.4867e-03, -4.2958e-04,  ..., -9.0566e-04,\n",
      "           -7.1498e-03, -1.7085e-02]],\n",
      "\n",
      "         [[ 7.9450e-03,  2.1499e-03, -2.8569e-05,  ...,  1.0006e-03,\n",
      "            5.4964e-03,  4.1594e-03],\n",
      "          [-2.5852e-04, -6.7145e-03, -5.0049e-03,  ..., -5.5973e-03,\n",
      "           -7.8611e-03, -1.4269e-02],\n",
      "          [ 3.7832e-05, -4.8212e-03, -5.5848e-03,  ..., -2.4609e-04,\n",
      "            5.1368e-03, -5.2103e-03],\n",
      "          ...,\n",
      "          [ 1.1700e-03, -4.4274e-03, -1.1131e-02,  ..., -1.4617e-02,\n",
      "           -2.2159e-03, -8.4394e-05],\n",
      "          [-5.0638e-04, -1.5732e-03, -2.3659e-03,  ..., -4.9507e-03,\n",
      "            1.5125e-03, -3.7824e-03],\n",
      "          [-7.9370e-03, -1.2061e-02, -6.5091e-03,  ..., -4.7603e-03,\n",
      "           -6.2116e-03, -1.3120e-02]],\n",
      "\n",
      "         [[ 6.3716e-03,  3.0157e-03,  3.0826e-03,  ...,  3.2714e-03,\n",
      "            5.3213e-03,  1.2532e-03],\n",
      "          [ 9.4900e-05, -2.7180e-03,  3.2537e-03,  ...,  1.2759e-03,\n",
      "           -6.3106e-03, -1.6870e-02],\n",
      "          [ 2.4641e-03,  3.5586e-03,  6.7604e-03,  ...,  1.2599e-02,\n",
      "            1.1963e-02, -4.3293e-03],\n",
      "          ...,\n",
      "          [ 4.0135e-03,  4.3051e-03,  1.2907e-03,  ..., -1.1440e-03,\n",
      "            7.8708e-03,  3.7390e-03],\n",
      "          [-2.1054e-03,  6.2654e-04,  5.0873e-03,  ...,  4.3956e-03,\n",
      "            6.1226e-03, -4.5306e-03],\n",
      "          [-1.1776e-02, -1.4425e-02, -4.8474e-03,  ..., -1.7342e-03,\n",
      "           -7.5578e-03, -1.6955e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.9976e-02,  1.7677e-02, -1.3502e-02,  ..., -3.2090e-02,\n",
      "            3.2034e-02,  5.3819e-02],\n",
      "          [ 3.4315e-02, -8.8656e-02, -1.4499e-01,  ..., -1.6078e-01,\n",
      "           -9.2801e-02, -5.7004e-02],\n",
      "          [ 2.8099e-02, -1.1389e-01, -1.8920e-01,  ..., -1.9277e-01,\n",
      "           -1.3910e-01, -9.2072e-02],\n",
      "          ...,\n",
      "          [-1.6143e-02, -1.6994e-01, -2.2683e-01,  ..., -2.5098e-01,\n",
      "           -2.3274e-01, -1.5784e-01],\n",
      "          [ 2.6483e-03, -1.4929e-01, -1.9973e-01,  ..., -2.4162e-01,\n",
      "           -2.1517e-01, -1.3484e-01],\n",
      "          [ 2.4391e-02, -1.0392e-01, -1.5391e-01,  ..., -2.2947e-01,\n",
      "           -1.8617e-01, -1.3282e-01]],\n",
      "\n",
      "         [[-7.3367e-02, -4.0053e-03, -2.4102e-03,  ..., -1.0804e-03,\n",
      "            2.2344e-02,  5.3625e-03],\n",
      "          [-1.2673e-02,  5.5574e-02,  5.4656e-02,  ...,  6.5613e-02,\n",
      "            7.1241e-02,  4.0430e-02],\n",
      "          [ 1.6101e-02,  8.4815e-02,  8.0673e-02,  ...,  1.2248e-01,\n",
      "            9.3187e-02,  6.6656e-02],\n",
      "          ...,\n",
      "          [ 1.7871e-02,  9.9189e-02,  1.3828e-01,  ...,  1.7825e-01,\n",
      "            1.1907e-01,  1.0624e-01],\n",
      "          [ 1.0632e-02,  8.0377e-02,  1.1914e-01,  ...,  1.5232e-01,\n",
      "            1.1538e-01,  1.0982e-01],\n",
      "          [ 7.2481e-03,  7.9847e-02,  1.0168e-01,  ...,  1.0260e-01,\n",
      "            9.6159e-02,  8.8076e-02]],\n",
      "\n",
      "         [[-2.3347e-02,  1.6997e-02,  3.7918e-02,  ...,  1.0495e-02,\n",
      "            1.8406e-03, -3.7381e-02],\n",
      "          [ 4.9583e-03,  6.4961e-02,  9.7891e-02,  ...,  7.1476e-02,\n",
      "            3.8640e-02, -2.8267e-02],\n",
      "          [ 1.1045e-02,  7.9756e-02,  1.1487e-01,  ...,  1.2742e-01,\n",
      "            5.6380e-02, -9.8948e-03],\n",
      "          ...,\n",
      "          [-9.1592e-03,  6.1470e-02,  1.3545e-01,  ...,  1.7218e-01,\n",
      "            8.5654e-02,  3.0111e-02],\n",
      "          [-1.9313e-02,  3.2508e-02,  9.7970e-02,  ...,  1.3184e-01,\n",
      "            6.9249e-02,  3.8224e-02],\n",
      "          [-3.4648e-02,  1.6059e-02,  6.5021e-02,  ...,  6.9663e-02,\n",
      "            4.4823e-02,  6.9932e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5959e-02, -2.2781e-02, -5.1724e-02,  ...,  4.8728e-02,\n",
      "            3.7282e-02, -1.4559e-02],\n",
      "          [ 7.3093e-02,  4.8740e-02, -1.7610e-03,  ...,  1.2513e-01,\n",
      "            1.7406e-01,  8.4572e-02],\n",
      "          [-1.9429e-02, -5.0266e-02, -1.5404e-01,  ..., -4.3246e-02,\n",
      "            1.8491e-01,  1.5097e-01],\n",
      "          ...,\n",
      "          [ 1.1009e-01,  2.1606e-01,  2.5129e-01,  ..., -3.8430e-01,\n",
      "           -2.5213e-01, -3.6368e-02],\n",
      "          [-8.1772e-03,  6.6588e-02,  2.2123e-01,  ..., -7.7344e-03,\n",
      "           -1.0639e-01, -6.1465e-02],\n",
      "          [-6.1750e-02, -5.9904e-02,  5.7955e-03,  ...,  6.0510e-02,\n",
      "           -1.8456e-02, -8.1224e-03]],\n",
      "\n",
      "         [[-1.3817e-02, -4.6388e-02, -8.3044e-02,  ...,  4.9043e-02,\n",
      "            1.3418e-02, -2.5184e-02],\n",
      "          [ 3.4268e-02,  2.5061e-02, -2.4925e-02,  ...,  1.2632e-01,\n",
      "            1.3637e-01,  6.8987e-02],\n",
      "          [-6.6650e-02, -6.0815e-02, -1.5914e-01,  ..., -4.3801e-02,\n",
      "            1.5636e-01,  1.2346e-01],\n",
      "          ...,\n",
      "          [ 6.5523e-02,  1.7007e-01,  2.1636e-01,  ..., -3.7380e-01,\n",
      "           -2.5011e-01, -4.3482e-02],\n",
      "          [-1.5093e-02,  6.9171e-02,  2.1948e-01,  ...,  7.0715e-03,\n",
      "           -9.1238e-02, -4.4441e-02],\n",
      "          [-5.4593e-02, -5.6394e-02,  7.0060e-03,  ...,  7.6810e-02,\n",
      "           -1.6184e-02, -1.8822e-02]],\n",
      "\n",
      "         [[-2.6435e-03, -4.1603e-02, -5.0977e-02,  ...,  7.9230e-02,\n",
      "           -3.4722e-02, -8.1594e-02],\n",
      "          [ 3.3993e-02,  1.6162e-02, -9.9984e-03,  ...,  1.7128e-01,\n",
      "            9.5003e-02, -2.0513e-02],\n",
      "          [-7.5674e-02, -8.8879e-02, -1.6136e-01,  ...,  2.0527e-02,\n",
      "            1.4138e-01,  8.0881e-02],\n",
      "          ...,\n",
      "          [ 6.5248e-02,  1.4906e-01,  2.2779e-01,  ..., -3.1671e-01,\n",
      "           -2.5965e-01, -3.1953e-02],\n",
      "          [-1.9507e-02,  3.8509e-02,  2.1796e-01,  ...,  7.7891e-02,\n",
      "           -9.8168e-02, -4.2811e-02],\n",
      "          [-3.8234e-02, -7.9571e-02, -3.3670e-03,  ...,  1.3745e-01,\n",
      "           -2.7734e-02, -1.0797e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4641e-03,  2.4575e-02,  1.9870e-02,  ..., -6.9253e-02,\n",
      "            8.5802e-02, -6.1547e-02],\n",
      "          [ 2.9205e-02,  2.9544e-02,  4.5863e-02,  ..., -9.3010e-02,\n",
      "            2.4296e-01,  1.5191e-01],\n",
      "          [ 3.0289e-05,  3.4767e-02,  7.0735e-02,  ..., -4.3211e-01,\n",
      "            6.1340e-02,  2.6587e-01],\n",
      "          ...,\n",
      "          [-2.7475e-02,  3.5094e-04,  3.1092e-01,  ...,  7.4677e-02,\n",
      "           -2.1147e-01, -1.0063e-01],\n",
      "          [-7.1452e-02, -2.0537e-01, -8.5382e-02,  ...,  2.2172e-01,\n",
      "            3.9995e-02,  4.2269e-02],\n",
      "          [ 2.3089e-02, -8.9372e-02, -1.6531e-01,  ...,  6.5575e-02,\n",
      "           -1.5440e-02,  1.9421e-02]],\n",
      "\n",
      "         [[ 6.5726e-03,  2.0131e-02,  2.2212e-02,  ..., -2.2398e-02,\n",
      "            1.1967e-01, -4.3554e-02],\n",
      "          [ 1.4263e-02,  9.8440e-04,  1.1572e-02,  ..., -5.8042e-02,\n",
      "            2.5025e-01,  1.3321e-01],\n",
      "          [-2.0444e-02,  1.9435e-03,  2.8919e-02,  ..., -4.0156e-01,\n",
      "            7.3241e-02,  2.7032e-01],\n",
      "          ...,\n",
      "          [-6.1282e-03, -4.6618e-03,  2.8513e-01,  ...,  6.6178e-02,\n",
      "           -2.0297e-01, -8.2933e-02],\n",
      "          [-4.3037e-02, -1.9918e-01, -1.2977e-01,  ...,  1.6873e-01,\n",
      "            1.4999e-05,  2.1241e-02],\n",
      "          [ 6.9180e-02, -8.4388e-02, -1.9006e-01,  ...,  1.8596e-02,\n",
      "           -5.0552e-02, -2.5623e-02]],\n",
      "\n",
      "         [[ 3.9642e-02,  2.3592e-02,  2.7653e-02,  ..., -4.7381e-04,\n",
      "            7.9600e-02, -8.7420e-02],\n",
      "          [ 1.0998e-02, -2.9019e-02,  3.4720e-03,  ..., -3.6706e-02,\n",
      "            2.1405e-01,  8.0661e-02],\n",
      "          [-2.0017e-02, -4.0939e-02,  1.3184e-02,  ..., -3.9863e-01,\n",
      "            6.6926e-02,  2.5533e-01],\n",
      "          ...,\n",
      "          [ 3.6544e-02, -3.2384e-02,  2.7928e-01,  ...,  1.0118e-01,\n",
      "           -2.0056e-01, -2.4346e-02],\n",
      "          [-1.3966e-02, -2.3707e-01, -1.5910e-01,  ...,  1.8324e-01,\n",
      "           -2.7972e-02,  5.2645e-02],\n",
      "          [ 1.2300e-01, -6.3130e-02, -1.6206e-01,  ...,  4.0565e-02,\n",
      "           -7.6036e-02,  5.8198e-03]]]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Print to make sure model1 and model2 are different, so loading is actually doing something.\n",
    "print(list(list(model2._model.children())[0].parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to examine layers, children, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model, trainable):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad == trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Bottleneck(\n",
       "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Bottleneck(\n",
       "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (2): Bottleneck(\n",
       "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model._model.children())[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning batch norm parameters only.\n",
    "model._model.eval()\n",
    "model.set_requires_grad(False)\n",
    "for layer in model._model.modules():\n",
    "    if isinstance(layer,nn.modules.batchnorm.BatchNorm2d): \n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "count_parameters(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225344"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._model.eval()\n",
    "model.set_requires_grad(False)\n",
    "num_layers_fine_tune = 5\n",
    "for child in list(model._model.children())[:num_layers_fine_tune]:\n",
    "    for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "count_parameters(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_params(layers):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        for param in layer.parameters():\n",
    "            params.append(param)\n",
    "    return params\n",
    "\n",
    "base_params = get_params(list(model._model.children())[:-1])\n",
    "fc_params = get_params(list(model._model.children())[-1:])\n",
    "len(base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1',\n",
       "  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n",
       " ('bn1',\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('relu', ReLU(inplace=True)),\n",
       " ('maxpool',\n",
       "  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n",
       " ('layer1',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer2',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer3',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer4',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('avgpool', AdaptiveAvgPool2d(output_size=(1, 1))),\n",
       " ('fc', Linear(in_features=2048, out_features=1000, bias=True))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model._model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "swav_path = '/u/scr/ananya/simclr_weights/swav_800ep_pretrain.pth.tar'\n",
    "model = imnet_resnet.ResNet50(pretrained=True, pretrain_style='swav', checkpoint_path=swav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (_model): Sequential(\n",
       "    (resnet): ResNet(\n",
       "      (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0b6305c33951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munlabeled_extrapolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbreeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mentity30\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBreeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/u/scr/nlp/imagenet/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreeds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entity30'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trans' is not defined"
     ]
    }
   ],
   "source": [
    "from unlabeled_extrapolation.datasets import breeds\n",
    "entity30 = breeds.Breeds(root='/u/scr/nlp/imagenet/', breeds_name='entity30', transform=trans, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "trans = transforms.Compose(\n",
    "[\n",
    "    transforms.Resize(size=[224,224]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "x = torch.unsqueeze(trans(entity30[0][0]), axis=0)\n",
    "x = x.cuda()\n",
    "print(x.shape)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "z = model._model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(entity30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "1\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "2\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "3\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "4\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)\n",
    "    loader = torch.utils.data.DataLoader(entity30, batch_size=64,shuffle=True, num_workers=2)\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            print('hi')\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            outputs = model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
