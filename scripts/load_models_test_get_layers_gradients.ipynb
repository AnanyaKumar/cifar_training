{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unlabeled_extrapolation.models.imnet_resnet' from '/juice/scr/ananya/cifar_experiments/transfer_learning/unlabeled_extrapolation/models/imnet_resnet.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unlabeled_extrapolation.models import bit_resnet, vit_model, timm_model, clip_model, imnet_resnet\n",
    "from unlabeled_extrapolation.utils import utils\n",
    "import importlib\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "importlib.reload(bit_resnet)\n",
    "importlib.reload(vit_model)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(timm_model)\n",
    "importlib.reload(clip_model)\n",
    "importlib.reload(imnet_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/juice/scr/ananya/cifar_experiments/transfer_learning/scripts', '/juice/scr/ananya/cifar_experiments/transfer_learning/scripts', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python38.zip', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/lib-dynload', '', '/sailhome/ananya/.local/lib/python3.8/site-packages', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/site-packages', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/site-packages/apex-0.1-py3.8-linux-x86_64.egg', '/juice/scr/ananya/cifar_experiments/wilds', '/juice/scr/ananya/cifar_experiments/transfer_learning', '/juice/scr/ananya/verified_calibration', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/site-packages/IPython/extensions', '/sailhome/ananya/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers_freeze_test(model):\n",
    "    print('num params before freezing: ', utils.count_parameters(model, trainable=True))\n",
    "    print(model.get_layers()[1])\n",
    "    print(len(model.get_layers()))\n",
    "    for k in [1, 2, len(model.get_layers())]:\n",
    "        model.freeze_bottom_k(k=k)\n",
    "        print(f'num params after freezing {k}: {utils.count_parameters(model, trainable=True)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4314, grad_fn=<DotBackward>)\n",
      "tensor([[ 0.1264,  0.1806,  0.1987],\n",
      "        [-0.5067, -0.7239, -0.7963],\n",
      "        [ 0.3803,  0.5433,  0.5976]])\n"
     ]
    }
   ],
   "source": [
    "data = np.array([0.1, 0.4, 0.5], dtype=np.float32)+0.6\n",
    "x = torch.tensor(data)\n",
    "layer_norm = nn.LayerNorm(len(data), elementwise_affine=False)\n",
    "A = torch.eye(len(data), requires_grad=True)\n",
    "output = layer_norm(torch.matmul(A, x))\n",
    "loss = torch.dot(torch.tensor([0.1, 0.2, 0.5]), output) # torch.sum(torch.square(output))\n",
    "loss.backward()\n",
    "print(loss)\n",
    "print(A.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.0826, -18.0283, -18.0102],\n",
      "        [ 72.3376,  72.1204,  72.0480],\n",
      "        [-54.2588, -54.0958, -54.0415]])\n"
     ]
    }
   ],
   "source": [
    "data = np.array([0.1, 0.4, 0.5], dtype=np.float32) - 100.0\n",
    "x = torch.tensor(data)\n",
    "A = torch.eye(len(data), requires_grad=True)\n",
    "z = torch.matmul(A, x)\n",
    "z.retain_grad()\n",
    "mu = torch.mean(z)\n",
    "mu.retain_grad()\n",
    "sigma = torch.sqrt(torch.std(z, unbiased=False) ** 2)\n",
    "sigma.retain_grad()\n",
    "o = (z - mu) / sigma\n",
    "o.retain_grad()\n",
    "l = torch.dot(torch.tensor([0.1, 0.2, 0.5]), o)\n",
    "# l.backward()\n",
    "# print(A.grad)\n",
    "l.backward()\n",
    "print(A.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get norms and gradients for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clip_model.ClipModel('ViT-L/14')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clip_model.ClipModel('ViT-B/16')\n",
    "model.new_last_layer(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# print(list(model.get_layers()[0][1].parameters())[0].requires_grad)\n",
    "# inputs = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "def get_clip_mean_input():\n",
    "    inputs = torch.tensor([0.48145466, 0.4578275, 0.40821073])\n",
    "    inputs = inputs.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "    inputs = inputs.tile([1, 1, 224, 224])\n",
    "    return inputs\n",
    "\n",
    "def get_clip_dist_input():\n",
    "    inputs = torch.tensor([0.48145466, 0.4578275, 0.40821073])\n",
    "    inputs = inputs.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "    inputs = inputs.tile([1, 1, 224, 224])\n",
    "    return inputs\n",
    "\n",
    "inputs = torch.tensor([0.48145466, 0.4578275, 0.40821073])\n",
    "inputs = inputs.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "inputs = inputs.tile([1, 1, 224, 224])\n",
    "print(inputs.shape)\n",
    "inputs = inputs.cuda()\n",
    "model.cuda()\n",
    "outputs = model(inputs)\n",
    "loss = torch.sum(torch.square(outputs))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.54964256286621, 2.6062560390040383, 7.567190647125244, 1.0375860929489136, 0.26622636570179553, 9.328513982084095, 0.2186721176275342, 17.19362955770947, 0.26272152142902877, 9.570395973223832, 0.33883179052500684, 17.063759606866164, 0.4135279331824097, 19.316852593622446, 0.348065239809437, 23.211175772550735, 0.2866482939208723, 21.411272157777947, 0.2982341959606744, 32.02183701601188, 0.7350253231739102, 23.98497888947061, 0.3489564675414618, 36.33611495543812, 0.3906924973175038, 26.982765200703604, 0.4056054973737743, 39.959679978199176, 0.46362568149293487, 25.90123800988363, 0.2922789139876288, 40.1849475230448, 1.12168652906377, 28.275337317915774, 0.2797527143483323, 48.489088348578655, 0.5411435171208155, 21.4489124869876, 0.23895772899326645, 34.997931414576485, 1.7938492117508384, 21.208721582016143, 0.16792367077919937, 30.11186549644565, 2.420525364382956, 19.86338208946117, 0.4717152135407727, 27.1885166259501, 1.0686553663789327, 34.53155986991048, 0.2615572246974295, 33.576464443434766, 1.2850386157480747, 13.470720567165724]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_grad_layer(cur_layer):\n",
    "    grads = [p.grad.detach().cpu().numpy() for p in cur_layer.parameters()]\n",
    "    grad_norms_squared = [np.linalg.norm(g) ** 2 for g in grads]\n",
    "    grad_norm = np.sqrt(np.sum(grad_norms_squared))\n",
    "    return grad_norm\n",
    "\n",
    "def get_norm_layer(cur_layer):\n",
    "    norms_squared = [np.linalg.norm(p.data.detach().cpu().numpy()) ** 2 for p in cur_layer.parameters()]\n",
    "    norm = np.sqrt(np.sum(norms_squared))\n",
    "    return norm\n",
    "\n",
    "def get_layer_grads(model):\n",
    "    named_layers = model.get_layers()\n",
    "    names, layers = zip(*named_layers)\n",
    "    norms = [get_norm_layer(l) for l in layers]\n",
    "    grad_norms = [get_grad_layer(l) for l in layers]\n",
    "    return norms, grad_norms\n",
    "\n",
    "norms, grad_norms = get_layer_grads(model)\n",
    "print(grad_norms)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test get layers for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convnext\n",
    "\n",
    "convnext = timm_model.TimmModel('convnext_base_in22k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num layers:  7\n",
      "no. of params in layer 0 (stem): 6528\n",
      "no. of params in layer 1 (stage0): 415488\n",
      "no. of params in layer 2 (stage1): 1748992\n",
      "no. of params in layer 3 (stage2): 57950208\n",
      "no. of params in layer 4 (stage3): 27443200\n",
      "no. of params in layer 5 (post_norm): 2048\n",
      "no. of params in layer 6 (head): 22387025\n",
      "109953489\n"
     ]
    }
   ],
   "source": [
    "layers = convnext.get_layers()\n",
    "print('num layers: ', len(layers))\n",
    "total_count = 0\n",
    "for i in range(len(layers)):\n",
    "    num_params = utils.count_parameters(layers[i][1], trainable=False) + utils.count_parameters(layers[i][1], trainable=True)\n",
    "    total_count += num_params\n",
    "    print(f'no. of params in layer {i} ({layers[i][0]}): {num_params}')\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  68256659\n",
      "('conv-block-0', Sequential(\n",
      "  (unit01): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (unit02): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (unit03): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "6\n",
      "num params after freezing 1: 68247251\n",
      "num params after freezing 2: 68032339\n",
      "num params after freezing 6: 0\n",
      "num params before freezing:  87248787\n",
      "('conv-block-0', Sequential(\n",
      "  (unit01): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (unit02): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (unit03): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "6\n",
      "num params after freezing 1: 87239379\n",
      "num params after freezing 2: 87024467\n",
      "num params after freezing 6: 0\n"
     ]
    }
   ],
   "source": [
    "# Bit-resnet (get layers) for ResNet-50 and ResNet-101\n",
    "\n",
    "resnet50_checkpoint_path = \"/u/scr/ananya/simclr_weights/BiT-M-R50x1.npz\"\n",
    "resnet50 = bit_resnet.BitResNet(model_name='BiT-M-R50x1', checkpoint_path=resnet50_checkpoint_path)\n",
    "get_layers_freeze_test(resnet50)\n",
    "\n",
    "resnet101_checkpoint_path = \"/u/scr/ananya/simclr_weights/BiT-M-R101x1.npz\"\n",
    "resnet101 = bit_resnet.BitResNet(model_name='BiT-M-R101x1', checkpoint_path=resnet101_checkpoint_path)\n",
    "get_layers_freeze_test(resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dino/archive/main.zip\" to /sailhome/ananya/.cache/torch/hub/main.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  85806346\n",
      "('empty_ln_pre', Module())\n",
      "54\n",
      "1\n",
      "num params after freezing 1: 85215754\n",
      "2\n",
      "num params after freezing 2: 85215754\n",
      "54\n",
      "num params after freezing 54: 0\n"
     ]
    }
   ],
   "source": [
    "# DINO\n",
    "model = vit_model.VitModel(model_name='dino_vitb16')\n",
    "model.new_last_layer(10)\n",
    "get_layers_freeze_test(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  22050664\n",
      "('empty_ln_pre', Module())\n",
      "54\n",
      "num params after freezing 1: 21755368\n",
      "num params after freezing 2: 21755368\n",
      "num params after freezing 54: 0\n"
     ]
    }
   ],
   "source": [
    "# Timm ViT-S\n",
    "model = vit_model.VitModel(model_name='timm.vit_small_patch16_224')\n",
    "get_layers_freeze_test(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed 26.6946963982087\n",
      "empty_ln_pre 0.0\n",
      "pos_embed 114.1449203491211\n",
      "cls_token 11.814652442932129\n",
      "trans0_norm1 10.727939400443407\n",
      "trans0_attn 51.44874777832921\n",
      "trans0_norm2 28.292761646663003\n",
      "trans0_mlp 76.65611477620195\n",
      "trans1_norm1 11.67158919875855\n",
      "trans1_attn 51.968497785989186\n",
      "trans1_norm2 16.081294584238012\n",
      "trans1_mlp 72.49136824958491\n",
      "trans2_norm1 14.588461930309668\n",
      "trans2_attn 47.43609999667546\n",
      "trans2_norm2 16.750402005493847\n",
      "trans2_mlp 73.4898046975493\n",
      "trans3_norm1 17.127796509537827\n",
      "trans3_attn 46.12080652841503\n",
      "trans3_norm2 16.560562623359647\n",
      "trans3_mlp 73.75539281539531\n",
      "trans4_norm1 16.38613601236467\n",
      "trans4_attn 45.396057461621595\n",
      "trans4_norm2 15.56170805432499\n",
      "trans4_mlp 74.04262678751516\n",
      "trans5_norm1 15.666596993058972\n",
      "trans5_attn 45.22580724285582\n",
      "trans5_norm2 16.125041315399216\n",
      "trans5_mlp 74.32087040062893\n",
      "trans6_norm1 16.50691386925591\n",
      "trans6_attn 44.89644589636653\n",
      "trans6_norm2 16.870073778570866\n",
      "trans6_mlp 78.20890488715406\n",
      "trans7_norm1 16.66077125665377\n",
      "trans7_attn 45.82781002989781\n",
      "trans7_norm2 19.266974095400364\n",
      "trans7_mlp 81.80467684677028\n",
      "trans8_norm1 17.5644882043329\n",
      "trans8_attn 47.610578568992075\n",
      "trans8_norm2 43.14843316111718\n",
      "trans8_mlp 81.65995954456746\n",
      "trans9_norm1 19.72671889415036\n",
      "trans9_attn 48.02174698323452\n",
      "trans9_norm2 65.44239677355796\n",
      "trans9_mlp 85.10741788908027\n",
      "trans10_norm1 23.690038485002656\n",
      "trans10_attn 47.81185122297828\n",
      "trans10_norm2 173.51592363743683\n",
      "trans10_mlp 96.2868619031599\n",
      "trans11_norm1 29.018153114479592\n",
      "trans11_attn 53.61129902293072\n",
      "trans11_norm2 24.21393277393142\n",
      "trans11_mlp 84.18814129510835\n",
      "post_norm 48.72875120683025\n",
      "head 17.718359892033757\n"
     ]
    }
   ],
   "source": [
    "# Get model grads and norms for Timm ViT-S\n",
    "layers = model.get_layers()\n",
    "\n",
    "for name, layer in layers:\n",
    "    norms_squared = [np.linalg.norm(p.data.detach().cpu().numpy()) ** 2 for p in layer.parameters()]\n",
    "    norm = np.sqrt(np.sum(norms_squared))\n",
    "    print(name, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  109953489\n",
      "('stage0', ConvNeXtStage(\n",
      "  (downsample): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (1): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (2): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "))\n",
      "7\n",
      "num params after freezing 1: 109946961\n",
      "num params after freezing 2: 109531473\n",
      "num params after freezing 7: 0\n"
     ]
    }
   ],
   "source": [
    "# Conv-next\n",
    "model = timm_model.TimmModel('convnext_base_in22k')\n",
    "get_layers_freeze_test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        ...,\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros((8,3,224,224))\n",
    "x = x.cuda()\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
      "  (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      "  (fc): Linear(in_features=1024, out_features=21841, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._model.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = imnet_resnet.ResNet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stem',\n",
       "  ModuleList(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )),\n",
       " ('layer1',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer2',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer3',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer4',\n",
       "  Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )),\n",
       " ('avgpool', AdaptiveAvgPool2d(output_size=(1, 1))),\n",
       " ('head', Linear(in_features=2048, out_features=1000, bias=True))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
