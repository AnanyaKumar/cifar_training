{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unlabeled_extrapolation.models' from '/juice/scr/ananya/cifar_experiments/unlabeled_extrapolation/unlabeled_extrapolation/models/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can load files from other sub-directories, e.g. datasets.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path = [module_path] + sys.path\n",
    "module_path = os.path.abspath(os.path.join('../unlabeled_extrapolation'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path = [module_path] + sys.path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "import quinine\n",
    "from unlabeled_extrapolation.baseline_train import preprocess_config, get_all_test_stats, get_test_loaders, build_model\n",
    "from unlabeled_extrapolation.log_reg_sk import inv_normalize_weights\n",
    "import unlabeled_extrapolation.utils.utils as utils\n",
    "import unlabeled_extrapolation.datasets.breeds\n",
    "\n",
    "import calibration as cal\n",
    "import unlabeled_extrapolation\n",
    "import unlabeled_extrapolation.models\n",
    "import pickle\n",
    "\n",
    "import importlib\n",
    "importlib.reload(unlabeled_extrapolation.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sklearn weights.\n",
    "path = '/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_domainnet_clip_resnet50/weights_0.pkl'\n",
    "coef, intercept, best_c, best_i = pickle.load( open( path, \"rb\" ) )\n",
    "# TODO: important, this is not needed long term so comment this line and uncomment the next line.\n",
    "# Only used as a stop-grab because we didn't apply this before saving.\n",
    "# new_coef, new_intercept = inv_normalize_weights(coef, intercept, features, 0)\n",
    "new_coef, new_intercept = coef, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get moco model, and initialize datasets.\n",
    "config_path = '/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/configs/adaptation/domainnet.yaml'\n",
    "config = quinine.Quinfig(config_path)\n",
    "preprocess_config(config, config_path)\n",
    "if not(config.train_dataset.classname.startswith('unlabeled_extrapolation.')):\n",
    "    config.train_dataset.classname = 'unlabeled_extrapolation.' + config.train_dataset.classname\n",
    "for test_dataset_config in config.test_datasets:\n",
    "    if not(test_dataset_config.classname.startswith('unlabeled_extrapolation.')):\n",
    "        test_dataset_config.classname = 'unlabeled_extrapolation.' + test_dataset_config.classname\n",
    "net = build_model(config)\n",
    "net.cuda()\n",
    "test_loaders, max_examples = get_test_loaders(config, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert sklearn model into pytorch.\n",
    "net.set_last_layer(new_coef, new_intercept)\n",
    "# coef_tensor = torch.tensor(new_coef, dtype=net._model.fc.weight.dtype).cuda()\n",
    "# bias_tensor = torch.tensor(new_intercept, dtype=net._model.fc.bias.dtype).cuda()\n",
    "# coef_param = torch.nn.parameter.Parameter(coef_tensor)\n",
    "# bias_param = torch.nn.parameter.Parameter(bias_tensor)\n",
    "# net._model.fc.weight = coef_param\n",
    "# net._model.fc.bias = bias_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': -1,\n",
       " 'test_loss/sketch_val': 0.40156289572386367,\n",
       " 'test_acc/sketch_val': 0.8928720300125053,\n",
       " 'test_loss/real_val': 0.47401880225542625,\n",
       " 'test_acc/real_val': 0.8736857266311393,\n",
       " 'test_loss/painting_val': 0.8756483087073201,\n",
       " 'test_acc/painting_val': 0.7490546579580611,\n",
       " 'test_loss/clipart_val': 0.879862503363536,\n",
       " 'test_acc/clipart_val': 0.7741336633663366}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test accuracies.\n",
    "device = 'cuda'\n",
    "criterion = utils.initialize(config['criterion']) \n",
    "get_all_test_stats(\n",
    "    epoch=-1, test_loaders=test_loaders, max_test_examples=max_examples,\n",
    "    config=config, net=net, criterion=criterion, device=device,\n",
    "    loss_name_prefix='test_loss/', acc_name_prefix='test_acc/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check this, let's load features and test weights using sklearn.\n",
    "features_path = '/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/logs/linprobe_living17_resnet50/features_0'\n",
    "features, labels, loader_names = pickle.load( open( features_path, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef, new_intercept = inv_normalize_weights(coef, intercept, features, 0)\n",
    "clf = LogisticRegression(random_state=0, warm_start=True)\n",
    "clf.coef_ = new_coef\n",
    "clf.intercept_ = new_intercept\n",
    "clf.classes_ = np.array(list(range(17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9647058823529412\n",
      "0.8194117647058824\n"
     ]
    }
   ],
   "source": [
    "for idx in [1, 2]:\n",
    "    preds = clf.predict(features[idx])\n",
    "    print(np.mean(preds == labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
