{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can load files from other sub-directories, e.g. datasets.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import utils.utils as utils\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "import calibration as cal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'cuda is available: {torch.cuda.is_available()}')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "cuda = torch.device('cuda') \n",
    "batch_size, num_workers = 32, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(config_path, checkpoint_path):\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    net = utils.initialize(config['model'])\n",
    "    if USE_CUDA:\n",
    "        net = net.cuda()\n",
    "    net.new_last_layer(config['num_classes'])\n",
    "    utils.load_ckp(checkpoint_path, net)\n",
    "    return net\n",
    "\n",
    "# Load datasets.\n",
    "def load_test_dataset(config, idx, split_arg_name='split', split='val'):\n",
    "    test_config = config['test_datasets'][idx]\n",
    "    test_config['args'][split_arg_name] = split\n",
    "    print(test_config['name'], test_config)\n",
    "    if 'transforms' not in test_config:\n",
    "        test_config['transforms'] = config['default_test_transforms']\n",
    "    test_data = utils.init_dataset(test_config)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size,\n",
    "        shuffle=False, num_workers=num_workers)\n",
    "    return test_data, test_loader\n",
    "\n",
    "def get_features_labels(net, loader):\n",
    "    net.cuda()\n",
    "    net.eval()\n",
    "    feature_model = nn.Sequential(*list(net._model.children())[:-1])\n",
    "    features_list, labels_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            features = feature_model(images)\n",
    "            features_list.append(features.detach().cpu().numpy())\n",
    "            labels_list.append(labels.detach().cpu().numpy())\n",
    "    features = np.squeeze(np.concatenate(features_list))\n",
    "    labels = np.concatenate(labels_list)\n",
    "    return features, labels\n",
    "\n",
    "def get_acc(preds, labels):\n",
    "    return np.mean(preds == labels)\n",
    "\n",
    "def make_none_list(rs, cs):\n",
    "    return [[None] * cs for _ in range(rs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a network how to get representations\n",
    "def get_model_representations(\n",
    "    config_paths, checkpoint_paths, model_names, loader_names, loader_indices, split_arg_names, split_names):\n",
    "    M, L = len(model_names), len(loader_names)\n",
    "    models = []\n",
    "    for m in range(M):\n",
    "        models.append(load_model(config_paths[m], checkpoint_paths[m]))\n",
    "\n",
    "    with open(config_paths[0]) as f:\n",
    "        config = json.load(f)\n",
    "    loaders = []\n",
    "    for l in range(L):\n",
    "        _, loader = load_test_dataset(config, loader_indices[l], split_arg_names[l], split_names[l])\n",
    "        loaders.append(loader)\n",
    "    features, labels = make_none_list(M, L), make_none_list(M, L)\n",
    "    for m in range(M):\n",
    "        for l in range(L):\n",
    "            features[m][l], labels[m][l] = get_features_labels(models[m], loaders[l])    \n",
    "    return features, labels\n",
    "        \n",
    "def get_test_accs(features, labels, C=1.0):\n",
    "    M, L = len(features), len(features[0])\n",
    "    assert(L == 2)  # Only support train on first, validate on second for now\n",
    "    clfs = []\n",
    "    preds = []\n",
    "    accs = []\n",
    "    for m in range(M):\n",
    "        cur_clf = LogisticRegression(random_state=0, C=C).fit(features[m][0], labels[m][0])\n",
    "        cur_preds = cur_clf.predict(features[m][1])\n",
    "        cur_acc = get_acc(cur_preds, labels[m][1])\n",
    "        print(cur_acc)\n",
    "        clfs.append(cur_clf)\n",
    "        preds.append(cur_preds)\n",
    "        accs.append(cur_acc)\n",
    "    return clfs, preds, accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val_living {'name': 'target_val_living', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': False, 'split': 'train', 'breeds_name': 'living17', 'root': '/u/scr/nlp/imagenet/'}}\n",
      "target_val_living {'name': 'target_val_living', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': False, 'split': 'val', 'breeds_name': 'living17', 'root': '/u/scr/nlp/imagenet/'}, 'transforms': [{'classname': 'torchvision.transforms.Resize', 'args': {'size': [224, 224]}}, {'classname': 'torchvision.transforms.ToTensor'}, {'classname': 'torchvision.transforms.Normalize', 'args': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]}\n",
      "source_val_living {'name': 'source_val_living', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': True, 'split': 'train', 'breeds_name': 'living17', 'root': '/u/scr/nlp/imagenet/'}}\n",
      "source_val_living {'name': 'source_val_living', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': True, 'split': 'val', 'breeds_name': 'living17', 'root': '/u/scr/nlp/imagenet/'}, 'transforms': [{'classname': 'torchvision.transforms.Resize', 'args': {'size': [224, 224]}}, {'classname': 'torchvision.transforms.ToTensor'}, {'classname': 'torchvision.transforms.Normalize', 'args': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]}\n"
     ]
    }
   ],
   "source": [
    "# Living17 MOCO\n",
    "\n",
    "config_paths = [\n",
    "    '../logs/breeds_moco_ft_0.003/config.json',\n",
    "]\n",
    "\n",
    "checkpoint_paths = [\n",
    "    '../logs/breeds_moco_ft_0.003/checkpoints/ckp_0',\n",
    "]\n",
    "\n",
    "model_names = ['original_model']\n",
    "loader_names = ['l17_trg_train', 'l17_trg_val', 'l17_src_train', 'l17_src_val']\n",
    "split_names = ['train', 'val', 'train', 'val']\n",
    "split_arg_names = ['split', 'split', 'split', 'split']\n",
    "loader_indices = [1, 1, 0, 0]  # Relative to the config file in the first config path in config_paths.\n",
    "\n",
    "features, labels = get_model_representations(\n",
    "    config_paths, checkpoint_paths, model_names, loader_names, loader_indices,\n",
    "    split_arg_names, split_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_val_entity {'name': 'target_val_entity', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': False, 'split': 'train', 'breeds_name': 'entity30', 'root': '/u/scr/nlp/imagenet/'}}\n",
      "target_val_entity {'name': 'target_val_entity', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': False, 'split': 'val', 'breeds_name': 'entity30', 'root': '/u/scr/nlp/imagenet/'}, 'transforms': [{'classname': 'torchvision.transforms.Resize', 'args': {'size': [224, 224]}}, {'classname': 'torchvision.transforms.ToTensor'}, {'classname': 'torchvision.transforms.Normalize', 'args': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]}\n",
      "source_val_entity {'name': 'source_val_entity', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': True, 'split': 'train', 'breeds_name': 'entity30', 'root': '/u/scr/nlp/imagenet/'}}\n",
      "source_val_entity {'name': 'source_val_entity', 'max_test_examples': 1000, 'classname': 'datasets.breeds.Breeds', 'args': {'source': True, 'split': 'val', 'breeds_name': 'entity30', 'root': '/u/scr/nlp/imagenet/'}, 'transforms': [{'classname': 'torchvision.transforms.Resize', 'args': {'size': [224, 224]}}, {'classname': 'torchvision.transforms.ToTensor'}, {'classname': 'torchvision.transforms.Normalize', 'args': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}]}\n"
     ]
    }
   ],
   "source": [
    "# Entity 30 MOCO\n",
    "\n",
    "config_paths = [\n",
    "    '../logs/entity30_moco_ft_0.003/config.json',\n",
    "]\n",
    "\n",
    "checkpoint_paths = [\n",
    "    '../logs/entity30_moco_ft_0.003/checkpoints/ckp_0',\n",
    "]\n",
    "\n",
    "model_names = ['original_model']\n",
    "loader_names = ['e30_trg_train', 'e30_trg_val', 'e30_src_train', 'e30_src_val']\n",
    "split_names = ['train', 'val', 'train', 'val']\n",
    "split_arg_names = ['split', 'split', 'split', 'split']\n",
    "loader_indices = [1, 1, 0, 0]  # Relative to the config file in the first config path in config_paths.\n",
    "\n",
    "e30_features, e30_labels = get_model_representations(\n",
    "    config_paths, checkpoint_paths, model_names, loader_names, loader_indices,\n",
    "    split_arg_names, split_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On CIFAR, Im-n-C10\n",
    "\n",
    "# config_paths = [\n",
    "#     '../logs/imnet_cifar_all_ft_0d01/config.json',\n",
    "# ]\n",
    "\n",
    "# checkpoint_paths = [\n",
    "#     '../logs/imnet_cifar_all_ft_0d01/checkpoints/ckp_0',\n",
    "# ]\n",
    "\n",
    "# model_names = ['original_model']\n",
    "# loader_names = ['e30_trg_train', 'e30_trg_val', 'e30_src_train', 'e30_src_val']\n",
    "# split_names = ['train', 'val', 'train', 'val']\n",
    "# split_arg_names = ['split', 'split', 'split', 'split']\n",
    "# loader_indices = [4, 4, 0, 0]  # Relative to the config file in the first config path in config_paths.\n",
    "\n",
    "# e30_features, e30_labels = get_model_representations(\n",
    "#     config_paths, checkpoint_paths, model_names, loader_names, loader_indices,\n",
    "#     split_arg_names, split_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021199878"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(features[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression\n",
    "def test_log_reg(features, labels, source_idx, test_indices, C=1.0, sgd=False):\n",
    "    M, L = len(features), len(features[0])\n",
    "    m = 0\n",
    "    if not sgd:\n",
    "        cur_clf = LogisticRegression(random_state=0, C=C).fit(features[m][source_idx], labels[m][source_idx])\n",
    "    else:\n",
    "        cur_clf = SGDClassifier(max_iter=10, loss='log', random_state=0, alpha=0.0, eta0=0.01, learning_rate='constant').fit(features[m][source_idx], labels[m][source_idx])\n",
    "    for l in test_indices:\n",
    "        cur_preds = cur_clf.predict(features[m][l])\n",
    "        cur_acc = get_acc(cur_preds, labels[m][l])\n",
    "        print(cur_acc)\n",
    "    return cur_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7894117647058824\n",
      "0.9317647058823529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# trg_clf = test_log_reg(features, labels, source_idx=0, test_indices=[1, 3], C=1.0)\n",
    "src_clf = test_log_reg(features, labels, source_idx=2, test_indices=[1, 3], C=10.0, sgd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9daea68046dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me30_trg_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_log_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me30_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me30_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0me30_src_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_log_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me30_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me30_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-574ecec4ec86>\u001b[0m in \u001b[0;36mtest_log_reg\u001b[0;34m(features, labels, source_idx, test_indices, C, sgd)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcur_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcur_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adaptive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcur_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    726\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[0;32m--> 566\u001b[0;31m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         if (self.tol is not None and self.tol > -np.inf\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    518\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                                  max_iter=max_iter)\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             self._fit_binary(X, y, alpha=alpha, C=C,\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_multiclass\u001b[0;34m(self, X, y, alpha, C, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[1;32m    625\u001b[0m                                 \u001b[0mvalidation_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                                 random_state=seed)\n\u001b[0;32m--> 627\u001b[0;31m             for i, seed in enumerate(seeds))\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# take the maximum of n_iter_ over every binary fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[0;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         est.eta0, est.power_t, est.t_, intercept_decay, est.average)\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e30_trg_clf = test_log_reg(e30_features, e30_labels, source_idx=0, test_indices=[1, 3], C=1.0, sgd=True)\n",
    "e30_src_clf = test_log_reg(e30_features, e30_labels, source_idx=2, test_indices=[1, 3], C=10.0, sgd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given two feature sets, make H-delta-H divergence dataset?\n",
    "def make_hdeltah_labels(xs1, xs2):\n",
    "    n1, n2 = len(xs1), len(xs2)\n",
    "    ys = [0] * n1\n",
    "    ys.extend([1] * n2)\n",
    "    return np.concatenate([xs1, xs2]), np.array(ys)\n",
    "\n",
    "def test_hdeltah(features, C=1.0):\n",
    "    l17_hdeltah_xs_train, l17_hdeltah_ys_train = make_hdeltah_labels(features[0][2], features[0][0])\n",
    "    l17_hdeltah_xs_val, l17_hdeltah_ys_val = make_hdeltah_labels(features[0][3], features[0][1])\n",
    "    cur_clf = LogisticRegression(random_state=0, C=C).fit(l17_hdeltah_xs_train, l17_hdeltah_ys_train)\n",
    "    cur_preds = cur_clf.predict(l17_hdeltah_xs_val)\n",
    "    cur_acc = get_acc(cur_preds, l17_hdeltah_ys_val)\n",
    "    return cur_clf, cur_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cur_avv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9e91def5fc68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcur_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_hdeltah\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_avv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cur_avv' is not defined"
     ]
    }
   ],
   "source": [
    "cur_clf, cur_acc = test_hdeltah(features, C=10.0)\n",
    "print(cur_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juice/scr/ananya/cifar_experiments/env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804\n"
     ]
    }
   ],
   "source": [
    "cur_clf, cur_acc = test_hdeltah(e30_features, C=10.0)\n",
    "print(cur_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump((features, labels), open(\"../logs/l17_moco_features_labels\", \"wb\"))\n",
    "pickle.dump((e30_features, e30_labels), open(\"../logs/e30_moco_features_labels\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = pickle.load(open(\"../logs/l17_moco_features_labels\", \"rb\"))\n",
    "e30_features, e30_labels = pickle.load(open(\"../logs/e30_moco_features_labels\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
