{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unlabeled_extrapolation.datasets.cifar10p1' from '/juice/scr/ananya/cifar_experiments/unlabeled_extrapolation/unlabeled_extrapolation/datasets/cifar10p1.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can load files from other sub-directories, e.g. datasets.\n",
    "import os\n",
    "import sys\n",
    "from importlib import reload  \n",
    "\n",
    "module_path = '/u/scr/ananya/cifar_experiments/unlabeled_extrapolation'\n",
    "USE_CUDA = True\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import unlabeled_extrapolation.utils.utils as utils\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import unlabeled_extrapolation.datasets.cifar10p1 as cifar10p1\n",
    "\n",
    "import calibration as cal\n",
    "reload(utils)\n",
    "reload(cifar10p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'cuda is available: {torch.cuda.is_available()}')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "living17_config = {\n",
    "    'name': 'living17_lp_ft_ensemble',\n",
    "    'models':\n",
    "    [{\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/full_ft_living17_resnet50/' + 'optimizer.args.lr-0.001_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_source_val_living',\n",
    "        'id_index': 0,\n",
    "        'ood_index': 1\n",
    "     },\n",
    "     {\n",
    "        'type': 'lp',\n",
    "        'path_prefix': module_path + '/logs/linprobe_living17_resnet50/',\n",
    "        'id_index': 1,\n",
    "        'ood_index': 2\n",
    "     },\n",
    "    ],\n",
    "    'num_trials': 3,\n",
    "    'id_val_size': 1000,\n",
    "}\n",
    "\n",
    "living17_noaugs_config = {\n",
    "    'name': 'living17_lp_ft_noaugs_ensemble',\n",
    "    'models':\n",
    "    [{\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/full_ft_no_augmentation_living17_resnet50/' + 'no_augmentation-True_optimizer.args.lr-0.0003_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_source_val_living',\n",
    "        'id_index': 0,\n",
    "        'ood_index': 1\n",
    "     },\n",
    "     {\n",
    "        'type': 'lp',\n",
    "        'path_prefix': module_path + '/logs/linprobe_living17_resnet50/',\n",
    "        'id_index': 1,\n",
    "        'ood_index': 2\n",
    "     },\n",
    "    ],\n",
    "    'num_trials': 1,\n",
    "    'id_val_size': 1000,\n",
    "}\n",
    "\n",
    "living17_bothaugs_config = {\n",
    "    'name': 'living17_lp_ft_bothaugs_ensemble',\n",
    "    'models':\n",
    "    [{\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/full_ft_living17_resnet50/' + 'optimizer.args.lr-0.001_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_source_val_living',\n",
    "        'id_index': 0,\n",
    "        'ood_index': 1\n",
    "     },\n",
    "     {\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/torch_linprobe_living17_resnet50/' + 'linear_probe-True_optimizer.args.lr-3.0_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_source_val_living',\n",
    "        'id_index': 0,\n",
    "        'ood_index': 1\n",
    "     },\n",
    "    ],\n",
    "    'num_trials': 1,\n",
    "    'id_val_size': 1000,\n",
    "}\n",
    "\n",
    "entity30_config = {\n",
    "    'name': 'entity30_lp_ft_ensemble',\n",
    "    'models':\n",
    "    [{\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/full_ft_entity30_resnet50/' + 'optimizer.args.lr-0.001_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_source_val_entity',\n",
    "        'id_index': 0,\n",
    "        'ood_index': 1\n",
    "     },\n",
    "     {\n",
    "        'type': 'lp',\n",
    "        'path_prefix': module_path + '/logs/linprobe_entity30_resnet50/',\n",
    "        'id_index': 1,\n",
    "        'ood_index': 2\n",
    "     },\n",
    "    ],\n",
    "    'num_trials': 3,\n",
    "    'id_val_size': 500,\n",
    "}\n",
    "\n",
    "domainnet_config = {\n",
    "    'name': 'domainnet_lp_ft_ensemble',\n",
    "    'models':\n",
    "    [{\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/full_ft_domainnet_clip_resnet50/' + 'optimizer.args.lr-0.001_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_sketch_val',\n",
    "        'id_index': 0,\n",
    "        'ood_index': 1\n",
    "        \n",
    "     },\n",
    "     {\n",
    "        'type': 'lp',\n",
    "        'path_prefix': module_path + '/logs/linprobe_domainnet_clip_resnet50/',\n",
    "        'id_index': 4,\n",
    "        'ood_index': 3\n",
    "     },\n",
    "    ],\n",
    "    'num_trials': 3,\n",
    "    'id_val_size': 500,\n",
    "    \n",
    "}\n",
    "\n",
    "cifar_stl_config = {\n",
    "    'name': 'cifar_stl_lp_ft_ensemble',\n",
    "    'models':\n",
    "    [{\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/full_ft_cifar_stl_resnet50/' + 'optimizer.args.lr-0.001_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_cifar10-test',\n",
    "        'id_index': 0,\n",
    "        'ood_index': 1\n",
    "     },\n",
    "     {\n",
    "        'type': 'lp',\n",
    "        'path_prefix': module_path + '/logs/linprobe_cifar_stl_resnet50/',\n",
    "        'id_index': 1,\n",
    "        'ood_index': 3\n",
    "     },\n",
    "    ],\n",
    "    'num_trials': 3,\n",
    "    'id_val_size': 500,\n",
    "}\n",
    "\n",
    "all_configs = [living17_bothaugs_config]\n",
    "# all_configs = [living17_noaugs_config, cifar_stl_config, domainnet_config, entity30_config, living17_config, living17_bothaugs_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "def load_model(config, checkpoint_path):\n",
    "    if 'unlabeled_extrapolation' not in config['model']['classname']:\n",
    "        config['model']['classname'] = 'unlabeled_extrapolation.' + config['model']['classname']\n",
    "    net = utils.initialize(config['model'])\n",
    "    if USE_CUDA:\n",
    "        net = net.cuda()\n",
    "    net.new_last_layer(config['num_classes'])\n",
    "    utils.load_ckp(checkpoint_path, net)\n",
    "    return net\n",
    "\n",
    "# Load datasets.\n",
    "def load_test_dataset(config, idx, batch_size=32, num_workers=2):\n",
    "    test_config = config['test_datasets'][idx]\n",
    "    if 'unlabeled_extrapolation' not in test_config['classname'] and 'torchvision' not in test_config['classname']:\n",
    "        test_config['classname'] = 'unlabeled_extrapolation.' + test_config['classname']\n",
    "    if 'transforms' not in test_config:\n",
    "        test_config['transforms'] = config['default_test_transforms']\n",
    "    test_data = utils.init_dataset(test_config)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size,\n",
    "        shuffle=False, num_workers=num_workers)\n",
    "    return test_data, test_loader\n",
    "\n",
    "def get_outputs_labels(net, loader):\n",
    "    torch.cuda.empty_cache()\n",
    "    net.cuda()\n",
    "    net.eval()\n",
    "    outputs_list, labels_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = net(images)\n",
    "            outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            labels_list.append(labels.detach().cpu().numpy())\n",
    "    outputs = np.concatenate(outputs_list)\n",
    "    labels = np.concatenate(labels_list)\n",
    "    return outputs, labels\n",
    "\n",
    "def split_dataset(inputs, labels, split_len):\n",
    "    # Returns (inputs1, labels1), (inputs2, labels2)\n",
    "    assert(len(inputs) == len(labels))\n",
    "    rng = np.random.RandomState(0)\n",
    "    random_indices = rng.permutation(len(inputs))\n",
    "    val_indices = random_indices[:split_len]\n",
    "    test_indices = random_indices[split_len:]\n",
    "    return (inputs[val_indices], labels[val_indices]), (inputs[test_indices], labels[test_indices])\n",
    "\n",
    "def make_validation(logits_list, labels_list, id_val_size):\n",
    "    (val_logits, val_labels), (test_logits, test_labels) = split_dataset(\n",
    "        logits_list[0], labels_list[0], split_len=id_val_size)\n",
    "    return [val_logits, test_logits] + logits_list[1:], [val_labels, test_labels] + labels_list[1:]\n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return np.mean(preds == labels)\n",
    "\n",
    "def lp_to_all_logits_labels(model_config, config):\n",
    "    path_prefix = model_config['path_prefix']\n",
    "    all_labels_list, all_model_logits = [], []\n",
    "    for i in range(config['num_trials']):\n",
    "        print(i)\n",
    "        features_path = path_prefix + 'features_' + str(i)\n",
    "        features, labels, loader_names = pickle.load(open(features_path, 'rb'))\n",
    "        weights_path = path_prefix + 'weights_' + str(i) + '.pkl'\n",
    "        coef, intercept, _, _ = pickle.load(open(weights_path, 'rb'))\n",
    "        features_list = [features[model_config['id_index']], features[model_config['ood_index']]]\n",
    "        labels_list = [labels[model_config['id_index']], labels[model_config['ood_index']]]\n",
    "        print(loader_names, model_config['id_index'], model_config['ood_index'])\n",
    "        model_logits = [f @ coef.T + intercept for f in features_list]\n",
    "        accs = [get_acc(logits, labels) for logits, labels in zip(model_logits, labels_list)]\n",
    "        print(accs)\n",
    "        model_logits, labels_list = make_validation(\n",
    "            model_logits, labels_list, id_val_size=config['id_val_size'])\n",
    "        all_model_logits.append(model_logits)\n",
    "        all_labels_list.append(labels_list)\n",
    "    return all_model_logits, all_labels_list\n",
    "\n",
    "def ft_to_all_logits_labels(model_config, config):\n",
    "    path_prefix = model_config['path_prefix']\n",
    "    checkpoint_suffix = model_config['checkpoint_suffix']\n",
    "    all_labels_list, all_model_logits = [], []\n",
    "    for i in range(config['num_trials']):\n",
    "        print(i)\n",
    "        torch.cuda.empty_cache()\n",
    "        cur_prefix = path_prefix.format(i, i)\n",
    "        config_path = cur_prefix + 'config.json'\n",
    "        ckp_path = cur_prefix + 'checkpoints/' + checkpoint_suffix\n",
    "        cur_config = load_config(config_path)\n",
    "        model = load_model(cur_config, ckp_path)\n",
    "        _, id_loader = load_test_dataset(cur_config, model_config['id_index'])\n",
    "        _, ood_loader = load_test_dataset(cur_config, model_config['ood_index'])\n",
    "        id_logits, id_labels = get_outputs_labels(model, id_loader)\n",
    "        ood_logits, ood_labels = get_outputs_labels(model, ood_loader)\n",
    "        model_logits = [id_logits, ood_logits]\n",
    "        labels_list = [id_labels, ood_labels]\n",
    "        accs = [get_acc(logits, labels) for logits, labels in zip(model_logits, labels_list)]\n",
    "        print(accs)\n",
    "        model_logits, labels_list = make_validation(\n",
    "            model_logits, labels_list, id_val_size=config['id_val_size'])\n",
    "        all_model_logits.append(model_logits)\n",
    "        all_labels_list.append(labels_list)\n",
    "    return all_model_logits, all_labels_list\n",
    "\n",
    "def model_to_all_logits_labels(model_config, config):\n",
    "    if model_config['type'] == 'lp':\n",
    "        return lp_to_all_logits_labels(model_config, config)\n",
    "    elif model_config['type'] == 'ft':\n",
    "        return ft_to_all_logits_labels(model_config, config)\n",
    "    else:\n",
    "        raise ValueError('model_config must be lp or ft')\n",
    "\n",
    "def config_to_all_logits_labels(config):\n",
    "    # For each model, get logits, labels\n",
    "    rob_all_model_logits, all_labels_list = model_to_all_logits_labels(config['models'][1], config)\n",
    "    std_all_model_logits, all_labels_list2 = model_to_all_logits_labels(config['models'][0], config)\n",
    "    return std_all_model_logits, rob_all_model_logits, all_labels_list\n",
    "\n",
    "    # Split up the first dataset into 1000 and rest, using seed 0.\n",
    "#     return list(zip(*[get_outputs_labels(model, l) for l in loaders]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "save_dir = '../logs/ensemble_logits/'\n",
    "for config in all_configs:\n",
    "    std_all_model_logits, rob_all_model_logits, all_labels_list = config_to_all_logits_labels(config)\n",
    "    pickle.dump((std_all_model_logits, rob_all_model_logits, all_labels_list),\n",
    "                open(save_dir + config['name']+'.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get results on CIFAR-10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels from file /u/scr/ananya/cifar10.1/cifar10.1_v6_labels.npy\n",
      "Loading image data from file /u/scr/ananya/cifar10.1/cifar10.1_v6_data.npy\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.228, 0.224, 0.225]\n",
    ")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "c10p1_test_data = cifar10p1.CIFAR10p1(root='/u/scr/ananya/cifar10.1', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_config = {\n",
    "    'name': 'cifar10p1_test',\n",
    "    'models':\n",
    "    [{\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/full_ft_cifar_stl_resnet50/' + 'optimizer.args.lr-0.001_seed-{}_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_cifar10-test',\n",
    "     },\n",
    "     {\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/lp_then_ft_valmode_cifar_stl_resnet50/' + 'optimizer.args.lr-0.0001_seed-{}_use_net_val_mode-True_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_0',\n",
    "     },\n",
    "     {\n",
    "        'type': 'ft',\n",
    "        'path_prefix': module_path + '/logs/lp_then_ft_valmode_cifar_stl_resnet50/' + 'optimizer.args.lr-0.0001_seed-{}_use_net_val_mode-True_run{}/',\n",
    "        'checkpoint_suffix': 'ckp_best_cifar10-test',\n",
    "     },\n",
    "    ],\n",
    "    'num_trials': 3,\n",
    "    'id_val_size': 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_ft_accs(model_config, config, dataset, batch_size=32, num_workers=2):\n",
    "    path_prefix = model_config['path_prefix']\n",
    "    checkpoint_suffix = model_config['checkpoint_suffix']\n",
    "    all_labels_list, all_model_logits = [], []\n",
    "    accs = []\n",
    "    for i in range(config['num_trials']):\n",
    "        print(i)\n",
    "        torch.cuda.empty_cache()\n",
    "        cur_prefix = path_prefix.format(i, i)\n",
    "        config_path = cur_prefix + 'config.json'\n",
    "        ckp_path = cur_prefix + 'checkpoints/' + checkpoint_suffix\n",
    "        cur_config = load_config(config_path)\n",
    "        model = load_model(cur_config, ckp_path)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=batch_size,\n",
    "            shuffle=False, num_workers=num_workers)\n",
    "        test_logits, test_labels = get_outputs_labels(model, test_loader)\n",
    "        acc = get_acc(test_logits, test_labels)\n",
    "        print(acc)\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "def config_results(config, data=c10p1_test_data):\n",
    "    # For each model, get logits, labels\n",
    "    for model_config in config['models']:\n",
    "        accs = get_ft_accs(model_config, config, c10p1_test_data)\n",
    "        print('mean: ', np.mean(accs))\n",
    "        print('stderr: ', 1.645 * np.std(accs) / np.sqrt(len(accs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.928\n",
      "1\n",
      "0.9195\n",
      "2\n",
      "0.9205\n",
      "mean:  0.9226666666666667\n",
      "stderr:  0.0036026237223980785\n",
      "0\n",
      "0.825\n",
      "1\n",
      "0.825\n",
      "2\n",
      "0.83\n",
      "mean:  0.8266666666666667\n",
      "stderr:  0.002238561459376851\n",
      "0\n",
      "0.9355\n",
      "1\n",
      "0.9355\n",
      "2\n",
      "0.934\n",
      "mean:  0.935\n",
      "stderr:  0.0006715684378130305\n"
     ]
    }
   ],
   "source": [
    "config_results(cifar_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
