{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unlabeled_extrapolation.models.innout_models' from '/juice/scr/ananya/cifar_experiments/unlabeled_extrapolation/unlabeled_extrapolation/models/innout_models.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('unlabeled_extrapolation'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from unlabeled_extrapolation.datasets import landcover\n",
    "from unlabeled_extrapolation.models import innout_models\n",
    "\n",
    "import importlib\n",
    "importlib.reload(landcover)\n",
    "importlib.reload(innout_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/u/scr/nlp/eix/landcover/timeseries_by_box_v2'\n",
    "cache_path = '/u/scr/nlp/eix/landcover/landcover_v2.pkl'\n",
    "seed=1111\n",
    "unlabeled_prop = 0.9\n",
    "\n",
    "dataset = landcover.Landcover(root=root, cache_path=cache_path, seed=seed, unlabeled_prop=unlabeled_prop, split='nonafrica-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['classifier.fc1.weight', 'classifier.fc1.bias', 'classifier.fc2.weight', 'classifier.fc2.bias'], unexpected_keys=['feature_extractor.0.Task1Linear1.weight', 'feature_extractor.0.Task1Linear1.bias', 'feature_extractor.0.Task1Linear2.weight', 'feature_extractor.0.Task1Linear2.bias', 'feature_extractor.0.Task1Linear3.weight', 'feature_extractor.0.Task1Linear3.bias', 'feature_extractor.1.Task2Linear1.weight', 'feature_extractor.1.Task2Linear1.bias', 'feature_extractor.1.Task2Linear2.weight', 'feature_extractor.1.Task2Linear2.bias', 'feature_extractor.1.Task2Linear3.weight', 'feature_extractor.1.Task2Linear3.bias'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/pretrained_checkpoints/landcover/best-checkpoint.pt'\n",
    "model = innout_models.CNN1D(in_channels=8, output_size=6, checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f136e5cac10>\n"
     ]
    }
   ],
   "source": [
    "# get model parameters\n",
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['feature_extractor.feature_extractor.conv1.weight', 'feature_extractor.feature_extractor.conv1.bias', 'feature_extractor.feature_extractor.conv2.weight', 'feature_extractor.feature_extractor.conv2.bias', 'feature_extractor.feature_extractor.conv3.weight', 'feature_extractor.feature_extractor.conv3.bias', 'feature_extractor.feature_extractor.conv4.weight', 'feature_extractor.feature_extractor.conv4.bias', 'classifier.fc1.weight', 'classifier.fc1.bias', 'classifier.fc2.weight', 'classifier.fc2.bias'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_extractor.feature_extractor.conv1.weight\n",
      "feature_extractor.feature_extractor.conv1.bias\n",
      "feature_extractor.feature_extractor.conv2.weight\n",
      "feature_extractor.feature_extractor.conv2.bias\n",
      "feature_extractor.feature_extractor.conv3.weight\n",
      "feature_extractor.feature_extractor.conv3.bias\n",
      "feature_extractor.feature_extractor.conv4.weight\n",
      "feature_extractor.feature_extractor.conv4.bias\n",
      "feature_extractor.0.Task1Linear1.weight\n",
      "feature_extractor.0.Task1Linear1.bias\n",
      "feature_extractor.0.Task1Linear2.weight\n",
      "feature_extractor.0.Task1Linear2.bias\n",
      "feature_extractor.0.Task1Linear3.weight\n",
      "feature_extractor.0.Task1Linear3.bias\n",
      "feature_extractor.1.Task2Linear1.weight\n",
      "feature_extractor.1.Task2Linear1.bias\n",
      "feature_extractor.1.Task2Linear2.weight\n",
      "feature_extractor.1.Task2Linear2.bias\n",
      "feature_extractor.1.Task2Linear3.weight\n",
      "feature_extractor.1.Task2Linear3.bias\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "checkpoint_path = '/u/scr/ananya/cifar_experiments/unlabeled_extrapolation/pretrained_checkpoints/landcover/best-checkpoint.pt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "compatible_state_dict = collections.OrderedDict()\n",
    "for k in checkpoint['state_dict']:\n",
    "    comp_k = k[k.find('.')+1:]\n",
    "    comp_k = 'feature_extractor' + comp_k[comp_k.find('.'):]\n",
    "    print(comp_k)\n",
    "    compatible_state_dict[comp_k] = checkpoint['state_dict'][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['classifier.fc1.weight', 'classifier.fc1.bias', 'classifier.fc2.weight', 'classifier.fc2.bias'], unexpected_keys=['feature_extractor.0.Task1Linear1.weight', 'feature_extractor.0.Task1Linear1.bias', 'feature_extractor.0.Task1Linear2.weight', 'feature_extractor.0.Task1Linear2.bias', 'feature_extractor.0.Task1Linear3.weight', 'feature_extractor.0.Task1Linear3.bias', 'feature_extractor.1.Task2Linear1.weight', 'feature_extractor.1.Task2Linear1.bias', 'feature_extractor.1.Task2Linear2.weight', 'feature_extractor.1.Task2Linear2.bias', 'feature_extractor.1.Task2Linear3.weight', 'feature_extractor.1.Task2Linear3.bias'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(compatible_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2219, -0.2962, -0.0927, -0.1076,  0.0733,  0.1528]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.unsqueeze(dataset[0][0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
