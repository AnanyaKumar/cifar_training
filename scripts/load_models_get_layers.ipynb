{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unlabeled_extrapolation.models.timm_model' from '/juice/scr/ananya/cifar_experiments/transfer_learning/unlabeled_extrapolation/models/timm_model.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unlabeled_extrapolation.models import bit_resnet, vit_model, timm_model\n",
    "from unlabeled_extrapolation.utils import utils\n",
    "import importlib\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "importlib.reload(bit_resnet)\n",
    "importlib.reload(vit_model)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(timm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/juice/scr/ananya/cifar_experiments/transfer_learning/scripts', '/juice/scr/ananya/cifar_experiments/transfer_learning/scripts', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python38.zip', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/lib-dynload', '', '/sailhome/ananya/.local/lib/python3.8/site-packages', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/site-packages', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/site-packages/apex-0.1-py3.8-linux-x86_64.egg', '/juice/scr/ananya/cifar_experiments/wilds', '/juice/scr/ananya/cifar_experiments/transfer_learning', '/juice/scr/ananya/verified_calibration', '/u/nlp/anaconda/main/anaconda3/envs/ananya-ue/lib/python3.8/site-packages/IPython/extensions', '/sailhome/ananya/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers_freeze_test(model):\n",
    "    print('num params before freezing: ', utils.count_parameters(model, trainable=True))\n",
    "    print(model.get_layers()[1])\n",
    "    print(len(model.get_layers()))\n",
    "    for k in [1, 2, len(model.get_layers())]:\n",
    "        model.freeze_bottom_k(k=k)\n",
    "        print(f'num params after freezing {k}: {utils.count_parameters(model, trainable=True)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  68256659\n",
      "('conv-block-0', Sequential(\n",
      "  (unit01): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (unit02): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (unit03): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "6\n",
      "num params after freezing 1: 68247251\n",
      "num params after freezing 2: 68032339\n",
      "num params after freezing 6: 0\n",
      "num params before freezing:  87248787\n",
      "('conv-block-0', Sequential(\n",
      "  (unit01): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (unit02): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (unit03): PreActBottleneck(\n",
      "    (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "6\n",
      "num params after freezing 1: 87239379\n",
      "num params after freezing 2: 87024467\n",
      "num params after freezing 6: 0\n"
     ]
    }
   ],
   "source": [
    "# Bit-resnet (get layers) for ResNet-50 and ResNet-101\n",
    "\n",
    "resnet50_checkpoint_path = \"/u/scr/ananya/simclr_weights/BiT-M-R50x1.npz\"\n",
    "resnet50 = bit_resnet.BitResNet(model_name='BiT-M-R50x1', checkpoint_path=resnet50_checkpoint_path)\n",
    "get_layers_freeze_test(resnet50)\n",
    "\n",
    "resnet101_checkpoint_path = \"/u/scr/ananya/simclr_weights/BiT-M-R101x1.npz\"\n",
    "resnet101 = bit_resnet.BitResNet(model_name='BiT-M-R101x1', checkpoint_path=resnet101_checkpoint_path)\n",
    "get_layers_freeze_test(resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dino/archive/main.zip\" to /sailhome/ananya/.cache/torch/hub/main.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  85806346\n",
      "('empty_ln_pre', Module())\n",
      "54\n",
      "1\n",
      "num params after freezing 1: 85215754\n",
      "2\n",
      "num params after freezing 2: 85215754\n",
      "54\n",
      "num params after freezing 54: 0\n"
     ]
    }
   ],
   "source": [
    "# DINO\n",
    "model = vit_model.VitModel(model_name='dino_vitb16')\n",
    "model.new_last_layer(10)\n",
    "get_layers_freeze_test(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  22050664\n",
      "('empty_ln_pre', Module())\n",
      "54\n",
      "num params after freezing 1: 21755368\n",
      "num params after freezing 2: 21755368\n",
      "num params after freezing 54: 0\n"
     ]
    }
   ],
   "source": [
    "# Timm ViT-S\n",
    "model = vit_model.VitModel(model_name='timm.vit_small_patch16_224')\n",
    "get_layers_freeze_test(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed 26.6946963982087\n",
      "empty_ln_pre 0.0\n",
      "pos_embed 114.1449203491211\n",
      "cls_token 11.814652442932129\n",
      "trans0_norm1 10.727939400443407\n",
      "trans0_attn 51.44874777832921\n",
      "trans0_norm2 28.292761646663003\n",
      "trans0_mlp 76.65611477620195\n",
      "trans1_norm1 11.67158919875855\n",
      "trans1_attn 51.968497785989186\n",
      "trans1_norm2 16.081294584238012\n",
      "trans1_mlp 72.49136824958491\n",
      "trans2_norm1 14.588461930309668\n",
      "trans2_attn 47.43609999667546\n",
      "trans2_norm2 16.750402005493847\n",
      "trans2_mlp 73.4898046975493\n",
      "trans3_norm1 17.127796509537827\n",
      "trans3_attn 46.12080652841503\n",
      "trans3_norm2 16.560562623359647\n",
      "trans3_mlp 73.75539281539531\n",
      "trans4_norm1 16.38613601236467\n",
      "trans4_attn 45.396057461621595\n",
      "trans4_norm2 15.56170805432499\n",
      "trans4_mlp 74.04262678751516\n",
      "trans5_norm1 15.666596993058972\n",
      "trans5_attn 45.22580724285582\n",
      "trans5_norm2 16.125041315399216\n",
      "trans5_mlp 74.32087040062893\n",
      "trans6_norm1 16.50691386925591\n",
      "trans6_attn 44.89644589636653\n",
      "trans6_norm2 16.870073778570866\n",
      "trans6_mlp 78.20890488715406\n",
      "trans7_norm1 16.66077125665377\n",
      "trans7_attn 45.82781002989781\n",
      "trans7_norm2 19.266974095400364\n",
      "trans7_mlp 81.80467684677028\n",
      "trans8_norm1 17.5644882043329\n",
      "trans8_attn 47.610578568992075\n",
      "trans8_norm2 43.14843316111718\n",
      "trans8_mlp 81.65995954456746\n",
      "trans9_norm1 19.72671889415036\n",
      "trans9_attn 48.02174698323452\n",
      "trans9_norm2 65.44239677355796\n",
      "trans9_mlp 85.10741788908027\n",
      "trans10_norm1 23.690038485002656\n",
      "trans10_attn 47.81185122297828\n",
      "trans10_norm2 173.51592363743683\n",
      "trans10_mlp 96.2868619031599\n",
      "trans11_norm1 29.018153114479592\n",
      "trans11_attn 53.61129902293072\n",
      "trans11_norm2 24.21393277393142\n",
      "trans11_mlp 84.18814129510835\n",
      "post_norm 48.72875120683025\n",
      "head 17.718359892033757\n"
     ]
    }
   ],
   "source": [
    "# Get model grads and norms for Timm ViT-S\n",
    "layers = model.get_layers()\n",
    "\n",
    "for name, layer in layers:\n",
    "    norms_squared = [np.linalg.norm(p.data.detach().cpu().numpy()) ** 2 for p in layer.parameters()]\n",
    "    norm = np.sqrt(np.sum(norms_squared))\n",
    "    print(name, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params before freezing:  109953489\n",
      "('stage0', ConvNeXtStage(\n",
      "  (downsample): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (1): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (2): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "))\n",
      "7\n",
      "num params after freezing 1: 109946961\n",
      "num params after freezing 2: 109531473\n",
      "num params after freezing 7: 0\n"
     ]
    }
   ],
   "source": [
    "# Conv-next\n",
    "model = timm_model.TimmModel('convnext_base_in22k')\n",
    "get_layers_freeze_test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        ...,\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625],\n",
       "        [-2.1558,  0.1969, -2.2230,  ..., -2.2479,  0.7122,  0.2625]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros((8,3,224,224))\n",
    "x = x.cuda()\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
      "  (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      "  (fc): Linear(in_features=1024, out_features=21841, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
